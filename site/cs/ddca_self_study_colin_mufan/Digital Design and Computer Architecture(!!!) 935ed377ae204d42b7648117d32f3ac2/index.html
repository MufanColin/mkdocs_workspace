
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../OS/">
      
      
        <link rel="next" href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2010%20eb97c06954a04afb99ae01d4a51f7bc4/">
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.0.11">
    
    
      
        <title>Digital Design and Computer Architecture(!!!) - Colin Mufan's Wonderland</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.0d440cfe.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.2505c338.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent="">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#digital-design-and-computer-architecture" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Colin Mufan&#39;s Wonderland" class="md-header__button md-logo" aria-label="Colin Mufan's Wonderland" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Colin Mufan's Wonderland
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Digital Design and Computer Architecture(!!!)
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Colin Mufan&#39;s Wonderland" class="md-nav__button md-logo" aria-label="Colin Mufan's Wonderland" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Colin Mufan's Wonderland
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        Welcome to Colin Mufan's wonderland
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../about/" class="md-nav__link">
        About
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../license/" class="md-nav__link">
        License
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
      
      
      
        <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
          CS
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          CS
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../DDCA/" class="md-nav__link">
        DDCA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../OS/" class="md-nav__link">
        OS
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" checked>
      
      
      
        <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
          Ddca self study colin mufan
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_4_3">
          <span class="md-nav__icon md-icon"></span>
          Ddca self study colin mufan
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Digital Design and Computer Architecture(!!!)
      </a>
      
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3_2" >
      
      
      
        <label class="md-nav__link" for="__nav_4_3_2" id="__nav_4_3_2_label" tabindex="0">
          Digital Design and Computer Architecture(!!!) 935ed377ae204d42b7648117d32f3ac2
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_3_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_3_2">
          <span class="md-nav__icon md-icon"></span>
          Digital Design and Computer Architecture(!!!) 935ed377ae204d42b7648117d32f3ac2
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_4_3_2_1" id="__nav_4_3_2_1_label" tabindex="0">
          Exercises 1 Checklist 9739faeb07f34d1ca5054be6c77d32a4
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_4_3_2_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_3_2_1">
          <span class="md-nav__icon md-icon"></span>
          Exercises 1 Checklist 9739faeb07f34d1ca5054be6c77d32a4
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2010%20eb97c06954a04afb99ae01d4a51f7bc4/" class="md-nav__link">
        Exercises 1.10
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2011%202470c3e6ea2247e3891c90d1d937d57b/" class="md-nav__link">
        Exercises 1.11
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2012%20e4a29214a0a046abbd796833f514b1b3/" class="md-nav__link">
        Exercises 1.12
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2013%2088c6ac38eb7a4a8dbe405d8ed36c1f6d/" class="md-nav__link">
        Exercises 1.13
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2014%205848d6963cdf403388c23f9575aeef6c/" class="md-nav__link">
        Exercises 1.14
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2015%20d52eb013fc324970b7fb0a5eed9b22f4/" class="md-nav__link">
        Exercises 1.15
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2016%209c0a504f498b4ef4a71bb108cf87fe62/" class="md-nav__link">
        Exercises 1.16
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2017%20c238149df31440b18aaf2f477472826e/" class="md-nav__link">
        Exercises 1.17
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2018%20ee81733299b241fe9c693ca7ca2e92e6/" class="md-nav__link">
        Exercises 1.18
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2019%20be390edc87fc4bd6a34e9281de12fd21/" class="md-nav__link">
        Exercises 1.19
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2020%20b740d9dd1bf24ad28643f0345ebe1110/" class="md-nav__link">
        Exercises 1.20
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2021%20e2e62e6b32154fb8ace582f3325dc827/" class="md-nav__link">
        Exercises 1.21
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2022%20c4ed318b8f4e4f5e88286c6f9fd57284/" class="md-nav__link">
        Exercises 1.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2023%206abd4ff4f34642a080f6d74f03a3978d/" class="md-nav__link">
        Exercises 1.23
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2024%203856d2317d1b4f478fa6dfe6d50d333f/" class="md-nav__link">
        Exercises 1.24
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2025%208a9ee3fa7b65420c915a9ef59f2a8966/" class="md-nav__link">
        Exercises 1.25
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2026%20e0742cd464cd4d00b03254bdae747197/" class="md-nav__link">
        Exercises 1.26
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2027%202aa06ba608174e089c9996675cb6371c/" class="md-nav__link">
        Exercises 1.27
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2028%207a39d73323c64c85844b61b3256567f3/" class="md-nav__link">
        Exercises 1.28
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2029%20ef0ad6558e06485b88499ce21bdead27/" class="md-nav__link">
        Exercises 1.29
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2030%205395e3a52b7549178c492a75a6c73869/" class="md-nav__link">
        Exercises 1.30
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2031%203b868a7b556849a096ef76d2c3d5d5f6/" class="md-nav__link">
        Exercises 1.31
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2032%200f6c5334043a4a709304a9afd32baa15/" class="md-nav__link">
        Exercises 1.32
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2033%20a88e0dc63af3479d8f7dd78b688f817b/" class="md-nav__link">
        Exercises 1.33
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2034%20a51d07d672b648bf9084c4f5561fcade/" class="md-nav__link">
        Exercises 1.34
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2035%208b202192a2cb481baecaffc0f4026234/" class="md-nav__link">
        Exercises 1.35
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2036%204180a60d4ec247dbb7f118f3a0745771/" class="md-nav__link">
        Exercises 1.36
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2037%20ddd1e130ee3b4d0c938de29980a0f2b2/" class="md-nav__link">
        Exercises 1.37
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2038%209dcc63eb41604125ab26b2d15d3139c3/" class="md-nav__link">
        Exercises 1.38
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2039%20828be2e26825457fa2c428122d861427/" class="md-nav__link">
        Exercises 1.39
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2040%2077ee90b34ecf45a9890c128b33a0cdb5/" class="md-nav__link">
        Exercises 1.40
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2041%206331cf415ae44d549b9817d47e36e5a8/" class="md-nav__link">
        Exercises 1.41
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2042%20b15be9a043514a2f833a07f23dadc2f0/" class="md-nav__link">
        Exercises 1.42
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2043%20ceb4bca019704340a058557b5520ffe9/" class="md-nav__link">
        Exercises 1.43
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2044%20a56d0ea66fbf4cf8a69e35cf9fcfa7d3/" class="md-nav__link">
        Exercises 1.44
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2045%205aaf25cf48584ddf8b9fa51d0528699a/" class="md-nav__link">
        Exercises 1.45
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2046%203582cbcb8d2e406e8dd084b03ba189aa/" class="md-nav__link">
        Exercises 1.46
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2047%20e042d3907cd346f0935ff80ccea94a17/" class="md-nav__link">
        Exercises 1.47
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2048%20b287524da7784998a0e1f01b9dc1d5e7/" class="md-nav__link">
        Exercises 1.48
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2049%20ce6aba5bd6c54bd4bf00edc8eccdd3fc/" class="md-nav__link">
        Exercises 1.49
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2050%20fbf0963aac8d48578383ff7db699d65d/" class="md-nav__link">
        Exercises 1.50
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2051%20e954da8d73184833b14cd3673e8eca49/" class="md-nav__link">
        Exercises 1.51
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2052%20af2c88a5cb524a6ca49703fbcd649139/" class="md-nav__link">
        Exercises 1.52
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2053%20444db9a1e08c4d63a338dec15d0fb3b5/" class="md-nav__link">
        Exercises 1.53
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2054%20a4e8e560a999440699d744cca1c184c4/" class="md-nav__link">
        Exercises 1.54
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2055%200c1684b93a224bea868bde038edab9c9/" class="md-nav__link">
        Exercises 1.55
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%2056%20c9817533db894102ad31406ad2b4789f/" class="md-nav__link">
        Exercises 1.56
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%206%207e227b1c17604545a91e0f0d56baa02b/" class="md-nav__link">
        Exercises 1.6
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%207%20bd1806833e3c4672a09c08ec65a3895d/" class="md-nav__link">
        Exercises 1.7
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%208%20849cf49f510949e7bab1a0d143d20c79/" class="md-nav__link">
        Exercises 1.8
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Exercises%201%209%20fd6964faad4345b8a9a8902674a01829/" class="md-nav__link">
        Exercises 1.9
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4/Untitled%205331123057ec42a2a8ff2eb6e333da81/" class="md-nav__link">
        Untitled
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3_2_2" >
      
      
      
        <label class="md-nav__link" for="__nav_4_3_2_2" id="__nav_4_3_2_2_label" tabindex="0">
          Exercises 2 Checklist 4b2fba53abf840e59c03a948aa131dbe
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_4_3_2_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4_3_2_2">
          <span class="md-nav__icon md-icon"></span>
          Exercises 2 Checklist 4b2fba53abf840e59c03a948aa131dbe
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%201%2083ec2d7f79084726bd92446b1cb182b2/" class="md-nav__link">
        Exercises 2.1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2010%201e9703ae525348ad9c1b40b57a82e478/" class="md-nav__link">
        Exercises 2.10
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2011%20aca3b6390dd741ccac3e7db77844b7f1/" class="md-nav__link">
        Exercises 2.11
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2012%20b6c09feb9ffb4e92aeff7364d361523f/" class="md-nav__link">
        Exercises 2.12
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2013%20d18a37541b7d4a70b18f17bd1398321a/" class="md-nav__link">
        Exercises 2.13
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2014%20040bcd97528f43f19c9d8a08bed39278/" class="md-nav__link">
        Exercises 2.14
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2015%20185e9af05dd048d1a9d8ff7431fa1fea/" class="md-nav__link">
        Exercises 2.15
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2016%200b0ce076ae1448278c1014ad01cfe2b1/" class="md-nav__link">
        Exercises 2.16
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2017%203d5b02c34e5744b084ae154aea0c37ef/" class="md-nav__link">
        Exercises 2.17
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2018%207c266bbd135a49e886bad59da63c258e/" class="md-nav__link">
        Exercises 2.18
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2019%20a53c1f37ae48499b81d200b738d55b0d/" class="md-nav__link">
        Exercises 2.19
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%202%20bcea0f249c834108af70a54b3a713541/" class="md-nav__link">
        Exercises 2.2
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2020%20936a963cfead4b14b265cc9521623fa7/" class="md-nav__link">
        Exercises 2.20
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2021%2043f03d158d134c38b8c261f904752b59/" class="md-nav__link">
        Exercises 2.21
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2022%205ce21a910d4a4f7c81bd94e38135b8ac/" class="md-nav__link">
        Exercises 2.22
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2023%207330a82cf1f548bcbdf43c007406f577/" class="md-nav__link">
        Exercises 2.23
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2024%20c205fa5492d444c3b2cc5d4b9454580b/" class="md-nav__link">
        Exercises 2.24
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2025%202596dad93b8c45ff8aa5dde92e1a33e0/" class="md-nav__link">
        Exercises 2.25
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%2026%20f39b5317a8844ad49337443018d8bd3a/" class="md-nav__link">
        Exercises 2.26
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%203%20ada23e3d73794426b2e0e44b47c2a694/" class="md-nav__link">
        Exercises 2.3
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%204%20d8d0fa10640242549ac2aaf259835a4f/" class="md-nav__link">
        Exercises 2.4
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%205%2085cb6c6d12804795a1806ac5b11dee07/" class="md-nav__link">
        Exercises 2.5
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%206%205968a7d9755e41988c38661b734c4457/" class="md-nav__link">
        Exercises 2.6
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%207%205969c6bf6662465a86b97eefd92d342a/" class="md-nav__link">
        Exercises 2.7
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%208%20f5759ca2ebea413ebce81971a793d586/" class="md-nav__link">
        Exercises 2.8
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Exercises%202%209%20a5e5451d2f604cd99e0004317ee34039/" class="md-nav__link">
        Exercises 2.9
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe/Untitled%20e4ec046157c8474e9fbde4b77efb5e4d/" class="md-nav__link">
        Untitled
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="digital-design-and-computer-architecture">Digital Design and Computer Architecture(!!!)</h1>
<p><a href="http://pages.hmc.edu/harris/ddca/">Digital Design and Computer Architecture</a></p>
<p><img alt="Screenshot 2023-02-01 at 23.13.43.png" src="Screenshot_2023-02-01_at_23.13.43.png" /></p>
<h1 id="1-from-zero-to-one">1 From Zero to One</h1>
<h2 id="10-exercises">1.0 Exercises</h2>
<p><a href="Exercises%201%20Checklist%209739faeb07f34d1ca5054be6c77d32a4.csv">Exercises 1 Checklist</a></p>
<h2 id="11-the-game-plan">1.1 The Game Plan</h2>
<aside>
📖 **Key Ideas**

- We believe that microprocessors are not only technically, economically, and socially important, but are also an **intrinsically fascinating human invention**.
- We assume that you have a basic familiarity with electricity, some prior programming experience, and **a genuine interest in understanding what goes on under the hood of a computer**.
- The designer’s challenge is to **combine these simple blocks into complicated systems**.
- One of the major themes weaved through this book is **how to manage complexity**.
</aside>

<aside>
📖 **Study pattern**

- We begin with **digital logic gates** that accept 1’s and 0’s as inputs and produce 1’s and 0’s as outputs.
- We then explore how to **combine logic gates into more complicated modules** such as adders and memories.
- Then we shift gears to **programming in assembly language**, the native tongue of the microprocessor.
- Finally, we **put gates together to build a microprocessor** that runs these assembly language programs.
</aside>

<h2 id="12-the-art-of-managing-complexity">1.2 The Art of Managing Complexity</h2>
<aside>
📌 **One of the characteristics that separates an engineer or computer scientist from a layperson is a systematic approach to managing complexity.**

</aside>

<h3 id="121-abstraction">1.2.1 Abstraction(!!!)</h3>
<aside>
📌 **The critical technique for managing complexity is *abstraction*: hiding details when they are not important.**

</aside>

<aside>
📖 **Levels of abstraction for an electronic computing system**

![Screenshot 2023-01-18 at 10.04.15.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-18_at_10.04.15.png)

</aside>

<aside>
📖 **Detailed Explanations**

1. At the lowest level of abstraction is the physics, **the motion of electrons**.
2. Our system is constructed from **electronic devices** such as transistors. These devices have well-defined connection points called ***terminals*** and can be modeled by the relationship between voltage and current as measured at each terminal.
3. The next level of abstraction is **analog circuits**, in which devices are assembled to create components such as amplifiers. Analog circuits **input and output a continuous range of voltages**.
4. **Digital circuits** such as logic gates **restrict the voltages to discrete ranges**, which we will use to indicate 0 and 1.
5. In logic design, we build **more complex structures**, such as **adders or memories**, from digital circuits.
6. **Microarchitecture** **links the logic and architecture levels of abstraction**. Microarchitecture involves **combing logic elements to execute the instructions defined by the architecture**. 
7. The **architecture level** of abstraction describes a computer **from the programmer’s perspective**. For example, the Intel x86 architecture used by microprocessors in most *personal computers*(*PCs*) is defined by a ***set of instructions*** and ***registers***(***memory for temporarily storing variables***) that the programmer is allowed to use. **A particular architecture can be implemented by one of many different microarchitectures with different price/performance/power trade-offs.**
8. Moving into the **software realm**, the **operating system** handles **low-level details such as accessing a hard drive or managing memory**. 
9. Finally, **the application software** uses these facilities provided by the operating system to solve a problem for the user.
</aside>

<aside>
📖 Things to keep in mind

- This book focuses on **the levels of abstraction from digital circuits through computer architecture**.
- **When you are working at one level of abstraction, it is good to know something about the levels of abstraction immediately above and below where you are working**.
</aside>

<h3 id="122-discipline">1.2.2  Discipline(?)</h3>
<h3 id="123-the-three-ys">1.2.3 The Three-Y’s</h3>
<aside>
📖 In addition to abstraction and discipline, designers use the three “-y’s” to manage complexity: **hierarchy**, **modularity**, and **regularity**. These principles apply to both software and hardware systems.

- **Hierarchy**

    Hierarchy involves **dividing a system into modules**, then further **sub-dividing each of these modules** until the pieces are easy to understand.


- Modularity

    Modularity states that the **modules have well-defined functions and interfaces**, so that they connect together easily without unanticipated side effects.


- Regularity

    Regularity **seeks uniformity among the modules**. Common modules are reused many times, reducing the number of distinct modules that must be designed.

</aside>

<h2 id="13-the-digital-abstraction">1.3 The Digital Abstraction</h2>
<aside>
📖 **Important takeaways**

- Digital systems represent information with **discrete-valued variables** — that is, variables with a **finite number** of **distinct values**.
- Most electronic computers use a binary(two-valued) representation in which a high voltage indicates a ‘1’ and a low voltage indicates a ‘0’, because it is a easier to distinguish between two voltages than ten.
- The ***amount of information*** $D\,$in a discrete valued variable with $N\,$distinct states is measured in units of ***bits*** as

    $$
    D=\log _2N \text \space\space\text{bits}
    $$

</aside>

<h2 id="14-number-systems">1.4 Number Systems(!!!)</h2>
<h3 id="140-overview">1.4.0 Overview(!!!)</h3>
<p><img alt="Screenshot 2023-01-18 at 14.42.40.png" src="Screenshot_2023-01-18_at_14.42.40.png" /></p>
<h3 id="142-binary-numbers">1.4.2 Binary Numbers</h3>
<h3 id="143-hexadecimal-numbers">1.4.3 Hexadecimal Numbers</h3>
<h3 id="144-bytes-nibbles-and-all-that-jazz">1.4.4 Bytes, Nibbles, and All That Jazz</h3>
<aside>
📖 **Important takeaways**

- **Conversion**

    A group of **eight bits** is called a ***byte***. It represents one of $\,2^8=256\,$possibilities. The size of objects stored in computer memories is customarily measured in bytes rather than bits.

    $$
    \begin{align*}1\,\text{byte}&=8\,\text{bits}=2\,\text{hexadecimal digits}\\0.5 \,\text{byte}&=4\,\text{bits}=1\,\text{hexadecimal digit}=1 \,\text{nibble}\end{align*}
    $$

- **Words**

    Microprocessors handle data in chunks called ***words***. **The size of a word depends on the architecture of the microprocessor**. When this chapter was written in 2012, most computers had 64-bit processors, indicating that they operate in **64-bit** words. At the time, older computers handling 32-bit words were also widely available. Simpler microprocessors, especially those used in gadgets such as toasters, use 8- or 16-bit words.


- **Least significant bit(lsb), most significant bit(msb), least significant byte(LSB), most significant byte(MSB)**

    ![Screenshot 2023-01-18 at 11.37.06.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-18_at_11.37.06.png)

- **Background Information**

    **A microprocessor is a processor built on a single chip**. Until 1970’s, processors were too complicated to fit on one chip, so mainframe processors were built from boards containing many chips. Intel introduced the first 4-bit microprocessor, called the 4004, in 1971. Now, even the most sophisticated supercomputers are built using microprocessors.

</aside>

<h3 id="145-binary-addition">1.4.5 Binary Addition</h3>
<aside>
📖 **Important takeaways**

- **Overflow**

    Digital system usually operate on a fixed number of digits. Addition is said to ***overflow*** if the result is too big to fit in the available digits. A 4-bit number, for example, has the range $[0,15]\,$. 4-bit binary addition overflows if the result exceeds 15. The fifth bit is discarded, producing an incorrect result in the remaining four bits. Overflow can be detected by checking for a carry out of the most significant column.

    $$
    \begin{align*}1101_2+0101_2&=10010_2\\7+5&=12\end{align*}
    $$

    **This result overflows the range of a 4-bit binary number**.

</aside>

<h3 id="146-signed-binary-numbers">1.4.6 Signed Binary Numbers(!!!)</h3>
<aside>
📖 **Important takeaways**

- **Lead in**

    So far, we have considered only ***unsigned binary numbers*** that represent positive quantities. We will often want to represent both positive and negative numbers, requiring a different binary number system. Several schemes exist to represent signed binary number; the two most widely employed are called **sign/magnitude** and **two’s complement**.

- **Sign/Magnitude Numbers(Not very good)**
    - Sign/magnitude numbers are intuitively appealing because they match our custom of writing negative numbers with a minus sign followed by the magnitude.
    - An $N$-bit sign/magnitude number uses the most significant bit as the sign and the remaining $N-1\,$bits as the magnitude(absolute value). A sign bit of $0$ indicates positive and a sign bit of $1\,$indicates negative.
    - Unfortunately, **ordinary binary addition does not work for sign/magnitude numbers**. For example, using ordinary addition on $-5_{10}+5_{10}\,$gives

        $$
        \begin{align*}1101_{2}+0101_{2}&=10010_{2}\\-5_{10}+5_{10}&=-2_{10}\end{align*}
        $$

        , which is nonsense.

    - An $N$-bit sign/magnitude number spans the range $[-2^{N-1}+1,2^{N-1}-1]\,$. **Sign/magnitude numbers are slightly odd in that both $+0\,$and $-0\,$exist**. Both indicating zero. As you may expect, it can be troublesome to have two different representations for the same number.
- **Two’s Complement Numbers(Much better)**
    - Two’s complement numbers are identical to unsigned binary numbers **except that the most significant bit position has a weight of $-2^{N-1}\,$instead of$\,2^{N-1}\,$**. They overcome the shortcomings of sign/magnitude numbers: **zero has a single representation, and ordinary addition works**.
    - In two’s complement representation:
        - Zero is written as all zeros: $00\cdots000_2\,$.
        - The most positive number has a $0\,$in the most significant position and $1$’s elsewhere: $\underbrace{01\cdots 111}_{N \,\text{digits}}{\scriptscriptstyle{2}}=2^{N-1}-1$.
        - The most negative number has a $1\,$in the most significant position and $0$’s elsewhere: $\underbrace{10\cdots 000}_{N \,\text{digits}}{\scriptscriptstyle{2}}=-2^{N-1}$.
    - Notice that positive numbers have a $0\,$in the most significant position and negative numbers have a $1\,$in this position, so **the most significant bit can be viewed as the sign bit**.
    - The two’s complement of $0\,$is found by inverting all the bits(producing $\underbrace{11\cdots 111}_{N \,\text{digits}}{\scriptscriptstyle{2}}$) and adding $1$, which produces all $0$’s, **disregarding the carry out of the most significant bit position**. Hence, zero is always represented with all $0$’s.
    - Unlike the sign/magnitude system, the two’s complement system has no separate $-0$. Zero is **considered** positive because its sign bit is $0$.
    - The range of an $N$-bit two’s complement number spans $[-2^{N-1},2^{N-1}-1]$. It should make sense that there is one more negative number than positive number($0\,$not included) because there is no $-0\,$.
- **Taking the two’s complement(!!!)**
    - **The sign** of a two’s complement number is **reversed** in a process called ***taking the two’s complement***. The process consists of **inverting all of the bits** in the number, then **adding $1\,$to the least significant bit position**(**disregarding the carry out of the most significant bit position**). This is useful to find the representation of a negative number or to determine the magnitude of a negative number.
        - Examples
            - Find the representation of $-2_{10}\,$as a $4$-bit two’s complement number.

                $$
                0010_2\xRightarrow[\text{all the bits}]{\text{inverting }}1101_2\xRightarrow[\text{disregard the carry out of the msb}]{\text{add one}}1110_2=-2_{10}
                $$

            - Find the decimal value of the two’s complement number $1001_2\,$.(**We can take the two’s complement of a negative number as well**)

                $$
                -7_{10}=1001_2\xRightarrow[\text{all the bits}]{\text{inverting }}0110_2\xRightarrow[\text{disregard the carry out of the msb}]{\text{add one}}0111_2=7_{10}
                $$

            - Compute$\,-2_{10}+1_{10}\,$and $-7_{10}+7_{10}\,$using two’s complement numbers.

                > **When adding $N$-bit numbers, the carry out of the $N$th bit is discarded.**
                > 

                $$
                \begin{align*}-2_{10}+1_{10}&=1110_{2}+0001_{2}=1111_{2}=-1_{10}\\-7_{10}+7_{10}&=1001_{2}+0111_{2}=0000_{2}=0_{10}\end{align*}
                $$

    - **Subtraction is performed by taking the two’s complement of the second number, then adding**.
        - Compute$\,5_{10}-3_{10}\,$and $3_{10}-5_{10}\,$using two’s complement numbers.

            $$
            \begin{align*}5_{10}-3_{10}&=0101_{2}-0011_{2}=0101_2+1101_2=0010_2=2_{10}\\3_{10}-5_{10}&=0011_{2}-0101_{2}=0011_{2}+1011_2=1110_2=-2_{10}\end{align*}
            $$

- **Overflow(!!!)**
    - Adding two $N$-bit positive numbers or negative numbers may cause overflow if the result is greater than $2^{N-1}-1\,$or less than $-2^{N-1}\,$. **Adding** a **positive** number to a **negative** number **never causes overflow**.
    - **Unlike unsigned numbers, a carry out of the most significant column does not indicate overflow**.

        $$
        -1_{10}+7_{10}=1111_2+0111_2=0110_2=6_{10}
        $$

    - Overflow occurs if the **two numbers being added** have the **same sign bit** and the **result** has the **opposite sign bit**.
        - Example
            - Compute$\,4_{10}+5_{10}\,$using $4$-bit two’s complement numbers. Does the result overflow?

                $$
                4_{10}+5_{10}=0100_2+0101_2=1001_2=-7_{10}
                $$

                The result overflows the range of $4$-bit positive two’s complement numbers, producing an incorrect negative result. If the computation had been done using five or more bits, the result would have been correct.

                $$
                4_{10}+5_{10}=00100_2+00101_2=01001_2=9_{10}
                $$

- **Sign extension(!!!)**
    - When a two’s complement number is extended to more bits, the sign bits must be **copied** into the most significant bit position**s**. This process is called ***sign extension***.
    - For example, the number $3\,$and $-3\,$are written as $4$-bit two’s complement numbers $0011\,$and $1101$, respectively. They are **sign-extended to seven bits** by **copying** the sign bit into the **three new upper bits** to form $0000011\,$and $1111101$, respectively.

        $$
        \begin{align*}3_{10}&=0011_2=0000011_2\\-3_{10}&=1101_2=1111101_2\end{align*}
        $$

</aside>

<h2 id="15-logic-gates">1.5 Logic Gates</h2>
<aside>
📖 **Important takeaways**

- ***Logic gates*** are simple **digital circuits** that take **one or more binary inputs** and produce **a binary output**.
- Logic gates are drawn with a symbol showing the input(or inputs) and the output. Inputs are usually drawn on the left(or top) and outputs on the right(or bottom).
- Digital designers typically use **letters near the beginning of the alphabet** for **gate inputs** and the letter $Y\,$for the **gate output**.
- The relationship between the inputs and the output can be described with a truth table or a Boolean equation.
- A truth table lists inputs on the left and the corresponding output on the right. It has **one row** for **each possible combination of inputs**.
- A Boolean equation is a mathematical expression using binary variables.
</aside>

<h3 id="151-not-gate">1.5.1 NOT Gate</h3>
<ul>
<li>
<p><strong>Visualization</strong></p>
<ol>
<li>The <strong>triangle symbol</strong> indicates a <strong>buffer</strong>.</li>
<li><strong>A circle on the output</strong> is called a <strong>bubble</strong> and indicates <strong>inversion</strong>, as was seen in the NOT gate symbol. </li>
</ol>
<p><img alt="Screenshot 2023-01-18 at 15.25.31.png" src="Screenshot_2023-01-18_at_15.25.31.png" /></p>
</li>
<li>
<p><strong>Explanation</strong></p>
<p><img alt="Screenshot 2023-01-18 at 15.25.15.png" src="Screenshot_2023-01-18_at_15.25.15.png" /></p>
</li>
</ul>
<h3 id="152-bufferit-copies-the-input-to-the-output">1.5.2 Buffer(It copies the input to the output)</h3>
<ul>
<li>
<p><strong>Visualization</strong></p>
<p><img alt="Screenshot 2023-01-18 at 15.32.15.png" src="Screenshot_2023-01-18_at_15.32.15.png" /></p>
</li>
<li>
<p><strong>Explanation</strong></p>
<p><img alt="Screenshot 2023-01-18 at 15.32.53.png" src="Screenshot_2023-01-18_at_15.32.53.png" /></p>
</li>
</ul>
<h3 id="153-and-gateyab">1.5.3 AND Gate(Y=AB)</h3>
<ul>
<li>
<p><strong>Visualization</strong></p>
<p><img alt="Screenshot 2023-01-18 at 15.37.32.png" src="Screenshot_2023-01-18_at_15.37.32.png" /></p>
</li>
<li>
<p><strong>Explanation</strong></p>
<p><img alt="Screenshot 2023-01-18 at 15.37.20.png" src="Screenshot_2023-01-18_at_15.37.20.png" /></p>
</li>
</ul>
<h3 id="154-or-gateyab">1.5.4 OR Gate(Y=A+B)</h3>
<ul>
<li>
<p><strong>Visualization</strong></p>
<p><img alt="Screenshot 2023-01-18 at 15.38.30.png" src="Screenshot_2023-01-18_at_15.38.30.png" /></p>
</li>
<li>
<p><strong>Explanation</strong></p>
<p><img alt="Screenshot 2023-01-18 at 15.38.40.png" src="Screenshot_2023-01-18_at_15.38.40.png" /></p>
</li>
</ul>
<h3 id="155-other-two-input-gatesxor-nand-nor-xnor">1.5.5 Other Two-Input Gates(XOR, NAND, NOR, XNOR)</h3>
<ul>
<li>
<p><strong>Visualization</strong></p>
<p><img alt="Screenshot 2023-01-18 at 15.42.46.png" src="Screenshot_2023-01-18_at_15.42.46.png" /></p>
<p><img alt="Screenshot 2023-01-18 at 15.50.18.png" src="Screenshot_2023-01-18_at_15.50.18.png" /></p>
<p><img alt="Screenshot 2023-01-18 at 15.50.32.png" src="Screenshot_2023-01-18_at_15.50.32.png" /></p>
</li>
<li>
<p><strong>Explanation</strong></p>
<p><aside>
📖 An $N$-input <strong>XOR gate</strong> is sometimes called a <strong>parity gate</strong> and produces a <strong>TRUE output</strong> <strong>if an odd number of inputs are TRUE</strong>.</p>
</aside>
<p><aside>
📖 The <strong>two-input XNOR gate</strong> is sometimes called an <strong>equality gate</strong> because its <strong>output is TRUE when the inputs are equal</strong>.</p>
</aside>
<p><img alt="Screenshot 2023-01-18 at 15.42.32.png" src="Screenshot_2023-01-18_at_15.42.32.png" /></p>
</li>
</ul>
<h3 id="156-multiple-input-gatesand-or-xor-nand-nor-xnor">1.5.6 Multiple-Input Gates(AND, OR, XOR, NAND, NOR, XNOR)</h3>
<ul>
<li>
<p><strong>Explanation</strong></p>
<p><aside>
📖 Many Boolean functions of three or more inputs exist. The most common are AND, OR, XOR, NAND, NOR, and XNOR. An $N$-input AND gate produces a TRUE output when all $N\,$inputs are TRUE. An $N$-input OR gate produces a TRUE output when at least one input is TRUE.</p>
</aside>
</li>
<li>
<p><strong>Visualization</strong></p>
<p><img alt="Screenshot 2023-01-18 at 15.56.25.png" src="Screenshot_2023-01-18_at_15.56.25.png" /></p>
<p><img alt="Screenshot 2023-01-18 at 15.56.37.png" src="Screenshot_2023-01-18_at_15.56.37.png" /></p>
<p><img alt="Screenshot 2023-01-18 at 15.56.04.png" src="Screenshot_2023-01-18_at_15.56.04.png" /></p>
<p><img alt="Screenshot 2023-01-18 at 15.56.18.png" src="Screenshot_2023-01-18_at_15.56.18.png" /></p>
</li>
</ul>
<h1 id="2-combinational-logic-design">2 Combinational Logic Design</h1>
<h2 id="20-exercises">2.0 Exercises</h2>
<p><a href="Exercises%202%20Checklist%204b2fba53abf840e59c03a948aa131dbe.csv">Exercises 2 Checklist</a></p>
<h2 id="21-introduction">2.1 Introduction(!!!)</h2>
<aside>
📖 **Circuit**

- In digital electronics, a ***circuit*** is a ***network that processes discrete-valued variables***.
- A circuit can be viewed as a black box, with
    1. one or more discrete-valued input terminals
    2. one or more discrete-valued output terminals
    3. a functional specification describing the relationship between inputs and outputs
    4. a timing specification describing the delay between inputs changing and outputs responding
- **Digital circuits** are classified as **combinational** or **sequential**. A combinational circuit is memoryless, but a sequential circuit has memory.
    1. A **combinational circuit’s outputs** **depend** only on the **current values of the inputs**; in other words, it combines the current input values to compute the output. For example, **a logic gate is a combinational circuit**.
    2. A **sequential circuit’s outputs depend** on both current and precious values of the inputs; in other words, it depends on the **input sequence**.
- The functional specification of a combinational circuit **expresses the output** values **in terms of the** current **input** values.
- The timing specification of a combinational circuit consists of lower and upper bounds on the delay from input to output.
</aside>

<aside>
📖 **Element, Node**

- Peering inside the black box, **circuits are composed of nodes and elements**.
- **An element is itself a circuit** with inputs, outputs, and a specification.(Recursive)
- A node is a wire, whose voltage conveys a discrete-valued variable. Nodes are classified as input, output, or internal.
    - Inputs receive values from the external world.
    - Outputs deliver values to the external world.
    - Wires that are not inputs or outputs are called internal nodes.
</aside>

<aside>
📖 **The rules of combinational composition**

- A circuit is combinational if it consists of interconnected circuit elements such that
    - Every circuit element is itself combinational.
    - Every node of the circuit is either designated as an input to the circuit or **connects to exactly one output terminal** of a circuit element.**(!!!)**
    - The circuit contains no cyclic paths: every path through the circuit visits each circuit node at most once.
- The rules of combinational composition are sufficient but not strictly necessary. Certain circuits that disobey these rules are still combinational, so long as the outputs depend only on the current values of the inputs. However, determining whether oddball circuits are combinational is more difficult, so we will usually restrict ourselves to combinational composition as a way to build compositional circuits.
- **Example**

    ![Screenshot 2023-01-18 at 17.06.01.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-18_at_17.06.01.png)

    ![Screenshot 2023-01-18 at 17.06.11.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-18_at_17.06.11.png)


</aside>

<p><img alt="Screenshot 2023-01-18 at 16.28.48.png" src="Screenshot_2023-01-18_at_16.28.48.png" /></p>
<p><img alt="Screenshot 2023-01-18 at 16.40.36.png" src="Screenshot_2023-01-18_at_16.40.36.png" /></p>
<aside>
📖 **Explanation**

- Figure 2.3 shows a combinational circuit with two inputs(A, B) and one output(Y).
- In this example, the function F is specified to be OR:

    $$
    Y=F(A,B)=A+B
    $$

    The output Y is a function of the two inputs, A and B, namely 

    $$
    Y=A\space\space  \mathrm{OR}\space\space B
    $$

</aside>

<p><img alt="Screenshot 2023-01-18 at 16.29.11.png" src="Screenshot_2023-01-18_at_16.29.11.png" /></p>
<aside>
📖 **Explanation**

- Figure 2.2 illustrates a circuit with three elements, E1, E2, and E3, and six nodes(A, B, C, n1, Y, Z).
    - Nodes A, B and C are inputs.
    - Y and Z are outputs.
    - n1 is an internal node(wire) between E1 and E3.
</aside>

<h2 id="22-boolean-equationshow-to-write-a-boolean-expression-given-a-truth-table">2.2 Boolean Equations(How to write a Boolean expression given a truth table!!!)</h2>
<h3 id="221-terminology">2.2.1 Terminology(!!!)</h3>
<aside>
📖 **Important takeaways**

- **complement**
    - The complement of a variable $A\,$is its inverse $\overline{A}\,$.
- **literal**
    - The variable or its complement is called a literal.
    - For example, $A,\overline{A},B,\overline{B}\,$are literals.
- **True form and complementary form**
    - We call $A\,$the true form of the variable and $\overline{A}\,$the complementary form.
    - True form does not mean that $A\,$is True, but merely that A does not have a line over it.
- **The order of operations**
    - The order of operations is important when interpreting Boolean equations.
    - In Boolean equations, NOT has the highest precedence, followed by AND, then OR.
    - Just as in ordinary equations, products are preforms before sums.
    - $\overline{A}B+BC\overline{D}=((\overline{A})B)+(BC{(\overline{D})})$

- **Product or implicant**
    - The **AND** of one or more literals is called a product or an implicant.
    - $A\overline{B},A\overline{B}\overline{C},\,$and $B\,$are all implicants for a function of three variables.
- **minterm**
    - A **minterm** is a **product** **involving all the inputs** to the function.
    - $A\overline{B}\overline{C}\,$is a minterm for a function of the three variables $A,B,\,$and $C,\,$but $\overline{A}B\,$is not, because it does not involve $C\,$.
- **Sum**
    - The **OR** of one or more literals is called a sum.
- **maxterm**
    - A **maxterm** is a **sum** **involving all of the inputs** to the function.
    - $A+\overline{B}+\overline{C}\,$is a maxterm for a function of the three variables $A,B,\,$and $C\,$.
</aside>

<h3 id="222-sum-of-products-form">2.2.2 Sum-of-Products Form(!!!)</h3>
<aside>
📖 **Important takeaways**

- A truth table of $N\,$inputs contains $2^N\,$rows, one for each possible value of the inputs.
- Each row in a truth table is associated with a minterm that is TRUE for that row.
- The minterm for the first row is $\overline{A}\,\overline{B}\,$because $\overline{A}\,\overline{B}\,$is TRUE when $A=0,B=0\,$.
- The minterms are numbered starting with $0$; the top row corresponds to minterm $0,\,$$m_0,\,$the next row to minterm $1,\,$$m_1,\,$and so on.

![Screenshot 2023-01-20 at 11.07.32.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_11.07.32.png)

![Screenshot 2023-01-20 at 11.08.46.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_11.08.46.png)

- We can write a Boolean equation for any truth table by **summing each of the minterms for which the output, $Y$, is TRUE**.
- For Figure 2.8, $Y=\overline{A}B\,$. For Figure 2.9, $Y=\overline{A}B+AB\,$.
- This is called the sum-of-products canonical form(standard form) of a function because it is sum(OR) of products(ANDs forming minterms).
- The sum-of-products canonical form can also be written in sigma notation using the summation symbol, $\Sigma\,$. With this notation, the function from Figure 2.9 would be written as

    $$
    Y=F(A,B)=\Sigma(m_1,m_3)=\Sigma(1,3)
    $$

- **每个最小项成1的方法只有一种，因此为了最终结果是1，必须使用或连接各个最小项。**
- **Sum-of-products produces a shorter equation when the output(Y) is TRUE on only a few rows of a truth table; product-of-sums is simpler when the output(Y) is FALSE on only a few rows of a truth table.**
- **Example**


    ![Screenshot 2023-01-20 at 11.19.53.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_11.19.53.png)

    ![Screenshot 2023-01-20 at 11.24.34.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_11.24.34.png)

    ![Screenshot 2023-01-20 at 11.20.11.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_11.20.11.png)

    ![Screenshot 2023-01-20 at 11.19.39.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_11.19.39.png)

    ![Screenshot 2023-01-20 at 11.24.01.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_11.24.01.png)

</aside>

<h3 id="223-product-of-sums-form">2.2.3 Product-of-Sums Form(!!!)</h3>
<aside>
📖 **Important takeaways**

- An alternative way of expressing Boolean functions is the product-of-sums canonical form(standard form).
- Each row of the truth table corresponds to a maxterm that is FALSE for that row.
- For example, the maxterm for the first row of a two-input truth table is $(A+B)\,$because $(A+B)\,$is FALSE when $A=0,B=0\,$.
- We can write a Boolean equation for any circuit directly from the truth table as the **AND of each of the maxterms** for which **the output is FALSE**.
- The product-of-sums canonical form can also be written in pi notation using the product simple, $\Pi$.
- Similarly, a Boolean equation for Ben’s picnic from Figure 2.10 can be written in product-of-sums form by circling the three rows of $0$’s to obtain

    $$
    E=(A+\overline{R})(\overline{A}+R)(\overline{A}+\overline{R})
    $$


![Screenshot 2023-01-20 at 11.36.50.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_11.36.50.png)

- **每个最大项成0的方法只有一种，因此为了最终结果是0，必须使用和连接各个最大项。**
- **Sum-of-products produces a shorter equation when the output(Y) is TRUE on only a few rows of a truth table; product-of-sums is simpler when the output(Y) is FALSE on only a few rows of a truth table.**
</aside>

<h2 id="23-boolean-algebrato-simplify-boolean-equations">2.3 Boolean Algebra(To simplify Boolean equations!!!)</h2>
<h3 id="230-background">2.3.0 Background</h3>
<aside>
📖 **Background**

- In the previous section, we learned how to write a Boolean expression given a truth table.
- However, the expression does not necessarily lead to the simplest set of logic gates.
- Just as you use algebra to simplify mathematical equations, you can use Boolean algebra to simplify Boolean equations.
- The rules of Boolean algebra are much like those of ordinary algebra but are in some cases simpler, because variables have only two possible values, 0 or 1.

- Boolean algebra is based on a set of axioms that we assume are correct.
- **Axions are unprovable** in the sense that a definition cannot be proved. From these axioms, we prove all the theorems of Boolean algebra. **These theorems have great practical significance, because they teach us how to simplify logic to produce smaller and less costly circuits**.
- Axioms and theorems of Boolean algebra obey the principle of duality. If the symbols 0 and 1 **and** the operators $\bullet$(AND) and $+$(OR) are interchanged, the statement will still be correct. We use the prime symbol($\,^\prime\,$) to denote the dual. of a statement

![Screenshot 2023-01-20 at 12.00.23.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_12.00.23.png)

</aside>

<h3 id="231-axioms">2.3.1 Axioms</h3>
<p><img alt="Screenshot 2023-01-20 at 12.00.23.png" src="Screenshot_2023-01-20_at_12.00.23%201.png" /></p>
<h3 id="232-theorems-of-one-variable">2.3.2 Theorems of One Variable</h3>
<aside>
📖 **Important takeaways**

![Screenshot 2023-01-20 at 13.16.58.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_13.16.58.png)

![Screenshot 2023-01-20 at 13.17.10.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_13.17.10.png)

![Screenshot 2023-01-20 at 13.17.19.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_13.17.19.png)

![Screenshot 2023-01-20 at 13.17.35.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_13.17.35.png)

![Screenshot 2023-01-20 at 13.17.55.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_13.17.55.png)

![Screenshot 2023-01-20 at 13.17.47.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_13.17.47.png)

- **The identity theorem, T1**
    - T1 means that if one input of a two-input AND gate is always 1, we can remove the AND gate and replace it with a wire connected to the variable input(B). Likewise, T1’ means that if one input of a two-input OR gate is always 0, we can replace the OR gate with a wire connected to B.
    - In general, gates cost money, power, and delay, so replacing a gate with a wire is beneficial.
- **The null element theorem, T2**
    - 0 is called the null element for the AND operation.
    - 1 is the null element for the OR operation.
- **Idempotency, T3**
    - idem(same), and potent(power).
    - A variable AND itself is equal to just itself.
    - Idempotency again permits replacing a gate with a wire.
- **Involution, T4**
    - Complementing a variable twice results in the original variable.
    - Two inverters in series logically cancel each other out and are logically equivalent to a wire.
- **The complement theorem, T5**
    - A variable AND its complement is 0.
    - A variable OR its complement is 1.
</aside>

<h3 id="233-theorems-of-several-variables">2.3.3 Theorems of Several Variables</h3>
<aside>
📖 **Important takeaways**

![Screenshot 2023-01-20 at 13.40.28.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_13.40.28.png)

- **Covering, T9**

    $$
    \begin{align*}B\bullet(B+C)&=(B+0)\bullet(B+C)\\&=B+(0\bullet C)\\&=B+0\\&=B\end{align*}
    $$

    $$
    \begin{align*}B+(B\bullet C)&=(B\bullet1)+(B\bullet C)\\&=B\bullet(1+C)\\&=B\bullet 1\\&=B\end{align*}
    $$


- **Combining, T10**

    $$
    \begin{align*}(B\bullet C)+(B\bullet \overline{C})&=B\bullet(C+\overline{C})\\&=B\bullet 1\\&=B\end{align*}
    $$

    $$
    \begin{align*}(B+C)\bullet(B+ \overline{C})&=B+(C\bullet\overline{C})\\&=B+0\\&=B\end{align*}
    $$

- **Consensus, T11**

    $$
    \begin{align*}(B\bullet C)+(\overline{B}\bullet D)+(C\bullet D)&=(B\bullet C)+(\overline{B}\bullet D)+(B+\overline{B})\bullet(C\bullet D)\\&=B\bullet C+\overline{B}\bullet D+B\bullet C\bullet D+\overline{B}\bullet C\bullet D\\&=B\bullet C\bullet(1+D)+\overline{B}\bullet D\bullet(1+C)\\&=B\bullet C+\overline{B}\bullet D\end{align*}
    $$

    $$
    \begin{align*}(B+C)\bullet(\overline{B}+ D)\bullet(C+D)&=(B+C)\bullet(\overline{B}+ D)\bullet\Big((B\bullet \overline{B})+(C+D)\Big)\\&=(B+C)\bullet(\overline{B}+ D)\bullet(B+C+D)\bullet(\overline{B}+C+D)\\&=\Big((B+C)+(0\bullet D)\Big)\bullet\Big((\overline{B}+D)+(0\bullet C)\Big)\\&=(B+C)\bullet(B+D)\end{align*}
    $$

- **De Morgan’s Theorem, T12**


    > The complement of the product of all the terms is equal to the sum of the complement of each term
    > 
    1. If $x\in\overline{B_0\bullet B_1\bullet B_2\cdots}\,$, then $x\notin B_0\bullet B_1\bullet B_2\cdots\,$, then $x\notin B_0\,\text{or}\,x\notin B_1\,\text{or}\,x\notin B_2\,\text{or}\cdots\,$, then $\,x\in \overline{B_0}\,\text{or}\,x\in \overline{B_1}\,\text{or}\,x\in \overline{B_2}\,\text{or}\cdots\,$.
    2. Thus, $\,x\in \overline{B_0}+\overline{B_1}+\overline{B_2}+\cdots\,$.
    3. If $x\in \overline{B_0}+\overline{B_1}+\overline{B_2}+\cdots\,$, then $\,x\in \overline{B_0}\,\text{or}\,x\in \overline{B_1}\,\text{or}\,x\in \overline{B_2}\,\text{or}\cdots\,$, then $x\notin B_0\,\text{or}\,x\notin B_1\,\text{or}\,x\notin B_2\,\text{or}\cdots\,$, then $x\notin B_0\bullet B_1\bullet B_2\cdots$.
    4. Thus, $x\in \overline{B_0\bullet B_1\bullet B_2\cdots}\,$.

    > The complement of the sum of all the terms is equal to the product of the complement of each term.
    > 
    1. If $x\in\overline{B_0+ B_1+ B_2\cdots}\,$, then $x\notin B_0+B_1+B_2+\cdots\,$, then $x\notin B_0 \,\text{and}\,x\notin B_1 \,\text{and}\,x\notin B_2 \,\text{and}\cdots\,$, then $x\in \overline{B_0} \,\text{and}\,x\in \overline{B_1} \,\text{and}\,x\in \overline{B_2} \,\text{and}\cdots\,$
    2. Thus $x\in \overline{B_0}\bullet\overline{B_1}\bullet\overline{B_2}\cdots\,$.
    3. If $x\in \overline{B_0}\bullet\overline{B_1}\bullet\overline{B_2}\cdots\,$, then $x\in \overline{B_0} \,\text{and}\,x\in \overline{B_1} \,\text{and}\,x\in \overline{B_2} \,\text{and}\cdots\,$, then $x\notin B_0 \,\text{and}\,x\notin B_1 \,\text{and}\,x\notin B_2 \,\text{and}\cdots\,$, then $x\notin B_0+B_1+B_2+\cdots\,$
    4. Thus $x\in\overline{B_0+ B_1+ B_2\cdots}\,$.

    - According to De Morgan’s theorem, a NAND gate is equivalent to an OR gate with inverted inputs.
    - Similarly, a NOR gate is equivalent to an AND gate with inverted inputs.
    - **The inversion circle is called a bubble**.
    - Intuitively, you can imagine that “pushing” a bubble through the gate causes it to **come out at the other side** and **flips the body of the gate** from AND to OR or vice versa
    - The underlying rules for bubble pushing are:
        1. Pushing bubbles backward(from the output) or forward(from the inputs) changes the body of the gate from AND to OR or vice versa.
        2. Pushing **a bubble** **from the output back to the inputs** puts **bubbles on all** gate **inputs**.
        3. Pushing bubbles on **all gate inputs forward** **toward the output** puts **a bubble** on the **output**.

    ![Screenshot 2023-01-20 at 14.37.47.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-20_at_14.37.47.png)

- **Example**

    Figure 2.20 shows the truth table for a Boolean function $Y\,$and its complement $\overline{Y}\,$. Using De Morgan’s Theorem, derive the product-of-sums canonical form of $Y\,$from the sum-of-products form of $\overline{Y}\,$.

    - sum-of-products form of $\overline{Y}\,$:

        $$
        \overline{Y}=\overline{A}\,\overline{B}+\overline{A}B
        $$

    - product-of-sums form of $\overline{Y}\,$:

        $$
        \overline{Y}=(\overline{A}+B)(\overline{A}+\overline{B})
        $$


    - sum-of-products form of $Y\,$:

        $$
        Y=A\overline{B}+AB
        $$

    - product-of-sums form of $Y\,$:

        $$
        Y=(A+B)(A+\overline{B})
        $$

    - De Morgan’s Theorem:

        $$
        Y=\overline{\overline{Y}}=\overline{\overline{A}\,\overline{B}+\overline{A}B}=\overline{\overline{A}\,\overline{B}}\,\overline{\overline{A}B}=(A+B)(A+\overline{B})
        $$

        $$
        Y=\overline{\overline{Y}}=\overline{(\overline{A}+B)(\overline{A}+\overline{B})}=\overline{\overline{A}+B}+\overline{\overline{A}+\overline{B}}=A\overline{B}+AB
        $$


    ![Screenshot 2023-01-21 at 09.06.39.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_09.06.39.png)

    ![Screenshot 2023-01-21 at 09.06.48.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_09.06.48.png)

</aside>

<h3 id="234-the-truth-behind-it-all">2.3.4 The Truth Behind It All</h3>
<aside>
📖 **Important takeaways**

- In Boolean algebra, proofs of theorems with a finite number of variables are easy: just show that the theorem holds for all possible values of these variables. **This method is called perfect induction and can be done with a truth table**.
- **Example**


    ![Screenshot 2023-01-21 at 09.24.25.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_09.24.25.png)

    ![Screenshot 2023-01-21 at 09.26.09.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_09.26.09.png)

    ![Screenshot 2023-01-21 at 09.25.05.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_09.25.05.png)

</aside>

<h3 id="235-simplifying-equations">2.3.5 Simplifying Equations</h3>
<aside>
📖 **Important takeaways**

- The theorems of Boolean algebra help us simplify Boolean equations. In general, multiple steps may be necessary to simplify more complex equations.
- The basic principle of simplifying sum-of-products equations is to combine terms using the relationship $PA+P\overline{A}=P(A+\overline{A})=P\bullet1=P\,$, where $P\,$may be any implicant.
- We define an equation in sum-of-products form to be minimized if it uses the fewest possible implicants.
- If there are several equations with the same number of implicants, the minimal one is the one with the fewest literals.
- An implicant is called a prime implicant if it cannot be combined with any other implicants in the equation to form a new implicant with fewer literals.
- The implicants in a minimal equation must all be prime implicants. Otherwise, they could be combined to reduce the number of literals.

![Screenshot 2023-01-21 at 09.40.41.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_09.40.41.png)

![Screenshot 2023-01-21 at 09.41.04.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_09.41.04.png)

![Screenshot 2023-01-21 at 09.41.18.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_09.41.18.png)

- Completely simplifying a Boolean equation with the theorems of Boolean algebra can take some trial and error. Section 2.7 describes a methodical technique called Karnaugh maps that make the process easier.
- Why bother simplifying a Boolean equation if it remains logically equivalent? **Simplifying reduces the number of gates used to physically implement the function, thus making it smaller, cheaper, and possibly faster**.
</aside>

<h2 id="24-from-logic-to-gates">2.4 From Logic To Gates</h2>
<aside>
📖 **Important takeaways**

- A schematic is a diagram of a digital circuit showing the elements and the wires that connect them together.

- By drawing schematics in a consistent fashion, we make them easier to read and debug. We will generally obey the following guidelines:
    - Inputs are on the left(or top) side of a schematic.
    - Outputs are on the right(or bottom) side of a schematic.
    - Whenever possible, gates should flow from left to right.
    - Straight wires are better to use than wires with multiple corners(jagged wires waste mental effort following the wire rather than thinking of what the circuit does).
    - Wires always connect at a T junction.
    - A dot where wires cross indicates a connection between the wires.
    - Wires crossing without a dot make no connection.
- Any Boolean equation in sum-of-products form can be drawn as a schematic in a systematic way similar to Figure 2.23.
    - First, draw columns for the inputs. Place inverters in adjacent columns to provide the complement inputs if necessary.
    - Draw rows of AND gates for each of the minterms.
    - Then, for each output, draw an OR gate connected to the minterms related to that output.

    > This style is called a programmable logic array(PLA) because the inverters, AND gates, and OR gates are arrayed in a systematic fashion.
    > 
- We can reduce the number of gates even further(albeit by a single inverter) by taking advantage of inverting gates.
    - Observe that $\overline{B}\,\overline{C}\,$is an AND with inverted inputs. Figure 2.26 shows a schematic using this optimization to elimininate the inverter on $C\,$.
    - Recall that by De Morgans’s theorem the AND with inverted inputs is equivalent to a NOR gate(pushing the bubbles).

        $$
        \overline{A}\,\overline{B}=\overline{A+B}\space(\mathrm{NOR})
        $$

    - Depending on the implementation technology, it may be cheaper to use the fewest gates or to use certain types of gates in preference to others.
    - For example, NANDs and NORs are preferred over ANDs and ORs in CMOS implementations.
- **Example: Multiple-output circuits(four-input priority circuit)**

    ![Screenshot 2023-01-21 at 11.43.20.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_11.43.20.png)

    - **Slower approach**
        - Write each output in sum-of-products form and reduce the equations using Boolean algebra

            $$
            \begin{align*}Y_3&=A_3\overline{A_2}\,\overline{A_1}\,\overline{A_0}+A_3\overline{A_2}\,\overline{A_1}A_0+A_3\overline{A_2}A_1\overline{A_0}+A_3\overline{A_2}A_1A_0\\&+A_3A_2\overline{A_1}\,\overline{A_0}+A_3A_2\overline{A_1}A_0+A_3A_2A_1\overline{A_0}+A_3A_2A_1A_0\\&=A_3\overline{A_2}\,\overline{A_1}+A_3\overline{A_2}A_1+A_3A_2\overline{A_1}+A_3A_2A_1\\&=A_3\overline{A_2}+A_3A_2\\&=A_3\end{align*}
            $$

            $$
            \begin{align*}Y_2&=\overline{A_3}A_2\overline{A_1}\,\overline{A_0}+\overline{A_3}A_2\overline{A_1}A_0+\overline{A_3}A_2A_1\overline{A_0}+\overline{A_3}A_2A_1A_0\\&=\overline{A_3}A_2\overline{A_1}+\overline{A_3}A_2A_1\\&=\overline{A_3}A_2\end{align*}
            $$

            $$
            \begin{align*}Y_1&=\overline{A_3}\,\overline{A_2}A_1\overline{A_0}+\overline{A_3}\,\overline{A_2}A_1A_0\\&=\overline{A_3}\,\overline{A_2}A_1\end{align*}
            $$

            $$
            Y_0=\overline{A_3}\,\overline{A_2}\,\overline{A_1}A_0
            $$

    - **Faster approach**
        - The simplified equations are clear **by inspection from the functional description**(and the truth table): $Y_3\,$is TRUE whenever $A_3\,$is asserted, so $Y_3=A_3\,$. $Y_2\,$is TRUE if $A_2\,$is asserted and $A_3\,$is not asserted, so $Y_2=\overline{A_3}A_2\,$. $Y_1\,$is TRUE if $A_1\,$is asserted and neither of the higher priority inputs is asserted: $Y_1=\overline{A_3}\,\overline{A_2}A_1\,$. And $Y_0\,$is TRUE whenever $A_0\,$and no other input is asserted: $Y_0=\overline{A_3}\,\overline{A_2}\,\overline{A_1}A_0\,$.
        - An experienced designer can often implement a logic circuit by inspection. Given a clear specification, simply turn the words into equations and the equations into gates.
        - Notice that if $A_3\,$is asserted in the priority circuit, the outputs don’t care what the other inputs are. We use the symbol $\mathrm{X}\,$to describe inputs that the outputs doesn’t care about.
        - Figure 2.29 shows that the four-input priority circuit truth table becomes much smaller with don’t cares. From this truth table, we can easily read the Boolean equations in sum-of-products form **by ignoring inputs with X’s**. Don’t cares can also appear in truth table outputs.

![Screenshot 2023-01-21 at 10.01.09.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_10.01.09.png)

![Screenshot 2023-01-21 at 10.02.08.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_10.02.08.png)

![Screenshot 2023-01-21 at 10.01.41.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_10.01.41.png)

![Screenshot 2023-01-21 at 11.43.55.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_11.43.55.png)

![Screenshot 2023-01-21 at 11.44.39.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_11.44.39.png)

![Screenshot 2023-01-21 at 11.45.17.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_11.45.17.png)

![Screenshot 2023-01-21 at 11.45.45.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_11.45.45.png)

</aside>

<h2 id="25-multilevel-combinational-logic">2.5 Multilevel Combinational Logic(!!!)</h2>
<h3 id="250-background">2.5.0 Background</h3>
<aside>
📖 **Background**

Logic in sum-of-products form is called two-level logic because it consists of literals connected to a level of AND gates connected to a level of OR gates. **Designers often** build circuits **with more than two levels of logic gates**. These **multilevel combinational circuits** **may use less hardware than their two-level counterparts**. **Bubble pushing** is especially helpful in **analyzing and designing multilevel circuits**.

</aside>

<h3 id="251-hardware-reduction">2.5.1 Hardware Reduction(!!!)</h3>
<aside>
📖 **Important takeaways**

- Some logic functions require an **enormous amount of hardware** when **built using two-level logic**.
- A notable example is the XOR function of multiple variables.
- **Example: building a three-input XOR** using the two-level techniques we have studied so far.

    ![Screenshot 2023-01-21 at 13.37.08.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_13.37.08.png)

    $$
    Y=\overline{A}\,\overline{B}C+\overline{A}B\overline{C}+A\overline{B}\,\overline{C}+ABC
    $$

    Unfortunately, there is no way to simplify this equation into fewer implicants.


- **Smarter Approach**

    On the other hand, $A\oplus B\oplus C=(A\oplus B)\oplus C\,$.

    - Truth table(for reference)


        | $A$ | $B$ | $C$ | $A\oplus B\oplus C$ | $(A\oplus B)\oplus C$ |
        | --- | --- | --- | --- | --- |
        | 0 | 0 | 0 | 0 | 0 |
        | 0 | 0 | 1 | 1 | 1 |
        | 0 | 1 | 0 | 1 | 1 |
        | 0 | 1 | 1 | 0 | 0 |
        | 1 | 0 | 0 | 1 | 1 |
        | 1 | 0 | 1 | 0 | 0 |
        | 1 | 1 | 0 | 0 | 0 |
        | 1 | 1 | 1 | 1 | 1 |

    Therefore, the three-input XOR can be built out of a cascade of two-input XORs.

    Similarly, an eight-input XOR would require 128 eight-input AND gates and one 128-input OR gate for a two-level sum-of-products implementation.

    A much better option is to use a tree of two-input XOR gates.

    $$
    A\oplus B\oplus C\oplus D\oplus E\oplus F\oplus G\oplus H\\=((A\oplus B)\oplus(C\oplus D))\oplus((E\oplus F)\oplus(G\oplus H))
    $$

    ![Screenshot 2023-01-21 at 13.48.11.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_13.48.11.png)

    ![Screenshot 2023-01-21 at 13.53.54.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_13.53.54.png)

</aside>

<h3 id="252-bubble-pushing">2.5.2 Bubble Pushing(!!!)</h3>
<aside>
📖 **Important takeaways**

- Figure 2.33 shows a multilevel circuit whose function is not immediately clear by inspection.

    ![Screenshot 2023-01-21 at 14.03.13.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_14.03.13.png)

    $$
    \begin{align*}Y&=\overline{\overline{\overline{A+B}\bullet C}\bullet D}\\&=\overline{\overline{\overline{A}\bullet \overline{B}\bullet C}\bullet D}\\&=\overline{(A+B+\overline{C})\bullet D}\\&=\overline{A+B+\overline{C}}+\overline{D}\\&=\overline{A}\,\overline{B}C+\overline{D}\end{align*}
    $$

- **Bubble pushing is a helpful way to redraw these circuits so that the bubbles cancel out and the function can be more easily determined**.
- **(REVIEW!!!)**The underlying rules for bubble pushing are:
    1. Pushing bubbles backward(from the output) or forward(from the inputs) **changes the body of the gate from AND to OR or vice versa**.
    2. Pushing **a bubble** **from the output back to the inputs** puts **bubbles on all** gate **inputs**.
    3. Pushing bubbles on **all gate inputs forward** **toward the output** puts **a bubble** on the **output**.
- The guidelines or bubble pushing are as follows:
    - **Begin at the output of the circuit and work toward the inputs**.
    - **Push any bubbles on the final output** **back towards the inputs** so that you can read an equation in terms of the output($\,Y$), instead of the complement of the output ($\,\overline{Y}$).
    - Working backward, draw each gate in a form so that bubbles cancel. If the current gate has an input bubble, draw the preceding gate(the gate before) with an output bubble. If the current gate does not have an input bubble, draw the preceding gate without an output bubble.

![Screenshot 2023-01-21 at 14.16.59.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_14.16.59.png)

![Screenshot 2023-01-21 at 14.54.11.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_14.54.11.png)

![Screenshot 2023-01-21 at 14.54.44.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_14.54.44.png)

![Screenshot 2023-01-21 at 15.08.05.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_15.08.05.png)

</aside>

<h2 id="26-xs-and-zs-oh-my">2.6 X’s and Z’s, Oh My</h2>
<h3 id="261-illegal-value-x">2.6.1 Illegal Value: X</h3>
<aside>
📖 **Important takeaways**

- The **symbol X** indicates that **the circuit node has an unknown or illegal value**.
- This commonly happens if it is being driven to both 0 and 1 at the same time.
- Figure 2.39 shows a case where node Y is driven both HIGH and LOW. This situation, called contention, is considered to be an error and must be avoided.
- Contention can cause large amounts to power to flow between the fighting gates, resulting in the circuit getting hot and possibly damaged.
- X values are also sometimes used by circuit simulators to indicate an uninitialized value. For example, if you forget to specify the value of an input, the simulator may assume it is an X to warn you of the problem.
- Digital designers also use the symbol X to indicate “don’t care” values in truth tables. Be sure not to mix up the two meanings.
- When X appears in a truth table, it indicates that the value of the variable in the truth table is unimportant(can be either 0 or 1). When X appears in a circuit, it means that the circuit node has an unknown or illegal value.

![Screenshot 2023-01-21 at 15.17.36.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_15.17.36.png)

</aside>

<h3 id="262-floating-value-z">2.6.2 Floating Value: Z</h3>
<aside>
📖 **Important takeaways**

- The **symbol Z** indicates that a node is being driven neither HIGH nor LOW.
- The node is said to be floating, high impedance, or high Z.
- A typical misconception is that a floating or undriven node is the same as a logic 0. **In reality, a floating node might be 0, might be 1, or might be at some voltage in between, depending on the history of the system**.
- The tristate buffer, shown in Figure 2.40, has three possible output states: HIGH(1), LOW(0), and floating(Z). The tristate buffer has an input A, output Y, and enable E. When the enable is TRUE, the tristate buffer acts as a simple buffer, transferring the input value to the output. When the enable is FALSE, the output is allowed to float(Z).
- The tristate buffer in Figure 2.40 has an active high enable. That is, when the enable is HIGH(1), the buffer is enabled.
- Figure 2.41 shows a tristate buffer with an active low enable. When the enable is LOW(0), the buffer is enabled.
- We show that the signal is active low by putting a bubble on its input wire. We often indicate an active low input by drawing a bar over its name, $\overline{E}\,$, or appending the letters “b” or “bar” after its name, Eb or Ebar.
- Tristate buffers are commonly used on busses that connect multiple chips. For example, a microprocessor, a video controller, and an Ethernet controller might all need to communicate with the memory system in a personal computer. Each chip can connect to a shared memory bus using tristate buffers, as shown in Figure 2.42(en1, en2, en3, en4). Only one chip at a time is allowed to assert its enable signal to drive a value onto the bus. The other chips must produce floating inputs **so that they do not cause contention with the chip talking to the memory**. Any chip can **read** the information from the shared bus at any time.
- Such tristate busses were once common. However, in modern computers, higher speeds are possible with point-to-point links, in which chips are connected to each other directly rather than over a shared bus.

![Screenshot 2023-01-21 at 15.28.26.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_15.28.26.png)

![Screenshot 2023-01-21 at 15.28.52.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_15.28.52.png)

![Screenshot 2023-01-21 at 15.32.21.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_15.32.21.png)

</aside>

<h2 id="27-karnaugh-maps">2.7 Karnaugh Maps(!!!)</h2>
<h3 id="270-background">2.7.0 Background</h3>
<aside>
📖 **Background**

- After working through several minimizations of Boolean equations using Boolean algebra, you will realize that, if you are not careful, you sometimes end up with a completely different equation instead of a simplified equation.
- Karnaugh maps(K-maps) are a graphical method for simplifying equations. They were invented in 1953 by Maurice Karnaugh, a telecommunications engineer at Bell Labs.
- **K-maps work well for problems with up to four variables**. More important, they give insight into manipulating Boolean equations.
- **Gray code**
    - You may have noticed that the $A\,$and $B\,$combinations in the top row are in peculiar order: 00, 01, 11, 10. This order is called a Gray code.
    - It differs from ordinary binary order: $(00,01,10,11)\,$in that **adjacent entries differ only in a single variable**. Ordinary binary order doesn’t have this property($\,01\,$and $10\,$). Hence, writing the combinations in binary order would not have produced our desired property of adjacent squares differing only in one variable.
    - Gray codes were patented by Frank Gray, a Bell Labs reseacher, in 1953. They were especially useful in mechanical encoders because a slight misalignment causes an error in only one bit.
    - Gray codes generalize to any number of bits. For example, a 3-bit Gray code sequence is:



        $$
        000,001,011,010,110,111,101,100
        $$


![Screenshot 2023-01-21 at 17.19.59.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_17.19.59.png)

- Figure 2.43 shows the truth table and K-map for a three-input(A, B, C) function. **The top row of the K-map** gives the four possible values for the A and B inputs. **The left column** gives the two possible values for the C input.
- Each square in the K-map corresponds to a row in the truth table and contains the value of the output Y for that row. For example, the top left square corresponds to the first row in the truth table and indicates that the output value $Y=1\,$when $ABC=000\,$.
- Just like each row in a truth table, each square in a K-map represents a single minterm. For the purpose of explanation, Figure 2.43(c) shows the minterm corresponding to each square in the K-map.
- Each square, or minterm, **differs from an adjacent square** by **a change** in **a single variable**. This means that adjacent squares share all the same literals except one, which appears in true form in one square and in complementary form in the other. For example, the squares representing the minterm $\overline{A}\,\overline{B}\,\overline{C}\,$ and $\overline{A}\,\overline{B}C\,$are adjacent and differ only in the variable C.
- **Wrap around**
    - **The K-map also “wraps around.” The squares on the far right are effectively adjacent to the squares on the far left, in that they differ only in one variable, $A$**.
    - In other words, you could take the map and roll it into a cylinder, then join the ends of the cylinder to form a torus(i.e., a donut), and still guarantee that adjacent squares would differ only in one variable.
</aside>

<h3 id="271-circular-thinking">2.7.1 Circular thinking</h3>
<aside>
📖 **Important takeaways**

- In the K-map in Figure 2.43, only two minterms are present in the equation, $\overline{A}\,\overline{B}\,\overline{C}\,$ and $\overline{A}\,\overline{B}C\,$, as indicated by the 1’s in the left column. Reading the minterms from the K-map is exactly equivalent to reading equations in sum-of-products form directly from the truth table.
- As before, we can use Boolean algebra to minimize equations in sum-of-products form.

    $$
    Y=\overline{A}\,\overline{B}\,\overline{C}+\overline{A}\,\overline{B}C=\overline{A}\,\overline{B}(\overline{C}+C)=\overline{A}\,\overline{B}
    $$

- K-maps help us do this simplification graphically by circling 1’s in adjacent squares, as shown in Figure 2.44. For each circle, we write the corresponding implicant.
- Variables whose **true and complementary forms are both in the circle** are **excluded from the implicant**. In this case, the variable $C\,$has both its true form(1) and its complementary form(0) in the circle, so we do not include it in the implicant.
- In other words, $Y\,$is true when $A=B=0\,$, independent of $C\,$. So the implicant is $\overline{A}\,\overline{B}\,$. The K-map gives the same answer we reached using Boolean algebra.

![Screenshot 2023-01-21 at 17.19.59.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_17.19.59%201.png)

![Screenshot 2023-01-21 at 23.36.50.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_23.36.50.png)

</aside>

<h3 id="272-logic-minimization-with-k-maps">2.7.2 Logic Minimization with K-Maps(!!!)</h3>
<aside>
📖 **Important takeaways**

- K-maps provide an easy visual way to minimize logic. Simply circle all the rectangular blocks of 1’s in the map, using the fewest possible number of circles. Each circle should be as large as possible. Then read off the implicants that were circled.
- More formally, recall that a Boolean equation is minimized when it is written as sum of the fewest number of prime implicants. Each circle on the K-map represents an implicant. The largest possible circles are prime implicants.
- For example, in the K-map of Figure 2.44, $\overline{A}\,\overline{B}\,\overline{C}\,$ and $\overline{A}\,\overline{B}C\,$are implicants, but not prime implicants. Only $\overline{A}\,\overline{B}\,$is a prime implicant in that K-map.
- **Rules for finding a minimized equation from a K-map are as follows:**
    - Use **the fewest circles** necessary to cover all the 1’s.
    - All the squares in each circle must contain 1’s.
    - **Each circle** must span a rectangular block **that is a power of 2**(i.e., 1, 2, or 4) squares **in each direction**.
    - **Each circle should be as large as possible**.
    - A circle **may wrap around the edges** of the K-map.
    - **A 1 in a K-map may be circled multiple times** if doing so allows fewer circles to be used.
- **Example 2.9: Minimization of a three-variable function using a K-map**
    - Circle the 1’s in the K-map using a few circles as possible, as shown in Figure 2.46.
    - Notice how the circle covering four squares wraps around the sides of the K-map.
    - Notice how the top-right square(minterm) is covered twice to make the prime implicant circles as large as possible.
    - As we saw with Boolean algebra techniques, this is equivalent to sharing a minterm to reduce the size of the implicant.(Idempotency)

        ![Screenshot 2023-01-22 at 00.00.35.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_00.00.35.png)

- **Example 2.10: Seven-segment display decoder**

    **Key points:**

    1. Remember that adjacent squares may differ in only a single variable, so we label the rows and columns in Gray code order: 00, 01, 11, 10. Be careful to also remember this ordering when entering the output values into the squares.
    2. Next, circle the **prime implicants**. Use the **fewest number of circles** necessary to **cover all the 1’s**. A circle can **wrap around the edges**(vertical and horizontal), and a 1 may be circled more than once.
    3. Note that **the minimal set of prime implicants is not unique**. For example, the 0000 entry in the $S_a\,$K-map was circled along with the 1000 entry to produce the $\overline{D_2}\,\overline{D_1}\,\overline{D_0}\,$minterm. The circled would have included the 0010 entry instead, producing a $\overline{D_3}\,\overline{D_2}\,\overline{D_0}\,$minterm, as shown with dashed lines in Figure 2.51.
    4. Figure 2.52 illustrates a common error in which a **nonprime implicant was chosen to cover the 1 in the upper left corner**. This minterm, $\overline{D_3}\,\overline{D_2}\,\overline{D_1}\,\overline{D_0}\,$, gives a sum-of-products equation that is not minimal. The minterm could have been combined with either of the adjacent ones to form a larger circle, as was done in the previous two figures.

    ![Screenshot 2023-01-22 at 09.52.05.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_09.52.05.png)

    ![Screenshot 2023-01-22 at 10.01.46.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_10.01.46.png)


![Screenshot 2023-01-21 at 23.36.50.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_23.36.50%201.png)

![Screenshot 2023-01-21 at 23.55.11.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_23.55.11.png)

![Screenshot 2023-01-21 at 23.55.51.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_23.55.51.png)

![Screenshot 2023-01-21 at 23.54.35.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-21_at_23.54.35.png)

![Screenshot 2023-01-22 at 10.02.00.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_10.02.00.png)

![Screenshot 2023-01-22 at 10.02.20.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_10.02.20.png)

![Screenshot 2023-01-22 at 10.02.35.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_10.02.35.png)

![Screenshot 2023-01-22 at 10.05.46.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_10.05.46.png)

![Screenshot 2023-01-22 at 10.02.54.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_10.02.54.png)

</aside>

<h3 id="273-dont-cares">2.7.3 Don’t cares</h3>
<aside>
📖 **Important takeaways**

- Recall that “don’t care” entries for truth table inputs were introduced in Section 2.4 to reduce the number of rows in the table when some variables do not affect the output. They are indicated by the symbol X, which means that the entry can be either 0 or 1.
- **Don’t cares also appear in truth table outputs** where **the output value is unimportant** or **the corresponding input combination can never happen**. Such outputs can be treated as either 0’s or 1’s at the designer’s discretion,
- In a K-map, X’s allow for even more logic minimization. **They can be circled if they help cover the 1’s with fewer or larger circles**, but **they do not have to be circled if they are not helpful**.
- Notice that in Figure 2.53(a), **the four squares in the corner are adjacent**, 0000 is adjacent to 1000 and 0010, 1000 is adjacent to 0000 and 1010, 0010 is adjacent to 0000 and 1010, 1010 is adjacent to 1000 and 0010. So these four squares can form a $2\times2\,$square.

![Screenshot 2023-01-22 at 10.22.36.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_10.22.36.png)

![Screenshot 2023-01-22 at 10.21.50.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_10.21.50.png)

</aside>

<h3 id="274-the-big-picture">2.7.4 The Big Picture</h3>
<aside>
📖 **Important takeaways**

- Boolean algebra and Karnaugh maps are **two methods of logic simplification**. Ultimately, **the goal is to find a low-cost method of implementing a particular logic function**.
- In modern engineering practice, computer programs called logic synthesizers produce simplified circuits from a description of the logic function, as we will see in Chapter 4. For large problems, logic synthesizers are much more efficient than humans. For small problems, human with a bit of experience can find a good solution by inspection.
- Neither of the authors has ever used a Karnaugh map in real life to solve a practical problem. But the insight gained from the principles underlying Karnaugh maps is valuable. And Karnaugh maps often appear to job interviews.
</aside>

<h2 id="28-combinational-building-blocks">2.8 Combinational Building Blocks(!!!)</h2>
<h3 id="280-background">2.8.0 Background</h3>
<aside>
📖 **Background**

- **Combinational logic is often grouped into larger building blocks to build more complex systems**.
- This is an application of **the principle of abstraction**, **hiding the unnecessary gate-level details to emphasize the function of the building block**.
- We have already studied three such building blocks: full adders, priority circuits, and seven-segment display decoders.
- This section introduces two more commonly used building blocks: multiplexers and decoders.
- Chapter 5 covers other combinational building blocks.

    ![Screenshot 2023-01-22 at 11.12.50.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_11.12.50.png)

    ![Screenshot 2023-01-22 at 11.11.50.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_11.11.50.png)


![Screenshot 2023-01-22 at 11.09.53.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_11.09.53.png)

![Screenshot 2023-01-22 at 11.09.36.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_11.09.36.png)

![Screenshot 2023-01-22 at 11.14.02.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_11.14.02.png)

![Screenshot 2023-01-22 at 11.14.16.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_11.14.16.png)

</aside>

<h3 id="281-multiplexers">2.8.1 Multiplexers(!!!)</h3>
<aside>
📖 **Important takeaways**

- Multiplexers are among the most commonly used combinational circuits.
- They **choose an output from among several possible inputs** **based on the value of a select signal**.
- A multiplexer is sometimes affectionately called a mux.
- Figure 2.54 shows the schematic and truth table for a 2:1 multiplexer with two data inputs $D_0\,$and $D_1\,$, a select input $S\,$, and one output $Y\,$.
- **The multiplexer chooses between the two data inputs based on the select: if $S=0\,$, $Y=D_0\,$, and if $S=1\,$, $Y=D_1\,$. $S\,$is also called a control signal because it controls what the multiplexer does**.
- A 2:1 multiplexer can be built from sum-of-produces logic as shown in Figure 2.55. The Boolean equation for the multiplexer may be derived with a Karnaugh map or read of by inspection($Y\,$is 1 if $S=0\,$AND $D_0\,$is 1 OR if $S=1\,$AND $D_1\,$is 1)

    $$
    Y=\overline{S}D_0+SD_1=D_0\overline{S}+D_1S
    $$

- Alternatively, multiplexers can be built from tristate buffers as shown in Figure 2.56. The tristate enables are arranged such that, at all times, exactly one tristate buffer is active. When $S=0\,$, tristate $T_0\,$is enabled, allowing $D_0\,$to flow to $Y\,$. When $S=1\,$, tristate $T_1\,$is enabled, allowing $D_1\,$to flow to $Y$.

![Screenshot 2023-01-22 at 11.33.44.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_11.33.44.png)

![Screenshot 2023-01-22 at 11.33.54.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_11.33.54.png)

> Shorting together the outputs of multiple gates technically violates the rules for combinational circuits given in Section 2.1.(不允许多个支流并在一起) But because exactly one of the outputs is driven at any time, this exception is allowed.
> 

![Screenshot 2023-01-22 at 11.34.04.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_11.34.04.png)

![Screenshot 2023-01-22 at 11.34.23.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_11.34.23.png)

![Screenshot 2023-01-22 at 11.52.02.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_11.52.02.png)

- **Wider Multiplexer**
    - A 4:1 multiplexer has four data inputs and one output, as shown in Figure 2.57. Two select signals are needed to choose among the four data inputs. The 4:1 multiplexer can be built using sum-of-products logic, tristates, or multiple 2:1 multiplexers, as shown in Figure 2.58.
    - Wider multiplexers, such as 8:1 and 16:1 multiplexers, can be built by expanding the methods shown in Figure 2.58. In general, an N:1 multiplexer needs $\log_2N\,$select lines. Again, the best implementation choice depends on the target technology.
    - The 4:1 multiplexer chooses between the four data inputs based on the select: if $S_1=0,S_0=0,Y=D_0\,$, and if $S_1=0,S_0=1,Y=D_1\,$, and if $S_1=1,S_0=0,Y=D_2\,$, and if $S_1=1,S_0=1,Y=D_3\,$. $S_1\,$and $S_0\,$are two control signals because it controls what the multiplexer does.

    $$
    Y=D_0\overline{S_1}\,\overline{S_0}+D_1\overline{S_1}S_0+D_2S_1\overline{S_0}+D_3S_1S_0
    $$


- 对于Figure 2.58(a)和 Figure 2.58(b), 我们根据上面给出的$\,Y\,$的式子不难画出电路。对于Figure 2.58(c), 我们稍作解释, $S_0\,$为0时，$D_0,D_2\,$可以通过，$S_0\,$为1时，$D_1,D_3\,$可以通过。$S_1\,$为0时，经过筛选的$D_0,D_1\,$中的幸存者可以通过，$S_1\,$为1时，经过筛选的$D_2,D_3\,$中的幸存者可以通过。

![Screenshot 2023-01-22 at 12.15.10.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_12.15.10.png)

- Multiplexers can be used as lookup tables to perform logic functions. Figure 2.59 shows a 4:1 multiplexer used to implement a two-input AND gate.
- The inputs, A and B, serve as select lines. The multiplexer data inputs are connected to 0 or 1 according to the corresponding row of the truth table.
- In general, a $2^N$-input multiplexer can be programmed to perform any N-input logic function by applying 0’s and 1’s to the appropriate data inputs.
- By changing the data inputs, the multiplexer can be reprogrammed to perform a different function.
- With a little cleverness, we can cut the multiplexer size in half, using only a $2^{N-1}$-input multiplexer to perform any $N$-input logic function. The strategy is to provide one of the literals, as well as 0’s and 1’s, to the multiplexer data inputs(**multiplexer logic using variable inputs**).

![Screenshot 2023-01-22 at 14.04.16.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_14.04.16.png)

![Screenshot 2023-01-22 at 14.14.49.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_14.14.49.png)

![Screenshot 2023-01-22 at 14.15.03.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_14.15.03.png)

![Screenshot 2023-01-22 at 13.50.56.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_13.50.56.png)

- 对于左边给出的这张真值表来说，有两个关键的要素，第一个是A和B的不同组合，第二个是最终输出的结果。这张真值表对应的是$\,Y=AB\,$这个公式。
- 我们想用multiplexer来实现这个公式，因此我们可以把A和B当做是两个选择器selector，当选择器的组合是00，01，10时，最终的输出结果是0(LOW),因此我们对应把00，01，10接地(倒三角表示接地)，这样当选择器的状态为00，01，10时，Y对应的是0(LOW)。
- 同时由于当选择器的组合是11的时候，最终的输出结果是1(HIGH)，因此我们对应把11接电源(小的横线表示接电源)，这样当选择器的状态为11时，Y对应的是1(HIGH)。

![Screenshot 2023-01-22 at 14.08.28.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_14.08.28.png)

![Screenshot 2023-01-22 at 14.08.12.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_14.08.12.png)

</aside>

<h3 id="282-decoders">2.8.2 Decoders(!!!)</h3>
<aside>
📖 **Important takeaways**

- A decoder has $N\,$inputs and $2^N\,$outputs. It asserts exactly one of its outputs depending on the input combination. Figure 2.63 shows a 2:4 decoder. When $A_{1:0}=00$, $Y_0=1$. When $A_{1:0}=01$, $Y_1=1$. When $A_{1:0}=10$, $Y_2=1$. When $A_{1:0}=11$, $Y_3=1$. The output are called one-hot, because exactly one is “hot”(HIGH) at a given time.
- Decoders can be combined with OR gates to build logic functions. Figure 2.65 shows the two-input XNOR function using a 2:4 decoder and a single OR gate. Because each output of a decoder represents a single minterm, the function is built as the OR of all the minterms in the function. In Figure 2.65, $Y=\overline{A\oplus B}=\overline{A}\,\overline{B}+AB\,$.
    - Given an equation $Y=\overline{A\oplus B}\,$, first draw the truth table.


        | $A$ | $B$ | $A\oplus B$ | $\overline{A\oplus B}$ |
        | --- | --- | --- | --- |
        | 0 | 0 | 0 | 1 |
        | 0 | 1 | 1 | 0 |
        | 1 | 0 | 1 | 0 |
        | 1 | 1 | 0 | 1 |
    - Thus, we conclude that

        $$
        Y=\overline{A\oplus B}=\overline{A}\,\overline{B}+AB\,
        $$

    - We use decoders and OR gates to build logic functions. Because each output of a decoder represents a single minterm, the function is built as the OR of all the minterms in the function.
- When using decoders to build logic, it is easiest to express functions as a truth table or in canonical sum-of-products form. An $N$-input function(指的是公式中自变量的个数，例如在上面的例子中有两个自变量，分别是$A\,$和$B\,$) with $M\,$1’s in the truth table can be built with an $N:2^N\,$decoder and an $M$-input OR gate attached to all of the minterms containing 1’s in the truth table.
- This concept will be applied to the building of Read Only Memories(ROM) in Section 5.5.6

![Screenshot 2023-01-22 at 15.28.11.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_15.28.11.png)

- In general, an $N:2^N\,$decoder can be constructed from $**2^N\,$$N$-input** AND gates that accept the various combinations of true or complementary inputs.
- Each output in a decoder represents a single minterm. For example, $Y_0\,$represents the minterm $\overline{A_1}\,\overline{A_0}\,$. This fact will be handy when using decoders with other digital building blocks.

$$
\begin{align*}Y_3&=A_1A_0\\Y_2&=A_1\overline{A_0}\\Y_1&=\overline{A_1}A_0\\Y_0&=\overline{A_1}\,\overline{A_0}\end{align*}
$$

![Screenshot 2023-01-22 at 15.28.22.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_15.28.22.png)

![Screenshot 2023-01-22 at 15.28.37.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_15.28.37.png)

</aside>

<h2 id="29-timing">2.9 Timing</h2>
<h3 id="290-background">2.9.0 Background</h3>
<aside>
📖 **Background**

- In previous sections, we have been concerned primarily with whether the circuit works — ideally, using the fewest gates.
- However, as any seasoned circuit designer will attest, **one of the most challenging issues in circuit design is timing: making a circuit run fast**.
- An output takes time to change in response to an input change.
- Figure 2.66 shows the delay between an input change and the subsequent output change for a buffer.
- The figure is called a timing diagram; it portrays the transient(lasting only for a short time; impermanent) response of the buffer circuit when an input changes.

![Screenshot 2023-01-22 at 23.50.53.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-22_at_23.50.53.png)

- The transition from LOW to HIGH is called the rising edge. Similarly, the transition form HIGH to LOW(not shown in the figure) is called the falling edge.
- The blue arrow indicates that the rising edge of Y is caused by the rising edge of A.
- We measure delay **from the 50% point of the input signal**, A, **to the 50% point of the output signal**, Y. The 50% point is the point at which the signal is half-way(50%) between its LOW and HIGH values as it transitions.
</aside>

<h3 id="291-propagation-and-contamination-delay">2.9.1 Propagation and Contamination Delay</h3>
<aside>
📖 **Important takeaways**

> When designers speak of calculating the delay of a circuit, they generally are referring to the worst-case value(the propagation delay), unless it is clear otherwise from the context.
> 
- Combinational logic is characterized by its **propagation delay** and **contamination delay**.
- The propagation delay $t_{pd}\,$is the **maximum** time from when an input changes until the output or outputs **reach their final value**.
- The contamination delay $t_{cd}\,$is the **minimum** time from when an input changes until any output **starts to change its value**.

- Figure 2.67 illustrates a buffer’s propagation delay and contamination delay in blue and gray, respectively. The figure shows that A is initially either HIGH or LOW and changes to the other state at a particular time; **we are interested only in the fact that it changes, not what value it has**. In response, Y changes some time later. The arcs indicate that Y may start to change $t_{cd}\,$after A transitions and that Y definitely settles to its new value within $t_{pd}\,$.
- Details

    The underlying causes of delay in circuits include the time required to charge the capacitance in a circuit and the speed of light. $t_{pd}\,$and $t_{cd}\,$may be different for many reasons, including

    - different rising and falling delays
    - multiple inputs and outputs, some of which are faster than others
    - circuits slowing down when hot and speeding up when cold

![Screenshot 2023-01-31 at 08.05.11.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_08.05.11.png)

- Along with the factors already listed, propagation and contamination delays are also determined by the path a signal takes from input to output. Figure 2.68 shows a four-input logic circuit.
- **The critical path, shown in blue, is the path from input A or B to output Y**. It is the longest, therefore the slowest, path, because the input travels through three gates to the output. This path is critical because it limits the speed at which the circuit operates.
- The short path through the circuit, shown in gray, is from input D to output Y. This is the shortest, and therefore the fastest, path through the circuit, because the input travel through only a single gate to the output.
- The propagation delay of a combination circuit is the sum of the propagation delays through each element on the critical path.
- The contamination delay is the sum of the contamination delays through each element on the short path.
- These delays are illustrated in Figure 2.69 and are described by the following equations.

    $$
    \begin{align*}t_{pd}&=2t_{pd\_{\mathrm{AND}}}+t_{pd\_{\mathrm{OR}}}\\t_{cd}&=t_{cd\_{\mathrm{AND}}}\end{align*}
    $$

    > Although we are ignoring wire delay in this analysis, digital circuits are now so fast that the delay of long wires can be as important as the delay of the gates. The speed of light delay in wires is covered in Appendix A.
    > 

![Screenshot 2023-01-31 at 08.12.43.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_08.12.43.png)

![Screenshot 2023-01-31 at 08.20.36.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_08.20.36.png)

- **Examples**


    ![Screenshot 2023-01-31 at 08.27.32.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_08.27.32.png)

    ![Screenshot 2023-01-31 at 08.27.54.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_08.27.54.png)

    ![Screenshot 2023-01-31 at 08.44.17.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_08.44.17.png)

    ![Screenshot 2023-01-31 at 08.44.32.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_08.44.32.png)

    ![Screenshot 2023-01-31 at 08.44.53.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_08.44.53.png)

    ![Screenshot 2023-01-31 at 08.45.24.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_08.45.24.png)

    ![Screenshot 2023-01-31 at 08.45.07.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_08.45.07.png)

</aside>

<h3 id="292-glitches">2.9.2 Glitches</h3>
<aside>
📖 **Important takeaways**

- So far we have discussed the case where a single input transition causes a single output transition. However, it is possible that **a single input transition can cause multiple output transitions**. These are called **glitches** or hazards. Although glitches usually don’t cause problems, it is important to realize that they exist and recognize them when looking at timing diagrams. Figure 2.75 shows a circuit with a glitch and the Karnaugh map of the circuit.

- The Boolean equation is correctly minimized, but let’s look at what happens when $A=0,C=1\,$, and $B\,$transitions from 1 to 0. Figure 2.76 illustrates this scenario. The short path(shown in gray) goes through two gates, the AND and OR gates. The critical path(shown in blue) goes through an inverter and two gates, the AND and OR gates.
- As B transitions from 1 to 0, **n2(on the short path) falls before n1(on the critical path) can rise**. Until n1 rises, the two inputs to the OR gates are 0, and the output Y drops to 0. When n1 eventually rises, Y returns to 1. As shown in the timing diagram of Figure 2.76, **Y starts at 1 and ends at 1 but momentarily glitches to 0**.
- As long as we wait for the propagation delay to elapse before we depend on the output, glitches are not a problem, because the output eventually settles to the right answer.
- If we choose to, we can avoid this glitch by adding another gate to the implementation. **This is easiest to understand in terms of the K-map**. Figure 2.77 shows how an input transition on B from ABC = 001 to ABC = 011 **moves from one prime implicant circle to another**. **The transition across the boundary of two prime implicants in the K-map indicates a possible glitch**.
- As we saw from the timing graph in Figure 2.76, if the circuitry implementing one of the prime implicants turns off before the circuitry of the other prime implicant can turn on, there is a glitch.
- To fix this, we **add another circle that covers that prime implicant boundary**, as shown in Figure 2.78. You might recognize this as the consensus theorem, where the added term, $\overline{A}C$, is the consensus of redundant term.

    $$
    \begin{align*}Y&=\overline{A}\,\overline{B}+BC\\Y&=\overline{A}\,\overline{B}+BC+\overline{A}C\\&=\overline{A}\,\overline{B}+BC+\overline{A}\,\overline{B}C+\overline{A}BC\\&=\overline{A}\,\overline{B}+\overline{A}\,\overline{B}C+BC+\overline{A}BC\\&=\overline{A}\,\overline{B}+BC\end{align*}
    $$

- Figure 2.79 shows the glitch-proof circuit. The added AND gate is highlighted in blue. Now a transition on B when $A=0\,$and $C=1\,$does not cause a glitch on the output, because the blue AND gate outputs 1 throughout the transition.

![Screenshot 2023-01-31 at 09.36.14.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_09.36.14.png)

| A | B | C | Y |
| --- | --- | --- | --- |
| 0 | 0 | 0 | 1 |
| 0 | 0 | 1 | 1 |
| 0 | 1 | 0 | 0 |
| 0 | 1 | 1 | 1 |
| 1 | 0 | 0 | 0 |
| 1 | 0 | 1 | 0 |
| 1 | 1 | 0 | 0 |
| 1 | 1 | 1 | 1 |

![Screenshot 2023-01-31 at 09.43.21.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_09.43.21.png)

![Screenshot 2023-01-31 at 10.00.19.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_10.00.19.png)

- In general, a glitch can occur when a change in a single variable crosses the boundary between two prime implicants in a K-map. We can eliminate the glitch by adding redundant implicants to the K-map to cover these boundaries. This of course comes at the cost of extra hardware.
- However, **simultaneous transitions on multiple inputs can also cause glitches**. These glitches cannot be fixed by adding hardware. Because the vast majority of interesting systems have simultaneous (or near-simultaneous) transitions on multiple inputs, glitches are a fact of life in most circuits. Although we have shown how to eliminate one kind of glitch, the point if discussing glitches is not to eliminate them but to be aware that they exist. This is especially important when looking at timing diagrams on a simulator or oscilloscope.
</aside>

<h2 id="210-summary">2.10 Summary</h2>
<aside>
📖 **Summary**

- A digital circuit is a module with discrete-valued inputs and outputs and a specification describing the function? and timing of the module. This chapter has focused on combinational circuits, circuits whose outputs depend only on the current values of the inputs.
- **The function of a combinational circuit can be given by a truth table of a Boolean equation**. The Boolean equation for any truth table can be obtained systematically using sum-of-products or product-of-sums form. In sum-of-products form, the function is written as the sum(OR) of one or more implicants. Implicants are the product(AND) of literals. Literals are the true or complementary forms of the input variables.
- Boolean equations can be simplified using the rules of Boolean algebra. In particular, they can be simplified into minimal sum-of-products form by combing implicants that differ only in the true and complementary forms of one of the literals: $PA+P\overline{A}=P(A+\overline{A})=P\,$. **Karnaugh maps are a visual tool for minimizing functions of up to four variables**. With practice, designers can usually simplify functions of a few variables by inspection. Computer-aided design tools(CAD) are used for more complicated functions; such methods and tools are discussed in Chapter 4.
- (!!!)Logic gates are connected to create combinational circuits that perform the desired function. **Any function in sum-of-products form can be built using two-level logic: NOT gates form the complement of the inputs, AND gates form the products, and OR gates form the sum**. Depending on the function and the building blocks available, multilevel logic implementations with various types of gates may be more efficient. For example, CMOS circuits favor NAND and NOR gates because these gates can be built directly from CMOS transistors without requiring extra NOT gates. When using NAND and NOR gates, bubble pushing is helpful to keep track of the inversions.
- (!!!)Logic gates are combined to produce larger circuits such as multiplexers, decoders, and priority circuits. A multiplexer chooses one of the data inputs based on the select input. A decoder sets one of the outputs HIGH according to the inputs. A priority circuit produces an output indicating the highest priority input. These circuits are all examples of combinational building blocks. Chapter 5 will introduce more building blocks, including other arithmetic circuits. These building blocks will be used extensively to build a microprocessor in Chapter 7.
- The timing specification of a combinational circuit consists of the propagation and contamination delays through the circuit. These indicate the longest and shortest times between an input change and the consequent output change. Calculating the propagation delay of a circuit involves identifying the critical path through the circuit, then adding up the propagation delays of each element along that path. There are many different ways to implement complicated combinational circuits; these ways offer trade-offs between speed and cost.
- The next chapter will move to sequential circuits, whose outputs depend on current as well as previous values of the inputs. In other words, sequential circuits have memory of the past.
</aside>

<h1 id="3-sequential-logic-design">3 Sequential Logic Design</h1>
<h2 id="30-exercises">3.0 Exercises</h2>
<h2 id="31-introduction">3.1 Introduction</h2>
<aside>
📖 **Important takeaways**

- In the last chapter, we showed how to analyze and design combinational logic. **The output of combinational logic depends only on current input values**. Given a specification in the form of a truth table or Boolean equation, we can create an optimized circuit to meet the specification.
- In this chapter, we will analyze and design sequential logic. **The output of sequential logic depend on both current and prior input values**. Hence, sequential logic has memory.
- Sequential logic might explicitly remember certain previous inputs, or it might **distill the prior inputs into a smaller amount of information called the state of the system**. **The state of a digital sequential circuit is a set of bits called state variables** that contain all the information about the past necessary to explain the future behavior of the circuit.
- The chapter begins by studying **latches and flip-flops,** which are **simple sequential circuits that store one bit of state**.
- In general, sequential circuits are complicated to analyze. To simplify design, we discipline ourselves to build only synchronous circuits consisting of combinational logic and banks of flip-flops containing the state of the circuit.
- The chapter describes **finite state machines**, which are **an easy way to design sequential circuits**.
- Finally, we analyze the speed of sequential circuits and discuss **parallelism** as a way to **increase speed**.
</aside>

<h2 id="32-latches-and-flip-flops">3.2 Latches and Flip-flops</h2>
<h3 id="320-background">3.2.0 Background</h3>
<aside>
📖 **Background**

> Just as Y is commonly used for the output of combinational logic, Q is commonly used for the output of sequential logic.
> 
- The fundamental building block of memory is a **bistable element**, **an element with two stable states**.
- Figure 3.1(a) shows a simple bistable element consisting of a pair of inverters connected in a loop. Figure 3.1(b) shows the same circuit redrawn to emphasize the symmetry. The inverters are cross-coupled, meaning that the input of I1 is the output of I2 and vice versa. The circuit has no inputs, but it does have two outputs, $Q\,$and $\overline{Q}\,$.
- Analyzing this circuit is different from analyzing a combinational circuit because it is cyclic: $Q\,$depends on $\overline{Q}\,$, and $\overline{Q}\,$depends on $Q\,$.
- Consider the two cases, $Q\,$is 0 and $Q\,$is 1. Working through the consequences of each case, we have:
    - Case 1: $Q=0\,$(stable)

        As shown in Figure 3.2(a), I2 receives a FALSE input, $Q\,$, so it produces a TRUE output on $\overline{Q}\,$. I1 receives a TRUE input, $\overline{Q}\,$, so it produces a FALSE output on $Q\,$. **This is consistent with the original assumption that $Q=0\,$, so the case is said to be stable**.

    - Case 2: $Q=1\,$(stable)

        As shown in Figure 3.2(b), I2 receives a TRUE input and produces a FALSE output on $\overline{Q}\,$. I1 receives a FALSE input and produces a TRUE output on $Q\,$. This is again stable.


![Screenshot 2023-01-31 at 10.34.26.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_10.34.26.png)

![Screenshot 2023-01-31 at 18.59.17.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_18.59.17.png)

- **Because the cross-coupled inverters have two stable states, $Q=0\,$and $Q=1$, the circuit is said to be bistable**.
- A subtle point is that the circuit has a third possible state with both outputs approximately halfway between 0 and 1. This is called a metastable state and will be discussed in Section 3.5.4.
- An element with $N\,$stable states conveys $\log_2{N}\,$bits of information, so a bistable element stores one bit.
- The state of the cross-coupled inverters is contained in one binary state variable, $Q$. The value of $Q\,$tells us everything about the past that is necessary to explain the future behavior of the circuit. Specifically, if $Q=0$, it will remain 0 forever, and if $Q=1$, it will remain 1 forever. The circuit does have another node, $\overline{Q}$, but $\overline{Q}\,$does not contain **any additional information** because if $Q\,$is known, $\overline{Q}\,$is also known. On the other hand, $\overline{Q}\,$is also an acceptable choice for the state variable.
- **When power is first applied to a sequential circuit, the initial state is unknown and usually unpredictable**. It may differ each time the circuit is turned on.
- Although the **cross-coupled inverters** can store a bit of information, they are not practical because the user has **no inputs to control the state**.
- However, other bistable elements, such as latches and flip-flops, provide inputs to control the value of the state variable. The remainder of this section considers these circuits.
</aside>

<h3 id="321-sr-latch">3.2.1 SR Latch(?!!!)</h3>
<aside>
📖 **Important takeaways**

- One of the simplest sequential circuits is the SR latch, which is composed of two cross-coupled NOR gates, as shown in Figure 3.3. The latch has two inputs, S and R, and two outputs, $Q\,$and $\overline{Q}$.
- The SR latch is similar to the cross-coupled inverters, but its state can be controlled through the S and R inputs, which set(S) and reset(R) the output $Q$.

![Screenshot 2023-01-31 at 20.11.43.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_20.11.43.png)

![Screenshot 2023-01-31 at 20.11.56.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_20.11.56.png)

![Screenshot 2023-01-31 at 20.07.43.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_20.07.43.png)

![Screenshot 2023-01-31 at 20.12.07.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_20.12.07.png)

![Screenshot 2023-01-31 at 20.12.17.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_20.12.17.png)

- Putting this all together, suppose $Q\,$has some known prior value, which we will call $Q_{prev}\,$, before we enter Case IV. $Q_{prev}\,$is either 0 or 1, and represents the state of the system.
- **When R and S are 0, $Q\,$will remember this old value, $Q_{prev}$**, and $\overline{Q}\,$will be its complement(the complement of $\overline{Q_{prev}}$ ). The circuit has memory.
- The truth table in Figure 3.5 summarizes these four cases. **The inputs S and R stand for Set and Reset**. To set a bit means to make it TRUE. To reset a bit means to make it FALSE. The outputs, $Q\,$and $\overline{Q}\,$, are normally complementary.
- When S is asserted(and R is not asserted), Q is set to 1 and $\overline{Q}\,$does the opposite($\overline{Q}\,$is set to 0).
- When R is asserted(and S is not asserted), Q is set to 0 and $\overline{Q}\,$does the opposite($\overline{Q}\,$is set to 1).
- When neither input is asserted, Q remembers its old value, $Q_{prev}$.
- **Asserting both S and R simultaneously doesn’t make much sense** because it means the latch should **be set and reset at the same time**, which is impossible. The poor confused circuit responds by making both outputs 0.
- Any circuit element with the relationship specified by the truth table in Figure 3.5 and the symbol in Figure 3.6 is called an SR latch.
- Like the cross-coupled inverters, the SR latch is a bistable element with one bit of state stored in $Q\,$. However, the state can be controlled through the S and R inputs.
    - When R is asserted, the state is reset to 0(the state of $Q$).
    - When S is asserted, the state is set to 1(the state of $Q$).
    - When neither is asserted, the state retains its old value.
- (?)Notice that the entire history of inputs can be accounted for by the single state variable $Q\,$. No matter what pattern of setting and resetting occured in the past, all that is needed to predict the future behavior of the SR latch is **whether it was most recently set or reset**.

</aside>

<h3 id="322-d-latch">3.2.2 D Latch</h3>
<aside>
📖 **Important takeaways**

- The SR latch is awkward because **it behaves strangely when both S and R are simultaneously asserted**. Moreover, the S and R inputs conflate the issues of what and when. Asserting one of the inputs determines not only what the state should be but also when it should change.
- Designing circuits becomes easier when these questions of what and when are separated.
- The D latch in Figure 3.7(a) solves these problems. It has two inputs.
    - The data input, $D$, controls what the next state should be.
    - The clock input, $CLK$, controls when the state should change.

![Screenshot 2023-01-31 at 21.12.56.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_21.12.56.png)

![Screenshot 2023-01-31 at 20.12.07.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_20.12.07%201.png)

- Again, we analyze the latch by writing the truth table, given in Figure 3.7(b). For convenience, we first consider the internal nodes $\overline{D}$, $S$, and $R$.
    - If $CLK=0$, both S and R are FALSE, regardless of the value of $D$.(first row in Figure 3.5)
    - **If $CLK=1$, one AND gate will produce TRUE and the other FALSE**, depending on the value of $D$.
    - Given S and R, $Q\,$and $\overline{Q}\,$are determined using Figure 3.5.
- Observe that when $CLK=0$, $Q\,$remembers its old value, $Q_{prev}$. When $CLK=1$, $Q=D$.$(D=1, S(set)=1, Q=1; D=0, R(reset)=1, Q=0)$.
- The D latch avoids the strange case of simultaneously asserted R and S inputs.
- Putting it all together, we see that **the clock controls when data flows through the latch**.
    - **When $CLK=1$, the latch is transparent**. The data at $D\,$flows through to $Q\,$as if the latch were just a buffer.
    - **When $CLK=0$, the latch is opaque**. It **blocks** the **new data** from flowing through to $Q$, and $**Q\,$retains the old value**.
- Hence, the D latch is sometimes called a transparent latch or a level-sensitive latch. The D latch symbol is given in Figure 3.7(c).
- The D latch updates its state continuously while $CLK=1$. We shall see later in this chapter that it is useful to update the state only at a specific instant in time. The D flip-flop described in the next section does just that.
</aside>

<h3 id="323-d-flip-flop">3.2.3 D Flip-Flop(!!!)</h3>
<aside>
📖 **Important takeaways**

- A D flip-flop can be built from two back-to-back D latches controlled by complementary clocks, as shown in Figure 3.8(a).
- The first latch, L1, is called the master. The second latch, L2, is called the slave. The node between them is named N1. A symbol for the D flip-flop is given in Figure 3.8(b). When the $\overline{Q}\,$output is not needed, the symbol is often condensed as in Figure 3.8(c).
- When $**CLK=0**$, the **master branch** is **transparent** and the **slave branch** is **opaque**. Therefore, whatever value was at D propagates through to N1.

    When $CLK=1$, the master goes opaque and the slave becomes transparent. The value at N1 propagates to Q(on the right hand side), but N1 is cut off from D.

    (When $**CLK=1**$, the **master branch** is **opaque** and the **slave branch** is **transparent**.)

    | CLK | master | slave | path |
    | --- | --- | --- | --- |
    | 0 | transparent | opaque | $D\rightarrow N1\nrightarrow Q$ |
    | 1 | opaque | transparent | $D\nrightarrow N1\rightarrow Q$ |
- Hence, whatever value was at D **immediately before** the clock rises from 0 to 1 gets copied to Q **immediately after** the clock rises. At all other times, $Q\,$retains its old value, because there is always an opaque latch blocking the path between D and $Q$.
- In other words, a D flip-flop copies D to $Q\,$on the rising edge of the clock, and remembers its state at all other times.
- The rising edge of the clock is often just called the clock edge for brevity.
- The D input specifies what the new state will be. The clock edge indicates when the state should be updated.(CLK 0→1)
- A D flip-flop is also known as a master-slave flip-flop, an edge-triggered flip-flop, or a positive edge-triggered flip-flop. The triangle in the symbols denotes an edge-triggered clock input. The $\overline{Q}\,$output is often omitted when it is not needed.

![Screenshot 2023-01-31 at 21.51.08.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_21.51.08.png)

![Screenshot 2023-01-31 at 22.27.41.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_22.27.41.png)

</aside>

<h3 id="324-register">3.2.4 Register</h3>
<aside>
📖 **Important takeaways**

- An $N$-bit register is a bank of $N$ flip-flops that share a common $CLK$ input, so that **all bits of the register are updated at the same time**.
- Registers are the key building block of most sequential circuits.
- Figure 3.9 shows the schematic and symbol for a four-bit register with inputs $D_{3:0}\,$and outputs $Q_{3:0}$. $D_{3:0}\,$and $Q_{3:0}\,$are both 4-bit busses.

![Screenshot 2023-01-31 at 22.36.04.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_22.36.04.png)

</aside>

<h3 id="325-enabled-flip-flop">3.2.5 Enabled Flip-Flop</h3>
<aside>
📖 **Important takeaways**

- An enabled flip-flop adds another input called $EN$ or $ENABLE$ to determine whether data is loaded on the clock edge.
- When $EN$ is TRUE, the enabled flip-flop behaves like an ordinary D flip-flop. When $EN$ is FALSE, the enabled flip-flop ignores the clock and retains its state.
- Enabled flip-flops are useful when we wish to load a new value into a flip-flop only some of the time, rather than on every clock edge.

- Figure 3.10 shows two ways to construct an enabled flip-flop from a D flip-flop and an extra gate. In Figure 3.10(a), **an input multiplexer** chooses whether to **pass the value at D, if $EN$ is TRUE**, or to **recycle the old state from Q, if $EN\,$is FALSE**.

    注：在Figure 3.10(a)中, D与1连接, Q出口($Q_{prev}$)与0连接。

- In Figure 3.10(b), the clock is gated. If $EN\,$is TRUE, the $CLK\,$input to the flip-flop toggles normally. If $EN\,$is FALSE, the $CLK$ input is also FALSE and the flip-flop retains its old value.
- Notice that $EN\,$must not change while $CLK=1$, lest the flip-flop see a clock glitch(switch at an incorrect time).
- Generally, performing logic on the clock is a bad idea. Clock gating delays the clock and can cause timing errors, as we will see in Section 3.5.3, so do it only if your are sure you know what you are doing.
- The symbol for an enabled flip-flop is given in Figure 3.10(c).

![Screenshot 2023-01-31 at 23.53.31.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-01-31_at_23.53.31.png)

- 我们现在的任务就是思考如何构建这样的一个enabled flip-flop. 根据enabled flip-flop的功能叙述，我们可以知道，当EN=1时，D要把自身的内容传递给Q，当EN=0时，Q要保持自己原有的状态，因此D相当于要把$Q_{prev}\,$的内容传递给Q。
- 注意在上面的叙述中，并不是说当EN=1时，D就直接把自身的内容传递给Q了，而是说当EN=1时，此时enabled flip-flop与一个常规的D flip-flop没有任何区别，依然会在CLK由0转1的时候完成信号由D到Q的传递(当CLK=0时，master是transparent，slave是opaque，此时信号停在中间到不了Q；当CLK由0变1的时候，master是opaque，slave是transparent，此时信号由中间到达Q，同时D的信号无法到达中间)。
- 而在EN=0的时候，由于我们的目标是要让Q保持$Q_{prev}\,$的状态，所以我们要让D的输入端口始终与$Q_{prev}\,$相连，这样无论CLK是什么样的状态，Q的状态都不会发生改变，一直保持$Q_{prev}\,$的状态。
- 因此我们可以画出右侧的一个truth table并写出与这个truth table相对应的$D_{in}\,$的一个equation，根据这个equation我们能够画出如图所示的电路图。如果我们忽略具体构建的细节，将其封装在一个红色框中，我们便得到了幻灯片中呈现的enabled flip-flop的标志，红框外侧即是enabled flip-flop的各种输入输出端口。

![IMG_4DEC4A63CFB8-1.jpeg](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/IMG_4DEC4A63CFB8-1.jpeg)

![IMG_738EA1C346F8-1.jpeg](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/IMG_738EA1C346F8-1.jpeg)

![Screen Shot 2023-02-01 at 08.38.32.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screen_Shot_2023-02-01_at_08.38.32.png)

![IMG_98BD07584F1D-1.jpeg](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/IMG_98BD07584F1D-1.jpeg)

</aside>

<h3 id="326-resettable-flip-flop">3.2.6 Resettable Flip-Flop</h3>
<aside>
📖 **Important takeaways**

- A resettable flip-flop adds another input called RESET. When RESET is FALSE, the resettable flip-flop haves like an ordinary D flip-flop. When RESET is TRUE, the resettable flip-flop ignores D and resets the output to 0(next clock edge).
- Resettable flip-flops are useful when we want to force a known state(i.e., 0) into all the flip-flops in a system when we first turn it on.
- Such flip-flops may be synchronously or asynchronously resettable. Synchronously resettable flip-flops reset themselves only on the rising edge of CLK. Asynchronously resettable flip-flops reset themselves as soon as RESET becomes TRUE, independent of CLK.
- Figure 3.11(a) shows how to construct a synchronously resettable flip-flop from an ordinary D flip-flop and an AND gate.
    - When RESET is TRUE($\overline{RESET}$ is FALSE), the AND gate forces a 0 into the input of the flip-flop.
    - When RESET is FALSE($\overline{RESET}$ is TRUE), the AND gate passes D to the flip-flop.

    | RESET | $D_{in}$ |
    | --- | --- |
    | 1 | 0 |
    | 0 | D |

    $$
    D_{in}=\overline{RESET}\cdot D
    $$


![Screen Shot 2023-02-01 at 09.21.31.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screen_Shot_2023-02-01_at_09.21.31.png)

![Screen Shot 2023-02-01 at 09.26.59.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screen_Shot_2023-02-01_at_09.26.59.png)

- In this example, $\overline{RESET}$ is an active low signal, meaning that the reset signal performs its function when it is 0, not 1.
- By adding an inverter, the circuit could have accepted an active high reset signal instead. Figure 3.11(b) and Figure 3.11(c) show symbols for the resettable flip-flop with active high reset.
- Asynchronously resettable flip-flops require modifying the internal structure of the flip-flop and are left to you to design in Exercise 3.13; however, they are frequently available to the designer as a standard component.
- As you might imagine, settable flip-flops are also occasionally used. They load a 1 into the flip-flop when SET is asserted, and they too come in synchronous and asynchronous flavors. Resettable and settable flip-flops may also have an enable input and may be grouped into $N$-bit registers.

| SET | $D_{in}$ |
| --- | --- |
| 1 | 1 |
| 0 | D |

$$
D_{in}=SET+\overline{SET}\cdot D
$$

![IMG_5018522C4FB7-1.jpeg](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/IMG_5018522C4FB7-1.jpeg)

</aside>

<h3 id="327">3.2.7</h3>
<h3 id="328-putting-it-all-together">3.2.8 Putting It All Together</h3>
<aside>
📖 **Important takeaways**

- Latches and flip-flops are the fundamental building blocks of sequential circuits.
- Remember that a D latch is level-sensitive, whereas a D flip-flop is edge-triggered.
- The D latch is transparent when CLK=1, allowing the input D to flow through to the output Q.
- The D flip-flop copies D to Q on the rising edge of CLK. At all other times, latches and flip-flops retain their old state.
- A register is a bank of several D flip-flops that share a common CLK signal.

- 首先，让我们来考虑 D latch。D latch的工作特点是当CLK=1时，根据D的情况来确定输出Q的状态，CLK=1时，若D=1，则Q=1；若D=0，则Q=0。而当CLK=0时，Q保持$Q_{prev}\,$。
    1. 初始的时候Q的状态未知，既有可能是0，也有可能是1。
    2. 在图中，CLK第一个由0转1的过程中，第二行中D处在LOW的状态，所以Q也处在LOW的状态。
    3. 当D由0转1后，由于此时CLK=1，所以Q会变为HIGH的状态。
    4. CLK=1的时候，因为D的状态不变，所以Q的状态不变。
    5. 在CLK第一次由1变为0后，Q保持HIGH的状态。
    6. CLK第二个由0转1的过程中，D仍处在HIGH的状态，故Q依然保持HIGH。
    7. CLK=1的时候，Q的变化与D的变化完全相同，先降后升。
    8. CLK=0的时候，继续保持HIGH到结束。

![Screenshot 2023-02-01 at 10.59.05.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-01_at_10.59.05.png)

![Screenshot 2023-02-01 at 10.58.40.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-01_at_10.58.40.png)

- 其次，让我们来考虑 D flip-flop。

    On each rising edge of CLK, D is copied to Q. At all other times, Q retains its state.

</aside>

<h2 id="33-synchronous-logic-design">3.3  Synchronous Logic Design</h2>
<h3 id="330-background">3.3.0 Background</h3>
<aside>
📖 **Background**

- In general, **sequential circuits** include all circuits that are not combinational — that is, **whose output cannot be determined simply by looking at the current inputs**. Some sequential circuits are just plain kooky.
- This section begins by examining some of those curious circuits. It then introduces the notion of **synchronous sequential circuits** and **the dynamic discipline**.
- By **disciplining ourselves to synchronous sequential circuits**, we can develop easy, systematic ways to analyze and design sequential systems.
</aside>

<h3 id="331-some-problematic-circuits">3.3.1 Some Problematic Circuits</h3>
<aside>
📖 **Important takeaways**

- **Astable circuits**

    ![Screenshot 2023-02-01 at 13.52.52.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-01_at_13.52.52.png)

    ![Screenshot 2023-02-01 at 13.53.31.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-01_at_13.53.31.png)

    ![Screenshot 2023-02-01 at 13.53.11.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-01_at_13.53.11.png)


- **Race Conditions(!!!)**

    Ben Bitdiddle designed a new D latch that he claims is better than the one in Figure 3.7 because it uses fewer gates. He has written the truth table to find the output, $Q$, given the two inputs, D and CLK, and the old state of the latch, $Q_{prev}$. Based on this truth table, he has derived Boolean equations. He obtained $Q_{prev}\,$by feeding back the output, $Q$. His design is shown in Figure 3.18. Does his latch work correctly, independent of the delays of each gate?

    ![Screenshot 2023-02-01 at 14.06.26.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-01_at_14.06.26.png)

    自己尝试复述问题原因：这里主要涉及到了不同的门延迟时间长短的问题。

    1. 假设D和CLK初始状态都为1(HIGH),此时Q的状态也是1(HIGH)。
    2. 现在我们假设CLK由1变为0，并且OR gate和AND gate的delay比inverter的delay要短，当CLK由1变为0后，N1处会较快地变为0，同时由于初始时CLK是1，导致N2处是0。
    3. 由于inverter的delay比较长，所以N2处变为1的时间比较长，因此这个时候可以认为N2处还没有变为1，还是0的状态，N1,N2都是0，Q也是0，导致返回的$Q_{prev}$也变成了0。
    4. 那么这个时候即使CLK变成了0，本来此时按照设想Q应该保持1的状态，但是由于$Q_{prev}\,$处提前变为了0，导致N2处仍未0，导致Q会待在0的状态不再动了。

**Solution**: 

- Figure 3.19 shows that **the circuit has a race condition** that causes it to **fail when certain gates are slower than others**.
- Suppose CLK=D=1. The latch is transparent and passes D through to make Q=1.
- Now, CLK falls. The latch **should** remember its old value, keeping Q=1.
- However, suppose the delay through the inverter from CLK to $\overline{CLK}$ is rather long compared to the delays of the AND and OR gates. Then **nodes N1 and Q($\overline{CLK}$ is still 0, thus N2 is 0) may both fall before $\overline{CLK}$ rises**. In such a case, N2 will never rise, and **Q becomes stuck at 0**.

> This is an example of asynchronous circuit design in which **outputs are directly feed back to inputs(something that we should avoid)**. Asynchronous circuits are infamous for having race conditions where **the behavior of the circuit depends on which of two paths through logic gates is fastest**. One circuit may work, while a seemingly identical one built from gates **with slightly different delays** may not work. Or the circuit may work only at certain temperatures or voltages at which the delays are just right. These malfunctions are extremely difficult to track down.
> 
</aside>

<h3 id="332-synchronous-sequential-circuits">3.3.2 Synchronous Sequential Circuits(?!!!)</h3>
<aside>
📖 **Important takeaways**

- The previous two examples contain **loops** called **cyclic paths**, in which **outputs are fed directly back to inputs**. They are sequential rather than combinational circuits.
    - Combinational logic has no cyclic paths and no races. If inputs are applied to combinational logic, the outputs will always settle to the correct value **within a propagation delay**.
    - However, **sequential circuits with cyclic paths** can have **undesirable races or unstable behavior**. Analyzing such circuits for problems is time-consuming.
- To avoid these problems, designer **break the cyclic paths** by **inserting registers somewhere in the path**.
    - This transforms the circuit into **a collection of combinational logic and registers**.(Recall that an N-bit register is a bank of N flip-flops that share a common $CLK$ input, so that all bits of the register are updated at the same time)
    - The **registers** contain the **state of the system**, which **changes only at the clock edge**, so we say the state is synchronized to the clock.
    - (?!!!)If the clock is sufficiently slow, so that the inputs to all registers settle before the next clock edge, all races are eliminated.
    - Adopting this discipline of **always using registers in the feedback path** leads us to the formal definition of a synchronous sequential circuit.
- The rules of synchronous sequential circuit composition teach us that a circuit is a synchronous sequential circuit if it consists of interconnected circuit elements such that:
    1. **Every circuit element** is either a **register** or a **combinational circuit**.
    2. **At least one** circuit element is a **register**.
    3. **All registers** receive the **same clock signal**.
    4. **Every cyclic path** contains **at least one register**.
    5. 
</aside>

<h2 id="34-finite-state-machines">3.4 Finite State Machines</h2>
<h3 id="340-background">3.4.0 Background(?!!!)</h3>
<aside>
📖 **Background**

- Synchronous sequential circuits can be drawn in the forms shown in Figure 3.22. These forms are called finite state machines(FSMs).
- They get their name because **a circuit with $k$ registers can be in one of a finite number($2^k$) of unique states**.
- An FSM has $M$ inputs, $N$ outputs and $k$ bits of state. It also receives a clock and, optionally, a reset signal.
- An FSM consists of two blocks of combinational logic, next state logic and output logic, and a register that stores the state.
- On **each clock edge**, the FSM advances to **the next state**, which **was computed** **based on the current state and inputs**.
- **output dependencies**
    - (?!!!)There are two general classes of finite state machines, characterized by their functional specifications(?).
    - In Moore machines, the outputs depend only on the current state of the machine.
    - In Mealy machines, the outputs depend on both the current state and the current inputs.
    - This method will be explained in the remainder of this section, starting with an example.

![Screenshot 2023-02-01 at 15.28.36.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-01_at_15.28.36.png)

|  | Moore machines | Mealy machines |
| --- | --- | --- |
| current state | ✅ | ✅ |
| current input | ❌ | ✅ |
</aside>

<h3 id="341-fsmfinite-state-machine-design-example">3.4.1 FSM(Finite State Machine) Design Example</h3>
<aside>
📖 **Important takeaways**

- To illustrate the design of FSMs, consider the problem of **inventing a controller for a traffic light at a busy intersection on campus**. The Dean of Students asks Ben Bitdiddle to install a traffic light before there are any fatalities.

![Screenshot 2023-02-02 at 09.50.19.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-02_at_09.50.19.png)

- Ben decides to solve the problem with an FSM. He installs two traffic sensors, $T_A$ and $T_B$, on Academic Ave. and Bravado Blvd., respectively. **Each sensor indicates TRUE if students are at present and FALSE if the street is empty**.
- He also installs two traffic lights, $L_A$ and $L_B$, to control traffic. Each light receives digital inputs specifying whether it should be green, yellow, or red.
- Hence, his FSM has two inputs, $T_A$ and $T_B$, and two outputs, $L_A$ and $L_B$. The intersection with lights and sensors is shown in Figure 3.23.
- Ben provides a **clock** with a 5-second period. On each clock tick(rising edge), the lights may change based on the traffic sensors. He also provides **a reset button** so that Physical Plant technicians can put the controller in a **known initial state** **when they turn it on**. Figure 3.24 shows a black box view of the state machine.

![Screenshot 2023-02-02 at 09.50.33.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-02_at_09.50.33.png)

- Ben’s next step is to sketch the **state transition diagram**, shown in Figure 3.25, to **indicate all the possible states of the system and the transitions between them**.

![Screenshot 2023-02-02 at 10.01.57.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-02_at_10.01.57.png)

1. When the **system is reset**, the lights are **green on Academic Ave.** and **red on Bravado Blvd**.(S0)
2. Every 5 seconds, the controller examines the traffic pattern and decides what to do next.
3. As long as traffic is present on Academic Ave., the lights do not change. When there is no longer traffic on Academic Ave., the light on Academic Ave becomes yellow for 5 seconds(S1) before it turns red and Bravado Blvd.’s light turns green.(S2)
4. Similarly, the Bravado Blvd. light remains green as long as traffic is present on the boulevard, then turns yellow(S3) and eventually turns red.(S0)
- In a **state transition diagram**, circles represent states and arcs represent transitions between states.
- The transitions take place on the **rising edge of the clock**; we do not bother to show the clock on the diagram, because it is always present in a synchronous sequential circuit.
- Moreover, the **clock simply controls when the transitions should occur**, whereas **the diagram indicates which transitions occur**.
- The arc labeled Reset pointing from outer space into state S0 indicates that the system should enter that state upon reset, regardless of what previous state if was in.
- If **a state has multiple arcs leaving it**, the arcs are labeled to show what inputs triggers each transition.
    - For example, when in state $S0$, the system will remain in that state if $T_A$ is TRUE and move to $S1$ if $T_A$ is FALSE.
- If a state has **a single arc leaving it**, **that transition always occurs regardless of the inputs**.
    - For example, when in state $S1$, the system will always move to $S2$.
- The value that the outputs have while in a particular state are indicated in the state.
    - For example, while in state $S2$, $L_A$ is red and $L_B$ is green.
- Ben **rewrites the state transition diagram as a state transition table**(Table 3.1), which indicates, for each state and input, what the next state, $S^\prime$, should be. Note that **the table uses don’t care symbols(X) whenever the next state does not depend on a particular input**.
- Also note that Reset is omitted from the table. Instead, we use resettable flip-flops that always go to $S0$ on reset, independent of the inputs.
- The state transition diagram is abstract in that it uses states labeled$\{S0, S1, S2, S3\}$ and outputs labeled $\{\mathrm{red, yellow, green}\}$. To build a real circuit, the states and outputs must be assigned **binary encodings**. Ben chooses the simple codings given in Table 3.2 and 3.3. Each state and each output is encoded with two bits: $S_{1:0}$, $L_{A1:0}$, and $L_{B1:0}$.

![Screenshot 2023-02-02 at 11.04.49.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-02_at_11.04.49.png)

> Notice that states are designated as $S0$, $S1$, etc. The subscripted versions, $S_0$, $S_1$, etc., refer to the state bits.
> 
- Ben updates the state transition table to use these binary encodings, as shown in Table 3.4. The revised state transition table is a truth table specifying the next state logic. It defines next state, $S^\prime$, as a function of the current state, $S$, and the inputs.

    ![Screenshot 2023-02-02 at 11.12.05.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-02_at_11.12.05.png)

- From this table, it is straightforward to read off the Boolean equation for the next state in sum-of-products form.

    $$
    \begin{align*}S_1^\prime&=\overline{S_1}S_0+S_1\overline{S_0}\,\overline{T_B}+S_1\overline{S_0}T_B\\S_0^\prime&=\overline{S_1}\,\overline{S_0}\,\overline{T_A}+S_1\overline{S_0}\,\overline{T_B}\end{align*}
    $$

    The equations can be simplified using Karnaugh maps, but often doing it by inspection is easier.

    $$
    \begin{align*}S_1^\prime&=\overline{S_1}S_0+S_1\overline{S_0}\,\overline{T_B}+S_1\overline{S_0}T_B\\&=\overline{S_1}S_0+S_1\overline{S_0}(\overline{T_B}+T_B)\\&=\overline{S_1}S_0+S_1\overline{S_0}\\&=S_1\oplus S_0\end{align*}
    $$

    | $T_AT_B/S_1S_0$ | 00 | 01 | 11 | 10 |
    | --- | --- | --- | --- | --- |
    | 00 | 0 | 1 | 0 | 1 |
    | 01 | 0 | 1 | 0 | 1 |
    | 11 | 0 | 1 | 0 | 1 |
    | 10 | 0 | 1 | 0 | 1 |

    $$
    \begin{align*}S_1^\prime&=S_1\oplus S_0\\S_0^\prime&=\overline{S_1}\,\overline{S_0}\,\overline{T_A}+S_1\overline{S_0}\,\overline{T_B}\end{align*}
    $$


- Similarly, Ben writes an output table(Table 3.5) indicating, for each state, what the output should be in that state. Again, it is straightforward to read off and simplify the Boolean equations for the outputs.

    $$
    \begin{align*}L_{A1}&=S_1\\L_{A0}&=\overline{S_1}S_0\\L_{B1}&=\overline{S_1}\\L_{B0}&=S_1S_0\end{align*}
    $$

    ![Screenshot 2023-02-02 at 11.37.27.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-02_at_11.37.27.png)

    | $S_1^\prime$ | $S_0^\prime$ | $L_{A1}$ | $L_{A0}$ | $L_{B1}$ | $L_{B0}$ |
    | --- | --- | --- | --- | --- | --- |
    | 0 | 0 | 0 | 0 | 1 | 0 |
    | 0 | 1 | 0 | 1 | 1 | 0 |
    | 1 | 0 | 1 | 0 | 0 | 0 |
    | 1 | 1 | 1 | 0 | 0 | 1 |
- Finally, Ben sketches his Moore FSM in the form of Figure 3.22(a).
    - **First**, he draws the 2-bit state **register**(because there are four states), as shown in Figure 3.26(a). On each clock edge, the state register copies the next state, $S_{1:0}^\prime$, to become the state $S_{1:0}$. The state register receives a synchronous or asynchronous reset to initialize the FSM at startup.
    - **Then**, he draws the **next state logic**, based on Equation 3.2, which **computes the next state from the current state and inputs**, as shown in Figure 3.26(b).
    - **Finally**, he draws the **output logic**, based on Equation 3.3, which computes the outputs from the current state, as shown in Figure 3.26(c).

        $$
        \begin{align*}S_1^\prime&=S_1\oplus S_0\\S_0^\prime&=\overline{S_1}\,\overline{S_0}\,\overline{T_A}+S_1\overline{S_0}\,\overline{T_B}\end{align*}
        $$


    ![Screenshot 2023-02-01 at 15.28.36.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-01_at_15.28.36%201.png)

    ![Screenshot 2023-02-02 at 14.33.56.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-02_at_14.33.56.png)

- Figure 3.27 shows a timing diagram illustrating the traffic light controller going through a sequence of states. The diagram shows CLK, Reset, the inputs $T_A$ and $T_B$, next state $S^\prime$, state $S$, and outputs $L_A$ and $L_B$.
- Arrows indicate causality; for example, **changing the state** causes the **outputs to change**, and **changing the inputs** causes the **next state to change**($T_A$ and $\overline{T_A}$).
- The clock has a 5-second period, so the traffic lights change at most once every 5 seconds. When the finite state machine is first turned on, its state is unknown, as indicated by the question marks. Therefore, the system should be reset to put it into a known state. In this timing diagram, $S$ immediately resets to $S0$, indicating that asynchronously resettable flip-flops are being used. In state $S0$, light $L_A$ is green and light $L_B$ is red.
- In this example, traffic arrives immediately on Academic Ave. Therefore, the controller remains in state $S0$, keeping $L_A$ green even though traffic arrives on Bravado Blvd. and starts waiting. After 15 seconds, the traffic on Academic Ave. has all passes through and $T_A$ falls. At the following clock edge, the controller proceeds to state S2 in which $L_A$ turns red and $L_B$ turns green.  The controller waits in state $S_2$ until all the traffic on Bravado Blvd. has passes through. It then proceeds to state  $S3$, turning $L_B$ yellow. 5 seconds later, the controller enters state $S0$, turning $L_B$ red and $L_A$ green. The process repeats.
- 详细解释：首先来看CLK,CLK以5s为周期,每经过5s就会迎来一个clock edge, 届时会更新当前的state. 初始阶段会有一个Reset, 这个Reset不需要来深究, 基本能够理解它会把状态置为S0,同时相应的灯变成绿色($L_A$)和红色($L_B$).在这样的current state和input之下, $T_A$保持HIGH, 会导致next state依然对应的是S0.

    由于经过一定的时间(15s)之后, $T_A$ 变为LOW, 这导致next state由S0变成了S1, 在clock edge到来的时候, current state 和当前灯的颜色都会发生变化(current state变为S1, 当前灯的颜色分别变为了黄色和红色), 此时next state也会随着current state 和 input的变化而变为S2, 这样在clock edge到来的时候, current state 和当前灯的颜色都会发生变化(current state变为S2，当前灯的颜色分别变为了红色和绿色).

    在某一个时间点之后, $T_B$变为LOW,这导致next state由S2变为S3,这样等clock edge到来的时候, current state 和当前灯的颜色都会发生变化(current state变为S3, 当前灯的颜色分别变为了红色和黄色), 此时next state也会随着current state 和 input的变化而变为S0,这样在clock edge到来的时候, current state 和当前灯的颜色都会发生变化(current state变为S0，当前灯的颜色分别变为了绿色和红色).

    ![Screenshot 2023-02-01 at 15.28.36.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-01_at_15.28.36%202.png)

    ![Screenshot 2023-02-02 at 17.20.57.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-02_at_17.20.57.png)

    ![Screenshot 2023-02-02 at 22.50.31.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-02_at_22.50.31.png)

</aside>

<h3 id="342-state-encodings">3.4.2 State Encodings</h3>
<aside>
📖 **Important takeaways**

- One important decision in **state encoding** is the choice between **binary encoding** and **one-hot encoding**.
    - With **binary encoding**, as was used in the traffic light controller example, **each state is represented as a binary number**. Because $K$ binary numbers can be represented by $\log_2K$ bits, **a system with $K$ states only needs $\log_2K$ bits of state(more accurately, $\big\lceil\log_2K\big\rceil$)**.
    - In **one-hot encoding**, **a separate bit of state is used for each state**. It is called one-hot because only one-bit is “hot” or TRUE at any time. **For example. a one-hot encoded FSM with three states would have state encodings of 001, 010, and 100**. **Each bit of state is stored in a flip-flop, so one-hot encoding requires more flip-flops than binary encoding**. However, with one-hot encoding, the next-state and output logic is often simpler, so fewer gates are required. The best encoding choice depends on the specific FSM.
- one-hot state encoding example(traffic light problem)


    | State | one-hot encoding |
    | --- | --- |
    | S0 | 0001 |
    | S1 | 0010 |
    | S2 | 0100 |
    | S3 | 1000 |

    | current state | $T_A$ | $T_B$ | next state |
    | --- | --- | --- | --- |
    | S0 | 0 | X | S1 |
    | S0 | 1 | X | S0 |
    | S1 | X | X | S2 |
    | S2 | X | 0 | S3 |
    | S2 | X | 1 | S2 |
    | S3 | X | X | S0 |

![Screenshot 2023-02-05 at 09.24.35.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_09.24.35.png)

![Screenshot 2023-02-05 at 09.25.25.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_09.25.25.png)

![Screenshot 2023-02-05 at 09.49.07.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_09.49.07.png)

| $S_3$ | $S_2$ | $S_1$ | $S_0$ | $T_A$ | $T_B$ | $S_3^\prime$ | $S_2^\prime$ | $S_1^\prime$ | $S_0^\prime$ |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 0 | 0 | 0 | 1 | 0 | X | 0 | 0 | 1 | 0 |
| 0 | 0 | 0 | 1 | 1 | X | 0 | 0 | 0 | 1 |
| 0 | 0 | 1 | 0 | X | X | 0 | 1 | 0 | 0 |
| 0 | 1 | 0 | 0 | X | 0 | 1 | 0 | 0 | 0 |
| 0 | 1 | 0 | 0 | X | 1 | 0 | 1 | 0 | 0 |
| 1 | 0 | 0 | 0 | X | X | 0 | 0 | 0 | 1 |

| $S_3$ | $S_2$ | $S_1$ | $S_0$ | $L_{A1}$ | $L_{A0}$ | $L_{B1}$ | $L_{B0}$ |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 |
| 0 | 0 | 1 | 0 | 0 | 1 | 1 | 0 |
| 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0 |
| 1 | 0 | 0 | 0 | 1 | 0 | 0 | 1 |
- **Common Error(!!!)**
    - **Incorrect Version**

        $$
        S_3^\prime=\overline{S_3}S_2\overline{S_1}\,\overline{S_0}\,\overline{T_B}
        $$

    - **Correct Version**


        $$
        S_3^\prime=S_2\overline{T_B}
        $$

        $$
        S_2^\prime=S_1+S_2T_B
        $$

        $$
        S_1^\prime=S_0\overline{T_A}
        $$

        $$
        S_0^\prime=S_0T_A+S_3
        $$

        $$
        L_{A1}=S_2+S_3
        $$

        $$
        L_{A0}=S_1
        $$

        $$
        ⁍
        $$

        $$
        L_{B_0}=S_3
        $$

        这样做的原因是在one-hot encoding中，如果有一项被设定为HIGH，即1，其它几项就自动为0了，这是one-hot encoding的定义所决定的，因此我们不需要诸如$\overline{S_3}$, $\overline{S_1}$, $\overline{S_0}$等项。

- 参考电路图


    ![Screenshot 2023-02-05 at 09.57.09.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_09.57.09.png)

    - 在左侧的电路图中有一个问题，当Reset=1时，默认$S_3,S_2,S_1,S_0$都被置为0，但是0000并不对应我们想要的初始状态S0,因为在one-hot encoding中，初始状态S0对应的是0001。
    - 改进的方法就是让前三个都是resettable flip-flop，而把最下面的一个换成settable flip-flop。
</aside>

<h3 id="343-moore-and-mealy-machines">3.4.3 Moore and Mealy Machines</h3>
<aside>
📖 **Important takeaways**

- So far, we have shown examples of Moore machines, in which the output depends only on the state of the system. Hence, in state transition diagrams for Moore machines, the outputs are labeled in the circles.
- Recall that Mealy machines are much like Moore machines, but the outputs can depend on inputs as well as the current state. Hence, in state transition diagrams for Mealy machines, the outputs are labeled on the arcs instead of in the circles.
- The block of combinational logic that computes the outputs uses the current state and inputs, as was shown in Figure 3.22(b).

![Screenshot 2023-02-02 at 10.01.57.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-02_at_10.01.57.png)

![Screenshot 2023-02-01 at 15.28.36.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-01_at_15.28.36.png)

![Screenshot 2023-02-05 at 10.23.38.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_10.23.38.png)

![Screenshot 2023-02-05 at 10.24.08.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_10.24.08.png)

- **Moore FSM**
    - 对于这样一个问题，首先我们要做的也是画出FSM的state transition diagram。首先在Reset之后，进入到了S0状态，S0状态说白了就是一片空白，没有任何我们想要的序列。进入到了S0状态后，如果当前的输入是0，那么我们就由S0状态进入到了S1状态，我们现在攒够了目标01中的第一个数字0，如果在进入到S0状态之后，当前输入的数字是1，那么我们依然停留在S0状态，因为我们的目标序列是01，当前单独给一个1，并且在这个1前并没有0是毫无意义的，我们依然没有作出任何有效的推进工作，所以停留在S0的状态。
    - 当我们进入到S1状态后，如果当前的输入是1，那么很好，我们已经凑够了01两个序列进入到S2状态，S2状态是1，意味着符合要求，此时可以输出😊。而当我们进入到S1状态后，如果当前的输入是0，那么我们不会进入到S2状态，依然停留在S1状态，即我们有效的数字依然只有01中的0，还缺1个1。
    - 进入到S2状态后，如果当前的输入是1，我们会退回S0这个一穷二白的状态。如果当前的输入是0，那么我们就已经攒够了一个新的01序列中的第一个数字0，因此我们又一次进入到了S1状态，这便是对于Moore FSM state transition diagram的解释。
    - 而对于Mealy FSM而言，在arc上遵循的是input/output的格式，例如当前若处于S0状态，若输入是0，则进入S1状态，输出为0，因此从S0到S1有一个arc，上面写着0/0。当前若处于S0状态，若输入是1，则仍然停留在S0状态，输出为0，因此从S0到S0有一个arc，上面写着0/0。当前若处于S1状态，若输入为1，则输出为1，同时回退到S0的状态，因此从S1到S0有一个arc，上面写着1/1。当前若处于S1状态，若输入为0，则输出为0，同时依然停留在S1的状态，因此从S1到S1有一个arc，上面写着0/0。
    - 我们接下来还是来写出Moore FSM的state transition table，对于state encoding，我们采取如下的格式，S0: 00, S1: 01, S2: 10, 我们采用的是binary encoding, 没有采用one-hot encoding法。


        | $S_1$ | $S_0$ | Inputs(A) | $S_1^\prime$ | $S_0^\prime$ |
        | --- | --- | --- | --- | --- |
        | 0 | 0 | 0 | 0 | 1 |
        | 0 | 0 | 1 | 0 | 0 |
        | 0 | 1 | 0 | 0 | 1 |
        | 0 | 1 | 1 | 1 | 0 |
        | 1 | 0 | 0 | 0 | 1 |
        | 1 | 0 | 1 | 0 | 0 |

        $$
        \begin{align*}S_1^\prime&=\overline{S_1}S_0A\\S_0^\prime&=\overline{A}\end{align*}
        $$

        如何得到$S_0^\prime=\overline{A}$，一方面可以通过观察state transition table得出结论，另一方面可以通过Karnaugh map得出结论。

        | $A/S_1S_0$ | 00 | 01 | 11 | 10 |
        | --- | --- | --- | --- | --- |
        | 0 | 1 | 1 | X | 1 |
        | 1 | 0 | 0 | X | 0 |
    - 在得到Moore FSM的state transition table后，我们下一步的任务就是画出output table。


        | $S_1$ | $S_0$ | output(Y) |
        | --- | --- | --- |
        | 0 | 0 | 0 |
        | 0 | 1 | 0 |
        | 1 | 0 | 1 |

        $$
        Y=S_1
        $$


- **Mealy FSM**
    - **Mealy transition & output table**

        对于Mealy FSM来说，其transition table和output table是画在一起的。特别注意，相比于Moore FSM，在这个具体的问题中Mealy FSM的state变成了2，比Moore FSM少一个，因此只需要1 bit即可表示，不需要2 bits。  

        | $S_0$ | input(A) | $S_0^\prime$ | output(Y) |
        | --- | --- | --- | --- |
        | 0 | 0 | 1 | 0 |
        | 0 | 1 | 0 | 0 |
        | 1 | 0 | 1 | 0 |
        | 1 | 1 | 0 | 1 |

        $$
        \begin{align*}S_0^\prime&=\overline{S_0}\,\overline{A}+S_0\overline{A}=\overline{A}\\Y&=S_0A\end{align*}
        $$


![Screenshot 2023-02-05 at 11.47.16.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_11.47.16.png)

![Screenshot 2023-02-05 at 11.45.43.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_11.45.43.png)

![Screenshot 2023-02-05 at 11.24.50.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_11.24.50.png)

![Screenshot 2023-02-05 at 11.47.48.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_11.47.48.png)

![Screenshot 2023-02-05 at 11.45.54.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_11.45.54.png)

![Screenshot 2023-02-05 at 11.25.12.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_11.25.12.png)

![Screenshot 2023-02-05 at 11.43.29.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_11.43.29.png)

![Screenshot 2023-02-05 at 11.44.10.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_11.44.10.png)

- The Moore and Mealy machine schematics are shown in Figure 3.31. The timing diagrams for each machine are shown in Figure 3.32. The two machines follow a different sequence of states. Moreover, **the Mealy machine’s output rises a cycle sooner because it responds to the input rather than waiting for the state change**. If the Mealy output was delayed through a flip-flop, it would match the Moore output. When choosing your FSM design style, consider when you want your outputs to respond.
- 背后的逻辑就是当输入由0转1的时候，Moore FSM必须等待下一个clock edge转变为state S2的时候才会输出1，但是Mealy FSM利用state S1和刚刚由0转1的输入直接就可以进行输出，因此Mealy FSM相较Moore FSM输出提前。
- 如果当input发生变化后，我们要求output无延迟立刻跟随其作出变化，那么就需要使用Mealy FSM。
</aside>

<h2 id="35-timing-of-sequential-logic">3.5 Timing of Sequential Logic</h2>
<h3 id="350-timing-of-sequential-logic">3.5.0 Timing of Sequential Logic</h3>
<aside>
📖 **Background**

- Recall that a flip-flop copies the input $D$ to the output $Q$ on the rising edge of the clock. This process is called **sampling $D$ on the clock edge**. If $D$ is stable at either 0 or 1 when the clock rises, this behavior is clearly defined. But what happens if $D$ is changing at the same time the clock rises?
- This problem is similar to that faced by a camera when snapping a picture. Imagine photographing a frog jumping from a lily pad into a lake. If you take the picture before the jump, you will see a frog on a lily pad(stable). If you take the picture after the jump, you will see ripples in the water(stable). But if you take it just as the frog jumps, you may see a blurred image of the frog stretching from the lily pad into the water.
- A camera is characterized by its aperture time, during which the object must remain still for a sharp image to be captured. Similarly, a sequential element has an aperture time around the clock edge, during which the input must be stable for the flip-flop to produce a well-defined output.
- The aperture of a sequential element is defined by a setup time and a hold time, before and after the clock edge, respectively. Just as the static discipline limited us to using logic levels outside the forbidden zone, the dynamic discipline limits us to using signals that change outside the aperture time.
- By taking advantage of the dynamic discipline, we can think of time in discrete units called clock cycles, just as we think of signal levels as discrete 1’s and 0’s. A signal may glitch and oscillate wildly for some bounded amount of time. Under the dynamic discipline, we are concerned only about its final value at the end of the clock cycle, after it has settled to a stable value. Hence, we can simply write $A[n]$, the value of signal $A$ at the end of the $n\mathrm{th}$ clock cycle, where $n$ is an integer, rather than $A(t)$, the value of $A$ at some instant $t$, where $t$ is any real number.
- The clock period has to be long enough for all signals to settle. This sets a limit on the speed of the system. In real systems, the clock does not reach all flip-flops at precisely the same time. This variation in time, called clock skew, further increases the necessary clock period.
- Sometimes it is impossible to satisfy the dynamic discipline, especially when interfacing with the real world. For example, consider a circuit with an input coming from a button. A monkey might press the button just as the clock rises. This can result in a phenomenon called metastability, where the flip-flop captures a value partway between 0 and 1 that can take an unlimited amount of time to resolve into a good logic value. The solution to such asynchronous inputs is to use a synchronizer, which has a very small(but nonzero) probability of producing an illegal logic value.
- We expand on all of these ideas in the rest of this section.
</aside>

<h3 id="351-the-dynamic-discipline">3.5.1 The Dynamic Discipline</h3>
<aside>
📖 **Important takeaways(From the video lecture)**

- Synchronous sequential circuit inputs must be stable during aperture(setup and hold) time around clock edge.
- Specifically, inputs must be stable
    - at least $t_{setup}$ before the clock edge
    - at least until $t_{hold}$ after the clock edge
- The delay between registers has a minimum and maximum delay, dependent on the delays of the circuit elements.
    - minimum delay $=t_{ccq}+t_{cd}+t_{setup}$.
    - maximum delay $=t_{pcq}+t_{pd}+t_{setup}$.

    ![Screenshot 2023-02-05 at 21.02.00.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_21.02.00.png)

    ![Screenshot 2023-02-05 at 21.04.14.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_21.04.14.png)

</aside>

<h3 id="352-system-timing">3.5.2 System Timing(!!!)</h3>
<aside>
📖 **Important takeaways**

- **Clock period(cycle time)**
    - The clock period or cycle time, $T_c$, is the time between rising edges of a repetitive clock signal. Its reciprocal, $f_c=1/T_c$, is the clock frequency.
    - All else being the same, increasing the clock frequency increases the work that a digital system can accomplish per unit time.
    - Frequency is measured in units of Hertz(Hz), or cycles per second: 1 megahertz(MHz) = $10^6$ Hz, and 1 gigahertz(GHz) = $10^9$ Hz.
    - Figure 3.38(a) illustrates a generic path in a synchronous sequential circuit whose clock period we wish to calculate. On the rising edge of the clock, register R1 produces output(or outputs) Q1. These signals enter a block of combinational logic, producing D2, the input(or inputs) to register R2.
    - The timing diagram in Figure 3.38(b) shows that each **output signal may start to change a contamination delay after its input changes** and **settles to the final value within a propagation delay after its input settles**.
    - The **gray arrows** represent **the contamination delay through R1 and the combinational logic**, and the **blue arrows** represent **the propagation delay through R1 and the combinational logic**.
    - We analyze the timing constraints with respect to the setup and hold time of the second register, R2.

    ![Screenshot 2023-02-05 at 18.09.36.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_18.09.36.png)


- **Setup Time Constraints(also called cycle time constraints)**
    - Depends on the maximum delay from register R1 through combinational logic to R2.
    - The input to register R2 must be stable at least $t_{setup}$ before clock edge.

    $$
    T_c\ge t_{pcq}+t_{pd}+t_{setup}
    $$

    $$
    t_{pd}\le T_c-(t_{pcq}+t_{setup})
    $$

    - $t_{pcq}+t_{setup}$ is called the sequencing overhead.

    ![Screenshot 2023-02-05 at 21.08.08.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_21.08.08.png)

    - Figure 3.39 is the timing diagram showing only the maximum delay through the path, indicated by the blue arrows. To satisfy the setup time of R2, D2 must settle no later than the setup time before the next clock edge.
    - Hence, we find an equation for the minimum clock period:

        $$
        T_c\ge t_{pcq}+t_{pd}+t_{setup}
        $$

    - In commercial designs, the clock period is often dictated by the Director of Engineering or by the marketing department(to ensure a competitive product). Moreover, the flip-flop clock-to-Q propagation delay and setup time, $t_{pcq}$ and $t_{setup}$, are specified by the manufacturer. Hence, we rearrange the equation above to solve for **the maximum propagation delay through the combinational logic($t_{pd}$), which is usually the only variable under the control of the individual designer**.

        $$
        t_{pd}\le T_c-(t_{pcq}+t_{setup})\,\,\,(3.14)
        $$

    - The term in parentheses, $t_{pcq}+t_{setup}$, is called the sequencing overhead. **Ideally**, the entire cycle time $T_c$ would be available for useful computation in the combinational logic, $t_{pd}$. **However, the sequencing overhead of the flip-flop cuts into this time**. Equation 3.14 is called the setup time constraint or max-delay constraint, because it depends on the setup time and limits the maximum delay through the combinational logic.
    - If the propagation delay through the combinational logic($t_{pd}$) is too great, D2 may not have settled to its final value by the time R2 needs it to be stable and samples it(稳定下来的时间在$t_{setup}$之后，这是不被允许的，必须至少在下一个clock edge前的$t_{setup}$就保持稳定). Hence, R2 may sample an incorrect result or even an illegal logic level, a level in the forbidden region. In such a case, the circuit will malfunction. The problem can be solved by increasing the clock period(增大$\,T_c\,$) or by redesiging the combinational logic to have a shorter propagation delay.

    ![Screenshot 2023-02-05 at 21.30.35.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_21.30.35.png)


- **Hold Time Constraints**
    - Depends on the minimum delay from register R1

    - The register R2 in Figure 3.38(a) also has a hold time constraint. Its input D2, must not change until some time, $t_{hold}$, after the rising edge of the clock. According to Figure 3.40, D2 might change as soon as $t_{ccq}+t_{cd}$ after the rising edge of the clock. Hence, we find

        $$
        t_{ccq}+t_{cd}\ge t_{hold}
        $$

    - Again, $t_{ccq}$ and $t_{cd}$ are characteristics of the flip-flop that are usually outside the designer’s control. Rearranging, we can solve for the minimum contamination dealy through the combinational logic

- **Input Timing Constraints**
    - Setup time: $t_{setup}=$ time before clock edge data must be stable
    - Hold time: $t_{hold}=$ time after clock edge data must be stable
    - Aperture time: $t_a=$ time around clock edge data must be stable

        $$
        t_a=t_{setup}+t_{hold}
        $$

- 具体来讲，这些input timing constraints在微观上到底来源于什么呢，这时候我们需要展开来看D flip-flop的微观结构。一个D flip-flop是由两个D latch组成的，当CLK=0时，左边的master D latch是处在transparent的状态，而右侧的slave D latch是处在opaque的状态，此时D的信号可以通过master D latch传送到N1的位置，但由于右侧的slave D latch是处在opaque的状态，N1信号无法通过右侧的slave D latch传递到Q。因此我们说$\,t_{setup}\,$本质上就对应着信号在clock edge发生以前信号从$\,D\,$传导到中间的N1的过程。因为如果信号在clock edge之前一直都处于波动状态，中间的N1处接收到的信号处于波动不规律的状态，那么我们最终获得的信号也一定不会是我们想要的。
- 当clock edge发生的时候，CLK会由0变为1，此时右侧的slave D latch处在transparent的状态，中间的internal node N1处的信号会通过右侧的slave D latch传递到Q处。但是由于左侧的分支有一个inverter，而这个inverter存在延时，也就是说当clock edge到来的时候，CLK由0变为1，但是左侧分支并不是立刻由1变为0，中间经历了短暂的时间才会由1变为0，而在这个短暂的时间间隔之内，左侧的master D latch其实还处于短暂的transparent的状态，也就是说D处的信号仍能在这个时间间隙中通过master D latch到达中间的N1，同时通过右侧的slave D latch最终传送到Q，那么在这个短暂的时间$\,t_{hold}\,$内，我们要求信号必须保持稳定，因为D仍然处在sampling的状态中，所以我们说$\,t_{hold}\,$在微观电路中对应的其实是inverter的延时(delay)。

![Screenshot 2023-02-05 at 14.43.36.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_14.43.36.png)

![Screenshot 2023-02-05 at 14.47.48.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_14.47.48.png)

- **Output Timing Constraints**
    - Propagation delay: $t_{pcq}=$ time after the clock edge that $Q$ is guaranteed to be stable(i.e., to stop changing): maximum delay. 从clock的change到Q的change之间经历的最长的时间长度(Q change最晚时间)。
    - Contamination delay: $t_{ccq}=$ time after the clock edge that $Q$ might be unstable(i.e., start changing): minimum delay.从clock的change到Q的change之间经历的最短的时间长度(Q change最早时间)
    - 当出现clock edge的时候，Q处的输出结果会被更新，Q处的输出结果来源于internal node N1，但是N1的信号传到Q处需要时间，因为从N1到Q中间还隔着一个L2 slave latch，这个slave latch存在delay，这两种delay可以被认为成是slave D latch(L2)的最长延时与最短延时。
    - 在$\,t_{ccq}\,$和$\,t_{pcq}\,$之间, Q的信号会发生波动变化。而在$\,t_{ccq}\,$和$\,t_{pcq}\,$之外, Q的信号不会发生波动变化。
    - When the clock rises, the output(or outputs) may start to change after the clock-to-Q contamination delay, $t_{ccq}$, and must definitely settle to the final value within the clock-to-Q propagation delay, $t_{pcq}$. These represent the fastest and slowest delays throught the circuit, respectively.

![Screenshot 2023-02-05 at 16.21.10.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_16.21.10.png)

![Screenshot 2023-02-05 at 16.21.46.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-05_at_16.21.46.png)

</aside>

<h1 id="5-digital-building-blocks">5 Digital Building Blocks</h1>
<h2 id="51-introduction">5.1 Introduction</h2>
<aside>
📖 **Background**

- Up to this point, we have examined the design of combinational and sequential circuits using Boolean equations, schematics, and HDLs.
- This chapter introduces **more elaborate combinational and sequential building blocks** used in digital systems.
- These blocks include **arithmetic circuits**, **counters**, **shift registers**, **memory arrays**, and **logic arrays**.
- These building blocks are not only useful in their own right, but they also demonstrate the principles of hierarchy, modularity, and regularity.
- The building blocks are hierarchically assembled from simpler components such as logic gates, multiplexers, and decoders.
- Each building block has a well defined interface and can be treated as a black box when the underlying implementation is unimportant.
- The regular structure of each building block is easily extended to different sizes.
- In Chapter 7, we use many of these building blocks to build a microprocessor.

![Screenshot 2023-02-06 at 07.00.06.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_07.00.06.png)

![Screenshot 2023-02-06 at 07.01.39.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_07.01.39.png)

> Digital circuits such as logic gates restrict the voltages to discrete ranges, which we will use to indicate 0 and 1. In **logic** design, we build **more complex structures**, such as adders or memories, **from digital circuits**.
> 

> **Microarchitecture links the logic and architecture levels of abstraction**. The architecture level of abstraction describes a computer from a programmer’s perspective. For example, the Intel x86 architecture used by microprocessors in most personal computer(PCs) is defined by a set of instructions and registers(memory for temporarily storing values) that the programmer is allowed to use. **Microarchitecture involves combining logic elements to execute the instructions defined by the architecture**. A particular architecture can be implemented by one of many different microarchitecture with different price/performance/power trade-offs. For example, the Intel Core i7, the Intel 80486, and the AMD Athlon all implement the x86 architecture with different microarchitectures.
> 
</aside>

<h2 id="52-arithmetic-circuits">5.2 Arithmetic Circuits</h2>
<h3 id="520-background">5.2.0 Background(!!!)</h3>
<aside>
📖 **Background**

- **Arithmetic circuits are the central building blocks of computers**.
- Computers and digital logic perform many arithmetic functions:
    1. addition
    2. subtraction
    3. comparisons
    4. shifts
    5. multiplication
    6. division
- This section describes hardware implementation for all of these operations.
</aside>

<h3 id="521-addition">5.2.1 Addition(!!!)</h3>
<aside>
📖 **Important takeaways**

- **Addition is one of the most common operations in digital systems**. We first consider how to **add two 1-bit binary numbers**. We then extend to **N-bit binary numbers**. Adders also illustrate **trade-offs between speed and complexity**.

- **Half Adder(!!!)**
    - We begin by building a 1-bit half adder. As shown in Figure 5.1, the half adder has two inputs, A and B, and **two outputs**, $S$, and $C_{out}$.
    - $S$ is the sum of A and B. If A and B are both 1, $S$ is 2, **which cannot be represented with a single binary digit**. Instead, it is **indicated with a carry out $C_{out}$ in the next column**. The half adder can be built from an XOR gate and an AND gate.
    - In a multi-bit adder, $C_{out}$ is added or carried in to the next most significant bit. For example, in Figure 5.2, the carry bit shown in blue is the output $C_{out}$ of the first column of 1-bit addition and the input $C_{in}$ to the second column of addition.
    - However, the half adder lacks a $C_{in}$ input to accept $C_{out}$ of the previous column. The full adder, described in the next section, solves this problem.
    - 注意这里解决此类问题的通用方法就是写出truth table，然后根据truth table写对应的Boolean equations。

    $$
    \begin{align*}S&=A\oplus B\\C_{out}&=AB\end{align*}
    $$


![Screenshot 2023-02-06 at 07.22.46.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_07.22.46.png)

![Screenshot 2023-02-06 at 07.22.59.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_07.22.59.png)

| A | B | $S$ | $C_{out}$ |
| --- | --- | --- | --- |
| 0 | 0 | 0 | 0 |
| 0 | 1 | 1 | 0 |
| 1 | 0 | 1 | 0 |
| 1 | 1 | 0 | 1 |

- **Full Adder(!!!)**

![Screenshot 2023-02-06 at 08.33.27.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_08.33.27.png)

![Screenshot 2023-02-06 at 08.34.10.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_08.34.10.png)

| A | B | $C_{in}$ | $S$ | $C_{out}$ |
| --- | --- | --- | --- | --- |
| 0 | 0 | 0 | 0 | 0 |
| 0 | 0 | 1 | 1 | 0 |
| 0 | 1 | 0 | 1 | 0 |
| 0 | 1 | 1 | 0 | 1 |
| 1 | 0 | 0 | 1 | 0 |
| 1 | 0 | 1 | 0 | 1 |
| 1 | 1 | 0 | 0 | 1 |
| 1 | 1 | 1 | 1 | 1 |

$$
\begin{align*}S&=A\oplus B\oplus C_{in}\\C_{out}&=AB+BC_{in}+C_{in}A\\&=AB+(A\oplus B)C_{in}\end{align*}
$$

![Screenshot 2023-02-07 at 20.40.11.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_20.40.11.png)

- **Carry propagate adder**
    - An N-bit adder sums two N-bit inputs, A and B, and a carry in $C_{in}$ to produce an N-bit result $S$ and a carry out $C_{out}$.
    - It is commonly called a carry propagate adder(CPA) because the carry out of one bit propagates into the next bit. The symbol for a CPA is shown in Figure 5.4; it is drawn just like a full adder except that A, B and $S$ are busses rather than single bits.
    - Three common CPA implementations are called ripple-carry adders, carry-lookahead adders, and prefix adders.

    ![Screenshot 2023-02-06 at 08.48.43.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_08.48.43.png)

    ![Screenshot 2023-02-06 at 08.56.02.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_08.56.02.png)

    ![Screenshot 2023-02-06 at 08.46.54.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_08.46.54.png)

- **Ripple-Carry Adder**
    - The simplest way to build an **N-bit carry propagate adder** is to **chain together N full adders**.
    - The $C_{out}$ of one stage acts as the $C_{in}$ of the next stage, as shown in Figure 5.5 for 32-bit addition. This is called a **ripple-carry adder**.
    - It is a good application of modularity and regularity: the full adder module is reused many times to form a larger system.
    - The ripple-carry adder has the advantage of being slow when $N$ is large. $S_{31}$ depends on $C_{30}$, which depends on $C_{29}$, which depends on $C_{28}$, and so forth all the way back to $C_{in}$, as shown in Figure 5.5. We say that the carry ripples through the carry chain.
    - The delay of the adder, $t_{ripple}$, grows directly with the number of bits, as given in Equation 5.1, where $t_{FA}$ is the delay of a full adder.

        $$
        t_{ripple}=Nt_{FA}
        $$


    > Schematics typically show signals flowing from left to right. Arithmetic circuits break this rule because the carries flow from right to left(from the least significant column to the most significant column).
    > 

    ![Screenshot 2023-02-06 at 08.58.37.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_08.58.37.png)

    ![Screenshot 2023-02-06 at 09.36.16.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_09.36.16.png)

    ![Screenshot 2023-02-06 at 09.36.40.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_09.36.40.png)

- **Carry-Lookahead Adder(!!!)**
    - The fundamental reason that **large ripple-carry adders are slow** is that **the carry signals must propagate through every bit in the adder**.
    - A **carry-lookahead adder(CLA)** is another type of carry propagate adder that solves this problem by **dividing the adder into blocks** and providing circuitry to **quickly determine the carry out of a block** as soon as the **carry in is known**. For example, a 32-bit adder may be divided into eight 4-bit blocks.
    - CLAs use generate(G) and propagate(P) signals that describe how a column or block determines the carry out.
    - The $i$th column of an adder is said to **generate a carry** if it **produces a carry out independent of the carry in**. The $i$th column of an adder is guaranteed to **generate a carry $C_i$ if $A_i$ and $B_i$ are both 1**. Hence $G_i$, the generate signal for column $i$, is calculated as $G_i=A_iB_i$.
    - The column is said to **propagate a carry** if it **produces a carry out whenever there is a carry in**. The $i$th column will **propagate a carry in, $C_{i-1}$, if either $A_i$ or $B_i$ is 1**. Thus, $**P_i=A_i+B_i**$.
    - Using these definitions, we can rewrite the carry logic for a particular column of the adder. The $i$th column of an adder will generate a carry out $C_i$ if it either generates a carry, $G_i$, or propagates a carry in, $P_iC_{i-1}$. In equation form($C_i$ is actually $C_{out}$, and $C_{i-1}$ is actually $C_{in}$)

        $$
        C_i=G_i+P_iC_{i-1}=A_iB_i+(A_i+B_i)C_{i-1}
        $$


    ![Screenshot 2023-02-06 at 14.38.21.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_14.38.21.png)

    ![Screenshot 2023-02-06 at 15.00.15.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_15.00.15.png)

    - 这里我们需要注意一下角标的问题，两个$N$-bit的数来作加法，我们从右向左从0开始进行标号，$G_i\,$和$\,P_i\,$的角标都不存在任何的问题，唯一需要注意的就是$\,C_i\,$的角标问题，首先$\,C_i\,$的定义是十分明确的，它和$\,G_i$, $P_i\,$一样，都是针对当前这一位来讨论的。因此$\,C_i=G_i+P_iC_{i-1}\,$这个公式本身的逻辑是没有问题的，它阐述的就是当前第$\,i\,$列的进位$(C_i)$来自两个地方，首先是第$\,i\,$列 generate 出的 carry($\,G_i\,$)，其次是第来自$\,i-1\,$列的进位($\,C_{i-1}\,$)恰巧可以在第$\,i\,$列得到传导($\,P_i\,$).
    - 但是我们通过上方最右侧的图可以看出$\,C_i\,$其实是标注在了第$\,i+1\,$列上，这也就解释了为什么最右侧第零列上方的进位是$C_{-1}$，同时$C_{-1}$的值其实是可以人为设定的，$C_{-1}\,$取1可以，取0也可以，看你需不需要一个初始的进位($C_{-1}$标注在右侧第0列上)，这一点需要特别关注一下。
    - The generate and propagate definitions extend to multiple-bit blocks.
        - A block is said to generate a carry if it produces a carry out independent of the carry in to the block.
        - The block is said to propagate a carry if it produces a carry out whenever there is a carry in to the block.
        - We define $G_{i:j}$ and $P_{i:j}$ as generate and propagate signals for blocks spanning columns $i$ through $j$.
    - A block generates a carry if the most significant column generates a carry, **or if the most significant column propagates a carry and the previous column generated a carry**, and so forth. For example, the generate logic for a block spanning column 3 through 0 is

        $$
        \begin{align*}G_{3:0}&=G_3+P_3G_2+P_3P_2G_1+P_3P_2P_1G_0\\&=G_3+P_3\big(G_2+P_2(G_1+P_1G_0)\big)\end{align*}
        $$

    - A block propagates a carry if all the columns in the block propagates the carry. For example, the propagate logic for a block spanning columns 3 through 0 is

        $$
        P_{3:0}=P_3P_2P_1P_0
        $$

    - Using the block generate and propagate signals, we can quickly compute the carry out of the block, $C_i$, using the carry into the block, $C_{j-1}$.

        $$
        C_i=G_{i:j}+P_{i:j}C_{j-1}
        $$


    ![Screenshot 2023-02-06 at 14.41.51.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_14.41.51.png)

    ![Screenshot 2023-02-06 at 14.43.28.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_14.43.28.png)

    ![Screenshot 2023-02-06 at 16.41.49.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_16.41.49.png)

    ![Screenshot 2023-02-06 at 16.41.34.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_16.41.34.png)

    - 这里也有一些细节值得注意，首先例如写成$\,P_{3:0}$, $G_{3:0}$形式，并不意味着这两个信号是4-bit的，相反，这两个信号都是single-bit signal。$P_{3:0}$是block propagate signal，这个信号的含义是如果对这个block而言有一个carry-in，这个block是否能够传递出一个carry-out。对于左1图中的实际例子，指的就是$\,P_{3:0}\,$并不是一个4-bit signal，$P_{3:0}\,$是一个one-bit signal。如果$\,P_{3:0}\,$是1，那么意味着对于这个block(从第0列到第3列，总共4列的block)来说，如果它有carry-in(在这个具体的例子中指的就是$C_{-1}=1$),那么它最终会传导出一个carry-out，即($C_3=1$)。如果$\,P_{3:0}\,$是0，那么意味着对于这个block(从第0列到第3列，总共4列的block)来说，如果它有carry-in(在这个具体的例子中指的就是$C_{-1}=1$),那么它最终无法传导出一个carry-out，即($C_3=0$)。
    - $G_{3:0}\,$虽然在形式上像是一个4-bit的signal，但其实它也是single-bit signal，我们把$\,G_{3:0}\,$称作block. generate signal，这个信号的含义是若$G_{3:0}=1$，则不管外界到底有没有carry-in，由这个block本身就可以generate出进位(carry)，在上面左2图中的例子里具体指无论$\,C_{-1}=0$ 还是$\,C_{-1}=1$，$C_3=1$。若$G_{3:0}=1$，则仅由这个block本身是无法自己generate出进位的(注意这里的进位是指对于整个block而言，如果内部有进位但是整个block最后不能向下一个block传递一个进位的话也是没有用的)。接下来一个很重要的任务就是来思考$\,G_{3:0}\,$何时为1？通过思考，我们可以得到当$\,G_3=1\,$或$\,G_2=1,P_3=1\,$或$\,G_1=1,P_2=P_3=1\,$或$\,G_0=1,P_1=P_2=P_3=1$共计四种情况，因此我们可以把$\,G_{3:0}\,$写成如下的形式：

        $$
        \begin{align*}G_{3:0}&=G_3+P_3G_2+P_3P_2G_1+P_3P_2P_1G_0\\&=G_3+P_3\big(G_2+P_2(G_1+P_1G_0)\big)\end{align*}
        $$


    - Figure 5.6(a) shows a 32-bit carry-lookahead adder composed of eight 4-bit blocks. Each block contains a 4-bit ripple-carry adder and some lookahead logic to compute the carry out of the block given the carry in, as shown in Figure 5.6(b)

    $$
    \begin{align*}G_{3:0}&=G_3+P_3G_2+P_3P_2G_1+P_3P_2P_1G_0\\&=G_3+P_3\big(G_2+P_2(G_1+P_1G_0)\big)\\\\P_{3:0}&=P_3P_2P_1P_0\\\\C_i&=G_{i:j}+P_{i:j}C_{j-1}\\\\C_3(C_{out})&=G_{3:0}+P_{3:0}C_{-1}(C_{in})\\&=G_3+P_3\big(G_2+P_2(G_1+P_1G_0)\big)+P_3P_2P_1P_0C_{-1}(C_{in})\end{align*}
    $$

    ![Screenshot 2023-02-06 at 13.48.52.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_13.48.52.png)

    - 右图所示的32-bit CLA(carry-lookahead adder)是由8个4-bit blocks组成的。其中每一个4-bit block的内部结构都在右图中予以放大呈现。
    - 当把4-bit block放大来看，其实和4个ripple-carry adder串联在一起几乎没有区别，**唯一的区别就是我们找不到这个ripple-carry adder的$\,C_{out}\,$**. 而事实上$**\,C_{out}\,$作为整个block的输出是通过下面一个看起来较为复杂的电路来计算得到的**。也就是说这个4-bit block的carry-out是通过下方的电路来计算得到的。
    - 我们把$\,S_0,S_1,S_2,S_3\,$等称为sum bits，可以得知**sum bits依然是通过ripple-carry adder计算出来的，并不走下方的复杂电路**，即利用$\,A_0,B_0,C_{in}\,$计算得到$\,S_0\,$，同时进位得到$\,C_0\,$，利用$A_1,B_1,C_0\,$计算得到$\,S_1\,$，同时进位得到$\,C_1\,$，利用$\,A_2,B_2,C_1\,$计算得到$\,S_2\,$，同时进位得到$\,C_2\,$，利用$A_3,B_3,C_2\,$计算得到$\,S_3\,$，**但是$\,C_3\,$不需要这样一步一步倒腾出来，我们利用block的思想，可以更快的计算出$\,C_3\,$**。

        $$
        \begin{align*}C_3(C_{out})&=G_{3:0}+P_{3:0}C_{-1}(C_{in})\\&=G_3+P_3\big(G_2+P_2(G_1+P_1G_0)\big)+P_3P_2P_1P_0C_{-1}(C_{in})\end{align*}
        $$

    - 我们可以把$\,G_i\,$称作是column generate signal，把$\,P_i\,$称作是column propagate signal。把$\,G_{i:j}\,$称作是block generate signal，把$\,P_{i:j}\,$称作是block propagate signal。在右侧的图示中，如$\,G_{3:0}$，$P_{3:0}\,$通过图示的电路来计算，而我们在图中没有呈现出$\,G_i\,$和$\,P_i\,$的电路，前者用AND gate即可实现，后者用OR gate即可实现。

    ![Screenshot 2023-02-06 at 16.43.51.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_16.43.51.png)

    - 看起来上方图示中最底下的电路图也很恐怖，那么它相比于把full adder串联起来形成的ripple-carry adder到底速度有没有明显的提升呢？我们就来仔细分析一下这个问题！
    - 首先值得明确的是$\,A_0,A_1\cdots,A_{31}\,$以及$B_0,B_1,\cdots,B_{31}$在初始条件下就是已知量，因为我们要做的就是两个32-bit的数相加的工作，这两个数的每一位都是知道的，不需要进行任何的运算。在经过1个gate的delay后(AND gate或者OR gate)，所有的$\,G_i$，$P_i$都是已知的，注意这里所有的$\,G_i$，$P_i$同时已知。因为在每个full adder内部$\,G_i=A_iB_i\,$，$P_i=A_i+B_i$。
    - 对于上图所示的具体情况而言，刚才提到在经过1个gate的delay后(AND gate或者OR gate)，所有的$\,G_i$，$P_i$都是已知的。再经过6个gate的delay后，所有的block generate signal都是已知的，如$\,G_{3:0},G_{7:4},G_{11:8},\cdots$。当然在6个gate的delay之内，下方所有的block propagate signal也同时全部已知，如$\,P_{3:0},P_{7:4},P_{11:8},\cdots$。
    - 在得到所有的block generate signal和block propagate signal之后(前者根据图示比后者花费的时间要更长)，我们再需要2个gate的delay便可以由$\,C_{in},G_{3:0},P_{3:0}\,$得到$\,C_{out}\,$(block carry-out，即$\,C_3\,$)。
    - 在得到了$\,C_3\,$之后，接下来所有的block carry-out都可以仿照类似的方法瞬间得到，因为每一个block中，block generate signal 和 block propagate signal 已经准备好了，每一个block都在等待一个$\,C_{in}\,$，这个$\,C_{in}\,$不是别的，正是前一个block的block carry-out，这样如同连锁反应一样，我们在得到$\,C_3\,$后可以快速得到$\,C_7,C_{11},C_{15},C_{19},C_{23},C_{27},C_{31\,}$。

    ![Screenshot 2023-02-06 at 17.50.27.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_17.50.27.png)

    ![Screenshot 2023-02-06 at 17.50.30.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_17.50.30.png)

    ![Screenshot 2023-02-06 at 17.50.31.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_17.50.31.png)

    ![Screenshot 2023-02-06 at 17.50.33.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_17.50.33.png)

    - 上面一组图的图3指的就是得到$\,C_3\,$后可以快速得到$\,C_7,C_{11},C_{15},C_{19},C_{23},C_{27},C_{31\,}$的过程。
    - 上面一组图的图4说明的就是，最后一个block接收到$\,C_{27}\,$作为$\,C_{in}\,$，还必须要走4个full adder组成的4-bit block，这样才可以把最高的四位的结果算出来。
    - The AND and OR gates needed to compute the single-bit generate and propagate signals, $G_i$ and $P_i$, from $A_i$ and $B_i$ are left out for brevity($G_i=A_iB_i$, $P_i=A_i+B_i$, 用$\,A_i\,$和$\,B_i\,$再加上AND gate就可以构造出$\,G_i$, 用$\,A_i\,$和$\,B_i\,$再加上OR gate就可以构造出$\,P_i\,$). Again, the carry-lookahead adder demonstrates modularity and regularity.
    - All of the CLA blocks computer the single-bit and block generate and propagate signals simultaneously. The critical path starts with computing $G_0$ and $G_{3:0}$ in the first CLA block. $C_{in}$ then advances directly to $C_{out}$ through the AND/OR gate in each block until the last. For a large adder, this is much faster than waiting for the carries to ripple through each consecutive bit of the adder. Finally, the critical path through the last block contains a short ripple-carry adder. Thus, an $N$-bit adder divided into $k$-bit blocks has a delay


        $$
        t_{CLA}=t_{pg}+t_{pg\_block}+\bigg(\dfrac{N}{k}-1\bigg)t_{AND\_OR}+kt_{FA}
        $$

        这里面提到的-1，指的就是最后一次不用穿，得到$\,C_{27}\,$以后就可以了，紧接着跟着的是$\,kt_{FA}\,$。

        **在上面和下面的例子中$\,t_{pg\_block}\,$中经过的gate数量可以用下面的公式计算**

        $**G_{i:j}\,$对应$\,2\times(i-j)\,$个门，这也正是下面$\,t_{pg\_block}=6\times100\mathrm{ps}=600\mathrm{ps}\,$中 6 的来历。**

        ![Screenshot 2023-02-06 at 18.14.15.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_18.14.15.png)

        ![Screenshot 2023-02-06 at 18.06.45.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_18.06.45.png)

        where $t_{pg}$ is the delay of the individual generate/propagate gates(a single AND or OR gate) to generate $P_i$ and $G_i$, $t_{pg\_block}$ is the delay to find the generate/propagate signals $P_{i:j}$ and $G_{i:j}$ for a $k$-bit block, and $t_{AND\_OR}$ is the delay from $C_{in}$ to $C_{out}$ through the final AND/OR logic of the $k$-bit CLA block.

    - For $N>16$, the carry-lookahead adder is generally much faster than the ripple-carry adder. However, the adder delay still increases linearly with $N$.
- **Prefix Adder**
    - Prefix adders **extend the generate and propagate logic** of the **carry lookahead adder** to **perform addition even faster**.
    - They first compute G and P for pairs of columns, then for blocks of 4, then for blocks of 8, then 16, and so forth until the generate signal for every column is known. The sums are computed from these generate signals.(**我个人认为这个说法不够准确，应该说是generate signal for every block，例如$G_{i-1:-1}$**)
    - In other words, the strategy of a prefix adder is to **compute the carry in $C_{i-1}$**(注意这里说的是carry-in，下标是$\,i-1$) **for each column $i$** as quickly as possible, then to compute the sum, using

        $$
        S_i=(A_i\oplus B_i)\oplus C_{in}=(A_i\oplus B_i)\oplus C_{i-1}
        $$

    - Define column $i=-1$ to hold $C_{in}$, so $G_{-1}=C_{in}$ and $P_{-1}=0$。稍微解释一下这个是什么意思，首先$\,C_{in}\,$说白了就是$\,C_{-1}\,$。$C_{-1}\,$在标注的时候会标注到右侧第0列上。$C_{in}=C_{-1}=1\,$时，整个系统是有carry-in，这个carry-in可以看成是由列 -1 generate出来的，所以我们此时可以认为$\,G_{-1}=1\,$。$C_{in}=C_{-1}=0\,$时，整个系统没有carry-in，此时可以看成是列 -1 没有generate出来carry-in，所以我们此时可以认为$\,G_{-1}=0\,$。综上所述，我们可以让$\,C_{-1}=C_{in}$，同时$\,G_{-1}=C_{in}=C_{-1},P_{-1}=0$。

    ![Screenshot 2023-02-06 at 18.46.09.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_18.46.09.png)

    ![Screenshot 2023-02-06 at 14.59.22.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_14.59.22.png)

    - Then $C_{i-1}=G_{i-1:-1}$ because there will be a carry out of column $i-1$ if the block spanning columns $i-1$ through **-1** generates a carry. The generated carry is either generated in column $i-1$ or generated in a previous column and propagated.($**C_{i-1}=G_{i-1:-1}$是一个双向的转换关系，需要学会熟练使用，同时需要注意的是$C_{i-1}$是第$i-1$列的carry-out，同时也是第$\,i\,$列的carry-in**)

        这里是一个重点，因此详细地解释一下。这里的重点在于引入的$\,G_{-1}=C_{in}\,$。我们可以对比一下上面的两张图，其中提到了如下的两个等式：

        $$
        C_{i-1}=G_{i-1:-1}
        $$

        $$
        C_3=G_{3:0}+P_{3:0}C_{-1}
        $$

        为什么这两个等式看起来不太一样呢，其实就是$\,G_{-1}=C_{-1}=C_{in}\,$的一个细节。我们首先可以这样理解：

        $$
        \begin{align*}G_{3:-1}&=G_3+G_2P_3+G_1P_2P_3+G_0P_1P_2P_3+G_{-1}P_0P_1P_2P_3\\C_3&=G_{3:0}+P_{3:0}C_{-1}\\&=G_{3:0}+P_3P_2P_1P_0C_{-1}\\&=(G_3+G_2P_3+G_1P_2P_3+G_0P_1P_2P_3)+P_3P_2P_1P_0G_{-1}\\&=G_{3:-1}\end{align*}
        $$

        除此之外，由于我们考虑了从 column $i-1$ 到 column **-1** 的这个block是否会 generate 出 carry，我们也就不再需要考虑传导进位的问题，因为我们已经追溯到了列-1，源头处已经不可能有什么可供传导的初始进位.

    - Thus, we rewrite equation

        $$
        S_i=(A_i\oplus B_i)\oplus C_{in}=(A_i\oplus B_i)\oplus C_{i-1}
        $$

        as

        $$
        S_i=(A_i\oplus B_i)\oplus G_{i-1:-1}
        $$

    - Hence, the main challenge is to rapidly compute all the block generate signals $G_{-1:-1},G_{0:-1},G_{1:-1},G_{2:-1},\cdots,G_{N-2:-1}$. These signals, along with $P_{-1:-1},P_{0:-1},P_{1:-1},P_{2:-1},\cdots P_{N-2:-1}$, are called prefixes.

    - 因为我们上面提到了接下来主要的难点就是快速计算出$G_{-1:-1},G_{0:-1},G_{1:-1},G_{2:-1},\cdots,G_{N-2:-1}$和 $P_{-1:-1},P_{0:-1},P_{1:-1},P_{2:-1},\cdots P_{N-2:-1}$，那么这些东西该如何计算，右边的这张图片中的两个公式就为我们提供了计算的思路。
    - 考虑计算一般的情况 generate and propagate signals for a block spanning bits $i:j$。注意在这个地方有$\,i>j\,$。

        $$
        \begin{align*}G_{i:j}&=G_{i:k}+P_{i:k}G_{k-1:j}\\P_{i:j}&=P_{i:k}P_{k-1:j}\end{align*}
        $$

        对于这两个公式的文字解读，右侧的图片中已经解释得很明白了，如果不喜欢upper part和lower part的表述，其实也可以把下标为$\,i:k\,$的部分理解为left part，同时把下标为$\,k-1:j\,$的部分理解为right part。

    - 接下来我们来考虑这样一个例子

        $$
        1010+0111=\,?\,\,\,C_{in}=1
        $$

        |  | 1 | 0 | 1 | 0 |  |
        | --- | --- | --- | --- | --- | --- |
        |  | 0 | 1 | 1 | 1 |  |
        | carry $C_{i-1}$ | 1($C_2$) | 1($C_1$) | 1($C_0$) | 1($C_{-1}$) |  |
        | column number i | 3 | 2 | 1 | 0 | -1 |
        | $G_i$ | 0 | 0 | 1 | 0 | 1 |
        | $P_i$ | 1 | 1 | 1 | 1 |  |
        1. 首先第一步还是计算出1-bit的情形，即单独的$\,G_i\,$和 $P_i$，遵循的原则依然是

            $$
            \begin{align*}G_i&=A_iB_i\\P_i&=A_i+B_i\end{align*}
            $$

        2. 在计算出1-bit的情形之后，我们按照原定计划就想要来计算出2-bit的情况

            $$
            \begin{align*}G_{0:-1}&=G_{0:0}+P_{0:0}G_{-1:-1}=0+1=1=C_0\\G_{2:1}&=G_{2:2}+P_{2:2}G_{1:1}=0+1=1\\P_{2:1}&=P_{2:2}P_{1:1}=1\end{align*}
            $$

        3. 在计算出2-bit的情况后，我们按照原定计划就想要来计算出4-bit的情况，当然与此同时我们也可以计算出一些非2的幂bit的情况，来看详细过程

            $$
            \begin{align*}G_{2:-1}&=G_{2:1}+P_{2:1}G_{0:-1}=1+1=1=C_2\\G_{1:-1}&=G_{1:1}+P_{1:1}G_{0:-1}=1+1=1=C_1\end{align*}
            $$

        4. 到这里，我们就计算出了如下结果

            $$
            \begin{align*}C_2=C_1=C_0=C_{-1}=1\end{align*}
            $$

            $$
            G_{2:-1}=G_{1:-1}=G_{0:-1}=G_{-1:-1}=1
            $$

        5. 最后我们要做的就是套用公式

            $$
            S_i=A_i\oplus B_i\oplus C_{i-1}
            $$

            来计算sum bits.

            $$
            \begin{align*}S_0&=A_0\oplus B_0\oplus C_{-1}=0\oplus1\oplus1=0\\S_1&=A_1\oplus B_1\oplus C_0=1\oplus1\oplus1=1\\S_2&=A_2\oplus B_2\oplus C_1=0\oplus1\oplus1=0\\S_3&=A_3\oplus B_3\oplus C_2=1\oplus0\oplus1=0\end{align*}
            $$


    ![Screenshot 2023-02-06 at 20.28.16.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_20.28.16.png)

    ![Screenshot 2023-02-06 at 23.20.58.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_23.20.58.png)

    注意上面的这张图片中$\,S_i\,$的计算公式有问题，$S_i\,$的正确公式是

    $$
    S_i=A_i\oplus B_i\oplus C_{i-1}
    $$

    ![Screenshot 2023-02-06 at 22.39.33.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_22.39.33.png)

    - Figure 5.7 shows an $N$= 16-bit prefix adder. The adder begins with a precomputation to form $P_i$ and $G_i$ for each column from $A_i$ and $B_i$ using AND and OR gates.
    - It then uses $\log_2N=4$ levels of black cells to form the prefixes of $G_{i:j}$ and $P_{i:j}$. A black cell takes inputs from the upper part of a block spanning bits $i:k$ and from the lower part spanning bits $k-1:j$. It then combines these parts to form generate and propagate signals for the entire block spanning bits $i:j$ using the equations

        $$
        \begin{align*}G_{i:j}&=G_{i:k}+P_{i:k}G_{k-1:j}\\P_{i:J}&=P_{i:k}P_{k-1:j}\end{align*}
        $$

    - In other word, a block spanning bits $i:j$ will generate a carry if the upper part generates a carry or if the upper part propagates a carry generated in the lower part. The block will propagate a carry if both the upper part and lower parts propagate the carry.
    - Finally, the prefix adder computers the sums using

        $$
        S_i=(A_i\oplus B_i)\oplus G_{i-1:-1}
        $$


    ![Screenshot 2023-02-06 at 23.33.28.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-06_at_23.33.28.png)

    - 接下来让我们对于prefix adder schematic进行详细解读。这张图描述的是一个16-bit prefix adder，整张图分为三大部分，上面的黄色部分、中间的黑色部分和下面的蓝色部分。
    - 每一个黄色部分都是用来实现column generate and propagate signal，即$\,G_i\,$和$\,P_i\,$，其中$\,G_i=A_iB_i\,$，$P_i=A_i+B_i$，在图中为了格式统一我们把$\,G_i\,$和$\,P_i\,$扩展成了$\,G_{i:i}\,$以及$\,P_{i:i}\,$的形式，其表达的含义是不变的。特别注意$\,G_{-1}=C_{-1}=C_{in}$。
    - 在我们得到column generate和propagate之后，我们要把单列组成2列、4列等等，例如我们组成了0:-1，2:1，4:3，6:5，8:7，10:9，12:11，14:13，我们现在想要来求解两列两列的generate 和 propagate，而这一部分内容的实现使用的就是黑色电路，其中$\,P_{i:j}=P_{i:k}P_{k-1:j}$，$G_{i:j}=G_{i:k}+P_{i:k}G_{k-1:j}$。

        也就是说我们会得到$\,G_{2:1},P_{2:1},G_{4:3},P_{4:3},G_{6:5},P_{6:5},G_{8:7},P_{8:7},G_{10:9},P_{10:9},G_{12:11},P_{12:11},G_{14:13},P_{14:13}\cdots\,$等等东西。

        进一步我们会得到$\,G_{2:-1},G_{6:3},G_{10:7},G_{14:11},P_{6:3},P_{10:7},P_{14:11}\cdots\,$ 等等东西。

        进一步我们会得到$\,G_{6:-1},G_{14:7},P_{14:7}\cdots\,$等等东西。

        进一步我们会得到$G_{14:1}$。

        与此同时，跨度不为2的幂对应的$\,G\,$和$\,P\,$也可以很容易求得。在视频中这些跨度不为2的幂被称为是intermediate calculations，举例来说

        $$
        \begin{align*}G_{5:-1}&=G_{5:3}+P_{5:3}G_{2:1}\\G_{3:-1}&=G_{3:3}+P_{3:3}G_{2:-1}=G_3+P_3G_{2:-1}\end{align*}
        $$

    - 最下面的蓝色部分其实就是用来计算sum bits的，它遵循的原则就是

        $$
        S_i=A_i\oplus B_i\oplus C_{i-1}=A_i\oplus B_i\oplus G_{i-1:-1}
        $$

    - 接下来我们来考虑一下延时问题:
        - 首先第一步就是得到图中黄色所示的信号，即column propagate和column generate，即$\,G_i\,$和$\,P_i\,$，其中$\,G_i=A_iB_i\,$，$P_i=A_i+B_i$，由黄色部分的内部结构图我们可以得知这里存在1个拥有两个输入端的AND gate/OR gate delay。
        - 接下来分析黑色block，每一个row对应的block是同步的，由黑色block的内部结构图可以得知它的delay是2个gates。对于两个$N$-bit的数相加的prefix adder，中间会经过$\,\log_2N\,$轮，类似于一个$\,8\to4\to2\to1\,$的衰减的过程，每一轮的delay都是2个gates，这里的总delay可以用$\,\#\mathrm{stages}\times \mathrm{delay\,of\,a\,single\,stage}$ 来计算。
        - 最后分析蓝色，蓝色部分就是计算sum bits的，其遵循的原则是$\,S_i=A_i\oplus B_i\oplus C_{i-1}=A_i\oplus B_i\oplus G_{i-1:-1}\,$。这个蓝色部分的延时是多少？看起来像是2 gates的delay，但事实上$\,A_i\oplus B_i\,$早就已经算好了，在计算$\,G_i=A_iB_i\,$，$P_i=A_i+B_i\,$的时候就已经计算完毕了。所以蓝色部分其实只有1 gate delay。
        - 在右侧我们就得到了prefix adder的delay的计算公式

            $$
            t_{PA}=t_{pg}+\log_2N(t_{pg\_prefix})+t_{XOR}
            $$

            其中$\,t_{pg}\,$对应的是黄色部分，$\log_2N(t_{pg\_prefix})\,$对应的是绿色部分，$t_{XOR}\,$对应的是蓝色部分。


        ![Screenshot 2023-02-07 at 10.57.02.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_10.57.02.png)

        ![Screenshot 2023-02-07 at 10.53.15.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_10.53.15.png)

        ![Screenshot 2023-02-07 at 11.01.40.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_11.01.40.png)

    - In summary, the prefix adder achieves a delay that grows logarithmically rather than linearly with the number of columns in the adder. This speedup is significant, especially for adders with 32 or more bits, but it comes at the expense of more hardware than a simple carry-lookahead adder.
    - The network of black cells is called a prefix tree.
    - The general principle of using prefix trees to perform computations in time that grows logarithmically with the number of inputs is a powerful technique. With some cleverness, it can be applied to many other types of circuits.
    - The critical path for an $N$-bit prefix adder involves the precomputation of $P_i$ and $G_i$ followed by $\log_2N$ stages of black prefix cells to obtain all the prefixes. $G_{i-1:-1}$ then proceeds through the final XOR gate at the bottom to computer $S_i$. Mathematically, the delay of an $N$-bit prefix adder is

        $$
        t_{PA}=t_{pg}+\log_2Nt_{pg\_prefix}+t_{XOR}
        $$

        where $t_{pg\_prefix}$ is the delay of a black prefix cell.

</aside>

<h3 id="522-subtraction">5.2.2 Subtraction</h3>
<aside>
📖 **Important takeaways**

- Adders can add positive and negative numbers **using two’s complement number representation**.
- Subtraction is almost as easy: flip the sig of the second number, then add.
- **Flipping the sign** of a two’s complement number is done by **inverting the bits** and **adding 1**.
- To compute $Y=A-B$, first create the two’s complement of $B$: Invert the bits of $B$ to obtain $\overline{B}$ and add 1 to get $-B=\overline{B}+1$. Add this quantity to $A$ to get $Y=A-B=A+\overline{B}+1$. This sum can be performed with a single CPA(carry propagate adder) **by adding $A+\overline{B}$ with $C_{in}=1$**.
- Figure 5.9 shows the symbol for a subtractor and the underlying hardware for performing $Y=A-B$.(图中小的横线表示接电源，也就是$C_{in}=\mathrm{HIGH}=1$)

![Screenshot 2023-02-07 at 11.23.57.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_11.23.57.png)

</aside>

<h3 id="523-comparators">5.2.3 Comparators</h3>
<aside>
📖 **Important takeaways**

- A **comparator** determine **whether two binary numbers are equal** or if **one is greater or less than the other**.
- A comparator receives two $N$-bit binary numbers $A$ and $B$. **There are two common types of comparators**.
    1. An equality comparator produces a single output indicating whether $A$ is equal to $B$($A==B$).
    2. A magnitude comparator produces one or more outputs indicating the relative values of $A$ and $B$.

- **Equality Comparator**
    - The equality comparator is the simpler piece of hardware. Figure 5.11 shows the symbol and implementation of a 4-bit equality comparator.
    - It first checks to determine whether the corresponding bits in each column of $A$ and $B$ are equal using $\mathrm{XNOR}$ gates.


        | $A_i$ | $B_i$ | $Y$ |
        | --- | --- | --- |
        | 0 | 0 | 1 |
        | 0 | 1 | 0 |
        | 1 | 0 | 0 |
        | 1 | 1 | 1 |

        $$
        Y=\overline{A\oplus B}
        $$

    - The numbers are equal if all of the columns are equal.(AND gate)

    ![Screenshot 2023-02-07 at 11.38.01.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_11.38.01.png)


- Magnitude comparison is usually done by computing $A-B$ and looking at the sign(most significant bit) of the result as shown in Figure 5.12.
- If the result is negative(i.e., the sign bit is 1), then $A$ is less than $B$. Otherwise $A$ is greater than or equal to B.

![Screenshot 2023-02-07 at 11.48.13.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_11.48.13.png)

![Screenshot 2023-02-07 at 11.49.38.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_11.49.38.png)

- 图中[N-1]的意思是从bus中取出最高位。即从右往左数第N-1位。
</aside>

<h3 id="524-alu">5.2.4 ALU(!!!)</h3>
<aside>
📖 **Important takeaways**

- An **Arithmetic/Logical Unit(ALU)** **combines a variety of mathematical and logical operations into a single unit**.
- For example, **a typical ALU might perform addition, subtraction, magnitude comparison, AND, and OR operations**.
- **The ALU form the heart of most computer systems**.

- Figure 5.14 shows the symbol for an $N$-bit ALU with $N$-bit inputs and outputs. **The ALU receives a 2-bit control signal ALUControl that specifies which function to perform**. Control signals will generally be shown in blue to distinguish them from the data.
- Table 5.1 lists typical functions that the ALU can perform.
- Figure 5.15 shows an implementation of the ALU. The ALU contains an $N$-bit adder and $N$ 2-input AND and OR gates(两个$N$-bit的数做AND和OR运算指的是两个$N$-bit数的每一位都做AND和OR运算). It also contains inverters and a multiplexer to invert input B when $ALUControl_0$ is asserted. A 4:1 multiplexer chooses the desired function based on $ALUControl$.

![Screenshot 2023-02-07 at 20.43.57.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_20.43.57.png)

- More specifically, **if $ALUControl=00$, the output multiplexer chooses $A+B$**. **If $ALUControl=01$, the ALU computes $A-B$**.(Recall that $\overline{B}+1=-B$ in two’s complement arithmetic. Because $ALUControl=01, ALUControl_0=1$, the adder receives inputs $A$ and $\overline{B}$ and an asserted carry in, causing it to perform subtraction: $A-B=A+\overline{B}+1$注意从$ALUControl$中分出来了$ALUControl_0$,并且$ALUControl_0$连了两个地方,上方连接的是一个multiplexer,当$ALUControl_0=0$时,接入的信号是$B$,当$ALUControl_0=1$时,接入的信号是$\overline{B}$,而下方$ALUControl_0$还是adder的carry-in,如果是计算$A+B$,此时不需要初始的carry-in,$ALUControl_0=\text{carry-in}=0$,如果是计算$A-B$,因为$A-B=A+\overline{B}+1$,所以此时有初始的$\text{carry-in}=ALUControl_0=1$)

    If $ALUControl=10$, the ALU computes $A$ $\mathrm{AND}$ $B$. If $ALUControl=11$, the ALU performs $A$ $OR$ $B$.

- 这样我们通过巧妙使用$ALUControl$信号中的$ALUControl_0$配合multiplexer,从而高效达到了只使用一个adder就完成了加法减法两种运算的成果。因为adder本身被我们认为是expensive的,也就是说我们构建adder的成本很高,尽量不要无缘无故增加adder的数量,可以增加其它更加简单的电子元器件。
- Some ALUs produce extra outputs, called flags, that indicate information about the ALU output. Figure 5.16 shows the ALU symbol with a 4-bit Flags output.
- As shown in the schematic of the ALU in Figure 5.17, the Flags output is composed of the N, Z, C, and V flags that indicate, respectively, that the ALU output, Result, is negative(N) or zero(Z) or that the adder produced a carry out(C) or overflowed(V).


    | Flag | Description |
    | --- | --- |
    | N | Result is Negative |
    | Z | Result is Zero |
    | C | Result produces Carry out |
    | V | Adder oVerflowed |

    ![Screenshot 2023-02-07 at 21.22.40.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_21.22.40.png)

    ![Screenshot 2023-02-07 at 21.24.56.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_21.24.56.png)

- 接下来我们就来详细叙述一下这四个flags都是如何实现的(overflow flag因为内容比较多单独写)
    - **N(Negative)**
        - 判断Result是否是负数比较简单，因为在two’s complement arithmetic中，最高位(the most significant bit)表征的一个数的正负，当最高位(most significant bit, msb)是1时，说明这个数是负数，当最高位(most significant bit, msb)是0时，说明这个数是正数。
        - Negative flag的工作原理比较简单，当negative flag = 1时，表明结果是负数，当negative flag = 0时，表明结果是正数。
        - 所以 $\text{negative flag}=\text{msb}=Result_{31}$.
    - **Z(Zero)**
        - Zero flag的工作原理比较简单，当zero flag = 1时，表明结果是0，当zero flag = 0时，表明结果不是0。
        - 所以我们可以对结果按位取反，然后AND在一起，因为只有当结果为0(每一位都是0)时，对其按位取反，才会每一位都是1，只有当每一位全是1的情况下，将其AND在一起，结果才会是1。
        - 所以我们在实际搭建电路的时候会有一个小圆圈表示取反，然后统一经过一个AND gate。
    - **C(Carry)**
        - Carry flag的工作原理比较简单，当$\,C_{out}=1\,$时，说明最后是有进位carry的，因此此时carry flag = 1。当$\,C_{out}=0\,$时，说明最后时没有进位carry的，因此此时carry flag = 0。
        - 我们判断carry的时候是要在ALU处于计算加法模式和减法模式的时候，由于加法模式对应的状态是$ALUControl=00$，减法模式对应的状态是$ALUControl=01$。
        - 所以我们可以让

            $$
            carry\,flag=\overline{ALUControl_1}\space\text{AND}\space C_{out}
            $$


![Screenshot 2023-02-07 at 20.22.39.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_20.22.39.png)

![Screenshot 2023-02-07 at 20.19.01.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_20.19.01.png)

[Logic Gates - Building an ALU](http://www.csc.villanova.edu/~mdamian/Past/csc2400fa13/assign/ALU.html)

![Screenshot 2023-02-07 at 20.40.11.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_20.40.11%201.png)

![Screenshot 2023-02-07 at 20.42.26.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_20.42.26.png)

![Screenshot 2023-02-07 at 20.42.58.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_20.42.58.png)

![Screenshot 2023-02-07 at 21.22.01.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_21.22.01.png)

![Screenshot 2023-02-07 at 21.31.23.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_21.31.23.png)

![Screenshot 2023-02-07 at 21.31.29.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_21.31.29.png)

![Screenshot 2023-02-07 at 21.31.31.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_21.31.31.png)

![Screenshot 2023-02-07 at 21.31.33.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_21.31.33.png)

![Screenshot 2023-02-07 at 21.31.36.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-07_at_21.31.36.png)

- **V(overflow)**
    - Overflow的基本思想比较简单，就是出现overflow的时候，overflow flag = 1，没有出现overflow的时候，overflow flag = 0。
    - 因此我们现在就要来着重分析到底在什么情况下会出现overflow。
    - **首先与carry flag的判断一样，我们的一个前提是ALU正在进行加法运算或减法运算**。
    - 其次就是要检查是否有overflow，要想**有overflow的一个必要条件就是A和Sum有相反的符号**。为什么这么说，我们不妨思考一下什么时候会发生overflow。
        - 一正一负做加法不会overflow，两个正做减法不会overflow，两个负做减法不会overflow。
        - 两个正做加法有可能overflow，两个负做加法有可能overflow，一个正一个负做减法有可能overflow，一个负一个正做减法有可能overflow。
        - 两个正做加法overflow的时候，A的sign bit是0，sum的sign bit 是1。
        - 两个负做加法overflow的时候，A的sign bit是1，sum的sign bit是0。
        - 一正一负做减法overflow的时候，A的sign bit是0，sum的sign bit是1，例如

            $1-(-7)=0001-1001=0001+0111=1000(overflow)$.

        - 一负一正做减法overflow的时候，A的sign bit是1，sum的sign bit是0，例如

            $-7-3=1001-0011=1001+1101=0110(overflow)$.

        - **A和Sum的符号(看的就是sign bit)如果相反，输出1，相同，输出0，这可以用XOR gate来实现**。
    - 最后光让A和Sum有相反的符号是不够的，因为有可能出现
        - 正+负=负，负+正=正，正-正=负，负-负=正的情况，在这四种情况中，虽然A和Sum有相反的sign bit，但是并不会发生overflow。
        - 因此我们需要进一步限定，A和Sum有相反的符号，且必须处在A、B同号并进行加法运算，或A、B异号并进行减法运算两种情况。这分别对应图片中写到的
            - A and B have same signs for addition.
            - A and B have different signs for subtraction.
        - 所以我们第三个条件有如下的要求
            - add(00)，same sign(same sign bit)，有000，011两种组合方式。
            - subtract(01)，different sign(different sign bit)，有101，110两种组合方式。
            - 组合方式是$ALUControl_0+sign\,bit\,1+sign\,bit\,2$。
            - 要求在上述几种组合方式下输出1，其余组合方式输出0。
            - 经过观察，发现应该使用XNOR gate(有偶数个1则输出1，有奇数个1则输出0，注意XNOR gate与XOR gate之间的区别，XOR gate是有奇数个1输出1，有偶数个1输出0)。
    - 最后我们实现V(overflow flag)还需要三剑合一
        1. 处于加法运算或减法运算模式($\overline{ALUControl_1}$)
        2. A与Sum的sign bit相反。($A_{31}\,\text{XOR}\,Sum_{31}$)
        3. A、B符号相同，且进行的是加法运算或A、B符号相反且进行的减法运算。

        $$
        A_{31}\space\text{XNOR}\space B_{31}\space\text{XNOR}\space ALUControl_0=\overline{A_{31}\oplus B_{31}\oplus ALUControl_0}
        $$

</aside>

<h2 id="53-number-systems">5.3 Number Systems</h2>
<h3 id="530-background">5.3.0 Background</h3>
<aside>
📖 **Background**

- **Computers operate on both integers and fractions**.
- So far, we have only considered representing signed or unsigned integers, as introduced in Section 1.4.
- This section introduces **fixed- and floating-point number systems** that can **represent rational numbers**.
- Fixed-point numbers are analogous to decimals; some of the bits represent the integer part, and the rest represent the fraction.
- Floating-point numbers are analogous to scientific notation, with a mantissa(?) and an exponent.
</aside>

<h3 id="531-fixed-point-number-systems">5.3.1 Fixed-Point Number Systems</h3>
<aside>
📖 **Important takeaways**

- **Fixed-point notation** has an **implied binary point** between the integer and fraction bits, **analogous to the decimal point** between the integer and fraction digits of an ordinary decimal number.
- For example,
    - Figure 5.23(a) shows a fixed-point number with **four integer bits and four fraction bits**.
    - Figure 5.23(b) shows **the implied binary point in blue**.
    - Figure 5.23(c) shows the equivalent decimal value.
- Signed(positive and negative) fixed-point numbers can use either two’s complement or sign/magnitude notation.
- Figure 5.24 shows the fixed-point representation of -2.375 using both notations with four integer and four fraction bits. The implicit binary point is shown in blue for clarity.
- In **sign/magnitude form**, the **most significant bit is used to indicate the sign**(1 for negative numbers and 0 for positive numbers).
- The **two’s complement representation** is formed by **inverting the bits of the absolute value and adding a 1 to the least significant (rightmost) bit**. In this case, **the least significant bit position is in the $2^{-4}$ column**.
- Like all binary number representations, fixed-point numbers are just a collection of bits. There is no way of knowing the existence of the binary point except through agreement of those people interpreting the number.
- In general, we use $Ua.b$ to denote an unsigned fixed-point number with $a$ integer bits and $b$ fraction bits. $Qa.b$ denotes a signed(two’s complement) fixed point number with $a$ integer bits(including the sign bit) and $b$ fractional bits.

![Screenshot 2023-02-08 at 00.05.59.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-08_at_00.05.59.png)

![Screenshot 2023-02-08 at 00.09.30.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-08_at_00.09.30.png)

![Screenshot 2023-02-08 at 00.24.44.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-08_at_00.24.44.png)

![Screenshot 2023-02-08 at 00.24.58.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-08_at_00.24.58.png)

![Screenshot 2023-02-08 at 00.24.08.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-08_at_00.24.08.png)

</aside>

<h3 id="532-floating-point-number-systems">5.3.2 Floating-Point Number Systems</h3>
<aside>
📖 **Important takeaways**

- 

</aside>

<h1 id="6-architecture">6 Architecture</h1>
<h2 id="61-introduction">6.1 Introduction</h2>
<aside>
📖 **Background**

- The previous chapters introduced digital design principles and building blocks. In this chapter, we **jump up a few levels of abstraction** to **define the architecture of a computer**. The **architecture is the programmer’s view of a computer**. It is defined by the **instruction set(language)** and **operand locations(registers and memory)**. Many different architectures exist, such as RISC-V, ARM, x86, MIPS, SPARC, and POWERPC.
- The **first step** in **understanding any computer architecture** is to **learn its language**. The words in a computer’s language are called **instructions**. The computer’s vocabulary is called the **instruction set**. All programs running on a computer use the same instruction set.
- **Computer instructions** indicate **both the operation** to perform **and the operands** to use. The **operands** may **come from memory**, **from registers, or from the instruction** itself.
- Humans consider reading machine language to be tedious, so we prefer to **represent the instructions in a symbolic format** called **assembly language**.
- The instruction sets of different architectures are more like different dialects than different languages. **Almost all architectures define basic instructions, such as add, subtract, and jump, that operate on memory or registers**.
- **A computer architecture does not define the underlying hardware implementation**. Often, many different hardware implementations of a single architecture exist.
- The specific arrangement of registers, memories, ALUs, and other building blocks to form a microprocessor is called the microarchitecture and will be the subject of Chapter 7. Often, many microarchitectures exist for a single architecture.
- In this text, we introduce the MIPS architecture that was first developed by John Hennessy and his colleagues at Stanford in the 1980s. MIPS processors are used by, among others, Silicon Graphics, Nintendo, and Cisco.
- We start by introducing the **basic instructions**, **operand locations**, and **machine language formats**. We then introduce **more instructions used in common programming concepts, such as branches, loops, array manipulations, and function calls**.

![Screenshot 2023-02-08 at 22.30.37.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-08_at_22.30.37.png)

![Screenshot 2023-02-08 at 22.30.58.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-08_at_22.30.58.png)

- Throughout the chapter, we motivate the design of the MIPS architecture using **four principles** articulated by Patterson and Hennessy:
    1. **simplicity favors regularity**
    2. **make the common case fast**
    3. **smaller is faster**
    4. **good design demands good compromises**
</aside>

<h2 id="62-assembly-language">6.2 Assembly Language</h2>
<h3 id="620-background">6.2.0 Background</h3>
<aside>
📖 **Background**

- Assembly language is the human-readable representation of the computer’s native language.
- Each **assembly language instruction** specifies both **the operation to perform** and **the operand on which to operate**.
- We introduce simple arithmetic instructions and show how these operations are written in assembly language. We then define the MIPS instruction operands: registers, memory, and constants.(这些都是运算operation作用的对象)
</aside>

<h3 id="621-instructions">6.2.1 Instructions</h3>
<aside>
📖 **Important takeaways**

- The most common operation computers perform is addition. The first part of the assembly instruction, `add`, is called the **mnemonic** and **indicates what operation to perform**. The operation is performed on `b` and `c` , the **source operands**, and the result is written to `a` , the **destination operands**.


    ```c
    a = b + c
    ```

    ```nasm
    add a, b, c
    ```

- Subtraction is similar to addition. The instruction format is the same as the `add` instruction except for the operation specification, `sub`. This consistent instruction format is an example of the first design principle:

    $$
    \mathrm{\bold{Design\space Principle\space1}:Simplicity\space favors\space regularity}
    $$

- In assembly language, only single-line comments are used. They begin with `#` and continue until the end of the line.
- Instructions with a consistent number of operands — in this case, two sources and one destination — are easier to encode and handle in hardware. **More complex high-level code translates into multiple MIPS instructions**.


    ```c
    a = b + c - d

    ```

    ```nasm
    sub t, c, d  # t = c - d
    add a, b, t  # a = b + t = b + c - d
    ```

    Using multiple assembly language instructions to perform more complex operations is an example of the second design principle of computer architecture:

    $$
    \mathrm{\bold{Design\space Principle\space2}:Make\space the\space common\space case\space fast}
    $$

- **The MIPS instruction set makes the common case fast by including only simple, commonly used instructions**. The number of instructions is kept small so that the hardware required to decode the instruction and its operand can be simple, small, and fast.
- More elaborate operations that are less common are performed using sequences of multiple simple instructions. Thus, **MIPS is a reduced instruction set computer(RISC)** architecture. Architectures with many complex instructions, such as Intel’s x86 architecture, are complex instruction set computers(CISC).
- A RISC architecture minimizes the hardware complexity and the necessary instruction encoding by keeping the set of distinct instructions small. For example, an instruction set with 64 simple instructions would need $\log_264=6$ bits to encode the operation. An instruction set with 256 complex instructions would need $\log_2256=8$ bits of encoding per instruction. In a CISC machine, even though the complex instructions may be used only rarely, they add overhead to all instructions, even the simple ones.
</aside>

<h3 id="622-operands-registers-memory-and-constants-load-wordlw-store-wordsw">6.2.2 Operands: Registers, Memory, and Constants(❗❗❗❗❗ load word[lw], store word[sw])</h3>
<aside>
📖 **Important takeaways**

- **Background**
    - An instruction operates on operands. In `add a, b, c` , the variables `a` , `b` , and `c` are all operands. But computers operate on 1’s and 0’s, not variable names. The instruction need a physical location from which to retrieve the binary data.
    - Operands can be stored in registers or memory, or they may be constants stored in the instruction itself.
    - Computers use **various locations** to **hold operands** in order to **optimize for speed and data capacity**.
        - Operands stored as constants or in registers are accessed quickly, but they hold only a small amount of data.
        - Additional data must be accessed from memory, which is large but slow.
    - MIPS is called a 32-bit architecture because it operates on 32-bit data.
- **Registers**
    - Instructions need to access operands quickly so that they can run fast. But operands stored in memory take a long time to retrieve.
    - Therefore, most architectures **specify a small number of registers** that **hold commonly used operands**.
    - The MIPS architecture uses 32 registers, called the register set or register file. The fewer the registers, the faster they can be accessed. This leads to the third design principle:

        $$
        \mathrm{\bold{Design\space Principle\space3}:Smaller\space is\space faster}
        $$

    - Looking up information from a small number of relevant books on your desk is a lot faster than searching for the information in the stacks at a library. Likewise, reading data from a small set of registers(for example, 32) is faster than reading it from 1000 registers or a large memory.
    - (?) A small register file is typically built from a small SRAM array(see Section 5.5.3). The SRAM array uses a small decoder and bitlines connected to relatively few memory cells, so it has a shorter critical path than a large memory does.
    - The following example shows the `add` instruction with register operands. MIPS register names are preceded by the `$` sign. The variable `a`, `b`, and `c` are arbitrarily placed in `$s0`, `$s1`, `$s2`. The name `$s1` is pronounced “register `s1`” or “dollar `s1`”, The instruction adds the 32-bit values contained in `$s1`(`b`) and `$s2`(`c`) and writes the 32-bit result to `$s0`(`a`).


        ```c
        a = b + c
        ```

        ```nasm
        add $s0, $s1, $s2
        ```

    - MIPS generally stores variables in 18 of the 32 registers: `$s0`-`$s7`, and `$t0`-`$t9`.
        - Register names beginning with `$s` are called saved registers. Following MIPS convention, these registers store variables such as `a`, `b`, and `c`. Saved registers have special connotations when they are used with function calls(see Section 6.4.6).
        - Register names beginning with `$t` are called temporary registers. They are used for storing temporary variables. The following example shows MIPS assembly code using a temporary register, `$t0` , to store the intermediate calculation of `c - d`.


            ```c
            a = b + c - d
            ```

            ```nasm
            sub $t0, $s2, $s3 # t = c - d
            add $s0, $s1, $t0 # a = b + t = b + c - d
            ```

            ![Screenshot 2023-02-08 at 23.56.43.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-08_at_23.56.43.png)

            ```nasm
            sub $s0, $s1, $s2 # a = b - c
            add $t0, $s4, $s5 # $t0 = g + h
            add $t1, $s6, $s7 # $t1 = i + j
            sub $s3, $t0, $t1 # f = (g + h) - (i + j)
            ```

- **The Register Set**


    - The MIPS architecture defines 32 registers. Each register has a name and a number ranging from 0 to 31. Table 6.1 lists the name, number, and use for each register.
    - `$0` always contain the value `0` because this constant is so frequently used in computer programs.
    - We have also discussed the `$s` and `$t` registers. The remaining registers will be described throughout this chapter.

    ![Screenshot 2023-02-09 at 00.02.45.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-09_at_00.02.45.png)

- **Memory**
    - If registers were the only storage space for operands, we would be confined to simple programs with no more than 32 variables. However, data can also be stored in memory.
    - When compared to the register file, **memory has many data locations**, but **accessing it takes a longer amount of time**.
    - Whereas the register file is small and fast, memory is large and slow. For this reason, **commonly used variables are kept in registers**.


        |  | the register file | memory |
        | --- | --- | --- |
        | data locations | limited data locations(only 32 registers) | many data locations |
        | time to access the data | shorter | longer |
    - By using a combination of memory and registers, a program can access a large amount of data fairly quickly.
    - (?) As described in Section 5.5, memories are organized as an array of data words.
    - **The MIPS architecture uses 32-bit memory addresses and 32-bit data words**.
    - **MIPS uses a byte-addressable memory**. That is, each byte in memory has a unique address. However, for explanation purposes only, we first introduce a word-addressable memory, and afterwards describe the MIPS byte addressable memory.
    - Figure 6.1 shows a memory array that is word-addressable. That is, each 32-bit data word has a unique 32-bit address. **Both the 32-bit word address and the 32-bit data value are written in hexadecimal in Figure 6.1**. For example, data `0xF2F1AC07` is stored at memory address `1`. Hexadecimal constants are written with the prefix `0x`. By convention, memory is drawn with low memory address toward the bottom and high memory address toward the top.
    - MIPS uses the load word, `lw`, to read a data word from memory into a register. Code Example 6.6 loads memory word `1` into `$s3`. The `lw` instruction specifies **the effective address in memory** as **the sum of a base address and an offset**.
        - The base address(written in parentheses in the instruction) is a register(e.g., `$0`).
        - The offset is a constant(written before the parentheses).
        - In Code Example 6.6, the base address is `$0`, which holds the value `0`, and the offset is `1` , so the `lw` instruction reads from memory address `($0 + 1) = 1`. After the load word instruction(`lw`) is executed, `$s3` holds the value `0xF2F1AC07`, which is the data value stored at memory address `1` in Figure 6.1.
        - Similarly, MIPS uses the store word instruction, `sw`, to write a data word from a register into memory(`lw` reads a data from the memory into a register). Code Example 6.7 writes the contents of register `$s7` into memory word `5`.
        - These examples have used `$0` as the base address for simplicity, but remember that any register can be used to supply the base address.

        ![Screenshot 2023-02-09 at 00.11.28.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-09_at_00.11.28.png)

        ![Screenshot 2023-02-09 at 00.12.03.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-09_at_00.12.03.png)

        ![Screenshot 2023-02-09 at 00.12.17.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-09_at_00.12.17.png)

    - The previous two code examples have shown a computer architecture with a word-addressable memory. **The MIPS memory model, however, is byte-addressable, not word-addressable**. **Each data byte has a unique address**.
    - A 32-bit word consists of four 8-bit bytes,$\,32\,\mathrm{bits}=4\times8\,\mathrm{bits}$. **So each word address is a multiple of 4**, as shown in in Figure 6.2. Again, both the 32-bit word address and the data value are given in hexadecimal.
    - Code Example 6.8 shows how to read and write words in the MIPS byte-addressable memory. **The word address is four times the word number**. The MIPS assembly code reads words 0, 2, 3 and writes words 1, 8, and 100. **The offset can be written in decimal or hexadecimal**.

        $$
        \begin{align*}0_{10}\times4&=0_{10}=0_{16}\\2_{10}\times 4&=8_{10}=8_{16}\\3_{10}\times 4&=12_{10}=\mathrm{0xC}_{16}\end{align*}
        $$

        $$
        \begin{align*}4_{10}\div4&=1_{10}\\0\mathrm{x20}_{16}\div 4&=32_{10}\div 4=8_{10}\\400_{10}\div 4&=100\end{align*}
        $$

        ![Screenshot 2023-02-09 at 00.31.36.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-09_at_00.31.36.png)

        ![Screenshot 2023-02-09 at 00.31.54.png](Digital%20Design%20and%20Computer%20Architecture(!!!)%20935ed377ae204d42b7648117d32f3ac2/Screenshot_2023-02-09_at_00.31.54.png)

    - The MIPS architecture also provides the `lb` and `sb` instructions that load and store single bytes in memory rather than words. They are similar to `lw` and `sw` and will be discusses further in Section 6.4.5.
    - Byte-addressable memories are organized in a big-endian or little-endian fashion, as shown in Figure 6.3.


</aside>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.db81ec45.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.6df46069.min.js"></script>
      
    
  </body>
</html>